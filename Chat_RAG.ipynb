{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Instalacion de Paquetes necesarios"
      ],
      "metadata": {
        "id": "jQioSBGkd3i2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sL05kkjy9R7D",
        "outputId": "13a6c1bf-4d1b-4065-b209-cec8b69181b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.3.20-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting openai\n",
            "  Downloading openai-1.65.3-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.7-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.41 (from langchain)\n",
            "  Downloading langchain_core-0.3.41-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.3.11-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
            "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
            "  Downloading SQLAlchemy-2.0.38-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting requests<3,>=2 (from langchain)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting PyYAML>=5.3 (from langchain)\n",
            "  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting anyio<5,>=3.5.0 (from openai)\n",
            "  Downloading anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting distro<2,>=1.7.0 (from openai)\n",
            "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting sniffio (from openai)\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting tqdm>4 (from openai)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions<5,>=4.11 (from openai)\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting certifi (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.41->langchain)\n",
            "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.41->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting packaging<25,>=23.2 (from langchain-core<1.0.0,>=0.3.41->langchain)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
            "  Downloading zstandard-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
            "  Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
            "  Downloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
            "  Downloading greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai)\n",
            "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Downloading langchain-0.3.20-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.65.3-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.7-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.6/345.6 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.41-py3-none-any.whl (415 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.1/415.1 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
            "Downloading langsmith-0.3.11-py3-none-any.whl (335 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.3/335.3 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.7/431.7 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.0/763.0 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading SQLAlchemy-2.0.38-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (602 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m602.4/602.4 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading orjson-3.10.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.3/130.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
            "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zstandard-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: zstandard, urllib3, typing-extensions, tqdm, tenacity, sniffio, regex, PyYAML, packaging, orjson, jsonpointer, jiter, idna, h11, greenlet, distro, charset-normalizer, certifi, annotated-types, SQLAlchemy, requests, pydantic-core, jsonpatch, httpcore, anyio, tiktoken, requests-toolbelt, pydantic, httpx, openai, langsmith, langchain-core, langchain-text-splitters, langchain-openai, langchain\n",
            "  Attempting uninstall: zstandard\n",
            "    Found existing installation: zstandard 0.23.0\n",
            "    Uninstalling zstandard-0.23.0:\n",
            "      Successfully uninstalled zstandard-0.23.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: sniffio\n",
            "    Found existing installation: sniffio 1.3.1\n",
            "    Uninstalling sniffio-1.3.1:\n",
            "      Successfully uninstalled sniffio-1.3.1\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.11.6\n",
            "    Uninstalling regex-2024.11.6:\n",
            "      Successfully uninstalled regex-2024.11.6\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: orjson\n",
            "    Found existing installation: orjson 3.10.15\n",
            "    Uninstalling orjson-3.10.15:\n",
            "      Successfully uninstalled orjson-3.10.15\n",
            "  Attempting uninstall: jsonpointer\n",
            "    Found existing installation: jsonpointer 3.0.0\n",
            "    Uninstalling jsonpointer-3.0.0:\n",
            "      Successfully uninstalled jsonpointer-3.0.0\n",
            "  Attempting uninstall: jiter\n",
            "    Found existing installation: jiter 0.8.2\n",
            "    Uninstalling jiter-0.8.2:\n",
            "      Successfully uninstalled jiter-0.8.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.14.0\n",
            "    Uninstalling h11-0.14.0:\n",
            "      Successfully uninstalled h11-0.14.0\n",
            "  Attempting uninstall: greenlet\n",
            "    Found existing installation: greenlet 3.1.1\n",
            "    Uninstalling greenlet-3.1.1:\n",
            "      Successfully uninstalled greenlet-3.1.1\n",
            "  Attempting uninstall: distro\n",
            "    Found existing installation: distro 1.9.0\n",
            "    Uninstalling distro-1.9.0:\n",
            "      Successfully uninstalled distro-1.9.0\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.1\n",
            "    Uninstalling charset-normalizer-3.4.1:\n",
            "      Successfully uninstalled charset-normalizer-3.4.1\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.1.31\n",
            "    Uninstalling certifi-2025.1.31:\n",
            "      Successfully uninstalled certifi-2025.1.31\n",
            "  Attempting uninstall: annotated-types\n",
            "    Found existing installation: annotated-types 0.7.0\n",
            "    Uninstalling annotated-types-0.7.0:\n",
            "      Successfully uninstalled annotated-types-0.7.0\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.38\n",
            "    Uninstalling SQLAlchemy-2.0.38:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.38\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.27.2\n",
            "    Uninstalling pydantic_core-2.27.2:\n",
            "      Successfully uninstalled pydantic_core-2.27.2\n",
            "  Attempting uninstall: jsonpatch\n",
            "    Found existing installation: jsonpatch 1.33\n",
            "    Uninstalling jsonpatch-1.33:\n",
            "      Successfully uninstalled jsonpatch-1.33\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.7\n",
            "    Uninstalling httpcore-1.0.7:\n",
            "      Successfully uninstalled httpcore-1.0.7\n",
            "  Attempting uninstall: anyio\n",
            "    Found existing installation: anyio 3.7.1\n",
            "    Uninstalling anyio-3.7.1:\n",
            "      Successfully uninstalled anyio-3.7.1\n",
            "  Attempting uninstall: requests-toolbelt\n",
            "    Found existing installation: requests-toolbelt 1.0.0\n",
            "    Uninstalling requests-toolbelt-1.0.0:\n",
            "      Successfully uninstalled requests-toolbelt-1.0.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.10.6\n",
            "    Uninstalling pydantic-2.10.6:\n",
            "      Successfully uninstalled pydantic-2.10.6\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.61.1\n",
            "    Uninstalling openai-1.61.1:\n",
            "      Successfully uninstalled openai-1.61.1\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.3.11\n",
            "    Uninstalling langsmith-0.3.11:\n",
            "      Successfully uninstalled langsmith-0.3.11\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.40\n",
            "    Uninstalling langchain-core-0.3.40:\n",
            "      Successfully uninstalled langchain-core-0.3.40\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.6\n",
            "    Uninstalling langchain-text-splitters-0.3.6:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.6\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.19\n",
            "    Uninstalling langchain-0.3.19:\n",
            "      Successfully uninstalled langchain-0.3.19\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-server 1.24.0 requires anyio<4,>=3.1.0, but you have anyio 4.8.0 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyYAML-6.0.2 SQLAlchemy-2.0.38 annotated-types-0.7.0 anyio-4.8.0 certifi-2025.1.31 charset-normalizer-3.4.1 distro-1.9.0 greenlet-3.1.1 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 idna-3.10 jiter-0.8.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.20 langchain-core-0.3.41 langchain-openai-0.3.7 langchain-text-splitters-0.3.6 langsmith-0.3.11 openai-1.65.3 orjson-3.10.15 packaging-24.2 pydantic-2.10.6 pydantic-core-2.27.2 regex-2024.11.6 requests-2.32.3 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.0.0 tiktoken-0.9.0 tqdm-4.67.1 typing-extensions-4.12.2 urllib3-2.3.0 zstandard-0.23.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi"
                ]
              },
              "id": "14d60734dcda445fafcd8182c6f0ed49"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install --force-reinstall langchain openai langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN4t8p3J9us1",
        "outputId": "cce19e14-df72-4ee5-eced-d2d235cd6bd1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.41)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.20 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.20)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.11)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.20->langchain-community) (0.3.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.20->langchain-community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.8.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.20->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.20->langchain-community) (2.27.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.19-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.19 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qrUrHf19t72",
        "outputId": "90e49f9c-9501-48c4-ac3e-d2df68c59aa5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.48.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.28.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gQxMsnNspEt",
        "outputId": "d0045acf-a961-41c0-9bd9-b635ecad34d6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdMrVndSYvP5",
        "outputId": "0f8f55b8-f765-4b33-e49c-3d0e6185d8a7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.3.5-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.41)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.16-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt<0.2,>=0.1.1 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.1.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.53-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (0.3.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (2.10.6)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.8.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.3.5-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.5/131.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.16-py3-none-any.whl (38 kB)\n",
            "Downloading langgraph_prebuilt-0.1.1-py3-none-any.whl (24 kB)\n",
            "Downloading langgraph_sdk-0.1.53-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.3.5 langgraph-checkpoint-2.0.16 langgraph-prebuilt-0.1.1 langgraph-sdk-0.1.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVLflejupG2a",
        "outputId": "4e841181-9597-4509-8d81-4a795205bec0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importamos las librerias a utilizar"
      ],
      "metadata": {
        "id": "C6J9TajTeQjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "import openai\n",
        "import os\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.documents import Document\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from typing_extensions import List, TypedDict\n",
        "from langgraph.graph import MessagesState, StateGraph\n",
        "from langchain_core.messages import SystemMessage\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.graph import END\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "from IPython.display import Image, display\n",
        "from langgraph.graph import START, StateGraph\n",
        "import PyPDF2"
      ],
      "metadata": {
        "id": "4b0vO8wC90EY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b6ec855-79a0-489a-fcf8-0c764846e9c2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seleccion del modelo"
      ],
      "metadata": {
        "id": "rmKqvPBFffbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = 'TU_CLAVE_OPEN_AI'\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o\")"
      ],
      "metadata": {
        "id": "bqGz_pf1tDqA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c05483e1-e35b-4ea0-9b75-80ccbf795ec0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-0da65a28279c>:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(model_name=\"gpt-4o\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Base Vectorial"
      ],
      "metadata": {
        "id": "rBhtSKzBfiYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
        "vector_store = InMemoryVectorStore(embeddings)"
      ],
      "metadata": {
        "id": "6dn7vewtiG-9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Este código abre un archivo PDF, lee su contenido página por página, extrae el texto de cada página, para poder combinarlo en una sola cadena"
      ],
      "metadata": {
        "id": "u6eUro5wfk-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = \"/content/drive/MyDrive/libro.pdf\"\n",
        "with open(df, 'rb') as file:\n",
        "    reader = PyPDF2.PdfReader(file)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text()\n",
        "print(text)"
      ],
      "metadata": {
        "id": "YXc103zRikru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c500ffd-0395-4bf0-f67e-eebf9774b969"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ciencia de datos desde cero\n",
            "Principios básicos con Python\n",
            "2.ª Edición\n",
            "Joel Grus\n",
            "Agradecimientos\n",
            "En primer lugar, quiero agradecer a Mike Loukides por aceptar mi\n",
            "propuesta para este libro (y por insistir en que lo reduzca a un tamaño\n",
            "razonable). Habría sido muy fácil para él decir: “¿Quién es esta persona que\n",
            "no para de enviarme correos electrónicos con capítulos de muestra, y qué\n",
            "hago para deshacerme de él?”. Pero me siento muy agradecido de que no lo\n",
            "dijera. También quisiera agradecer a mis editoras, Michele Cronin y Marie\n",
            "Beaugureau, por guiarme a lo largo del proceso de la publicación de libros y\n",
            "conseguir el libro en un estado mucho mejor de lo que jamás yo hubiera\n",
            "podido lograr por mí mismo.\n",
            "No podría haber escrito este libro si nunca hubiera aprendido ciencia de\n",
            "datos o \n",
            "data science\n",
            ", y probablemente no habría aprendido ciencia de datos si\n",
            "no hubiera sido por la influencia de Dave Hsu, Igor Tatarinov, John Rauser y\n",
            "el resto de la banda Farecast (hace ya tanto tiempo que, en ese momento, la\n",
            "ciencia de datos ¡ni siquiera se conocía con ese nombre!). Hay que\n",
            "reconocerles también el gran mérito que tienen los buenos chicos de Coursera\n",
            "y DataTau.\n",
            "Doy también las gracias a mis lectores y revisores beta. Jay Fundling\n",
            "encontró una gran cantidad de errores y resaltó muchas explicaciones no\n",
            "claras, y el libro es mucho mejor (y mucho más correcto) gracias a él.\n",
            "Debashis Shosh es un héroe por comprobar la sensatez de todas mis\n",
            "estadísticas. Andrew Musselman sugirió bajar el tono “la gente que prefiere\n",
            "R a Python son unos inmorales” del libro, lo que creo que finalmente acabó\n",
            "siendo un consejo bastante bueno. Trey Causey, Ryan Matthew Balfanz,\n",
            "Loris Mularoni, Núria Pujol, Rob Jefferson, Mary Pat Campbell, Zach Geary,\n",
            "Denise Mauldin, Jimmy O’Donnell y Wendy Grus proporcionaron también\n",
            "unos comentarios de gran valor. Gracias a todos los que leyeron la primera\n",
            "edición y ayudaron a que este libro fuera mejor. Los errores que puedan\n",
            "quedar son, por supuesto, responsabilidad mía.\n",
            "Le debo mucho a la comunidad de Twitter #datascience por exponerme a\n",
            "un montón de conceptos nuevos, presentarme a mucha gente estupenda yhacerme sentir tan manta, que se me ocurrió escribir un libro para\n",
            "compensarlo. Agradezco especialmente a Trey Causey (de nuevo) por\n",
            "recordarme (sin darse cuenta) incluir un capítulo sobre álgebra lineal y a Sean\n",
            "J. Taylor por señalar (sin darse cuenta) un par de enormes lapsus en el\n",
            "capítulo “Trabajando con datos”.\n",
            "Por encima de todo, le debo una tonelada de agradecimientos a Ganga y\n",
            "Madeline. La única cosa más difícil que escribir un libro es vivir con alguien\n",
            "que esté escribiendo un libro, y no podría haberlo logrado sin su apoyo.\n",
            "Sobre el autor\n",
            "Joel Grus es ingeniero investigador en el Allen Institute for AI.\n",
            "Anteriormente trabajó como ingeniero de software en Google y como\n",
            "científico de datos en varias \n",
            "startups\n",
            ". Vive en Seattle, donde habitualmente\n",
            "asiste a \n",
            "podcasts\n",
            " sobre ciencia de datos. Tiene un blog que actualiza\n",
            "ocasionalmente en \n",
            "joelgrus.com\n",
            ", pero se pasa el día tuiteando en\n",
            "@joelgrus\n",
            ".Índice\n",
            "Agradecimientos\n",
            "Sobre el autor\n",
            "Prefacio a la segunda edición\n",
            "Convenciones empleadas en este libro\n",
            "Uso del código de ejemplo\n",
            "Sobre la imagen de cubierta\n",
            "Prefacio a la primera edición\n",
            "Ciencia de datos o data science\n",
            "Partir de cero\n",
            "1. Introducción\n",
            "El ascenso de los datos\n",
            "¿Qué es la ciencia de datos o data science?\n",
            "Hipótesis motivadora: DataSciencester\n",
            "Localizar los conectores clave\n",
            "Científicos de datos que podría conocer\n",
            "Salarios y experiencia\n",
            "Cuentas de pago\n",
            "Temas de interés\n",
            "Sigamos adelante\n",
            "2. Un curso acelerado de Python\n",
            "El zen de Python\n",
            "Conseguir PythonEntornos virtuales\n",
            "Formato con espacios en blanco\n",
            "Módulos\n",
            "Funciones\n",
            "Cadenas\n",
            "Excepciones\n",
            "Listas\n",
            "Tuplas\n",
            "Diccionarios\n",
            "defaultdict\n",
            "Contadores\n",
            "Conjuntos\n",
            "Flujo de control\n",
            "Verdadero o falso\n",
            "Ordenar\n",
            "Comprensiones de listas\n",
            "Pruebas automatizadas y assert\n",
            "Programación orientada a objetos\n",
            "Iterables y generadores\n",
            "Aleatoriedad\n",
            "Expresiones regulares\n",
            "Programación funcional\n",
            "Empaquetado y desempaquetado de argumentos\n",
            "args y kwargs\n",
            "Anotaciones de tipos\n",
            "Cómo escribir anotaciones de tipos\n",
            "Bienvenido a DataSciencester\n",
            "Para saber más\n",
            "3. Visualizar datos\n",
            "matplotlib\n",
            "Gráficos de barras\n",
            "Gráficos de líneas\n",
            "Gráficos de dispersiónPara saber más\n",
            "4. Álgebra lineal\n",
            "Vectores\n",
            "Matrices\n",
            "Para saber más\n",
            "5. Estadística\n",
            "Describir un solo conjunto de datos\n",
            "Tendencias centrales\n",
            "Dispersión\n",
            "Correlación\n",
            "La paradoja de Simpson\n",
            "Otras advertencias sobre la correlación\n",
            "Correlación y causación\n",
            "Para saber más\n",
            "6. Probabilidad\n",
            "Dependencia e independencia\n",
            "Probabilidad condicional\n",
            "Teorema de Bayes\n",
            "Variables aleatorias\n",
            "Distribuciones continuas\n",
            "La distribución normal\n",
            "El teorema central del límite\n",
            "Para saber más\n",
            "7. Hipótesis e inferencia\n",
            "Comprobación de hipótesis estadísticas\n",
            "Ejemplo: Lanzar una moneda\n",
            "Valores p\n",
            "Intervalos de confianza\n",
            "p-hacking o dragado de datosEjemplo: Realizar una prueba A/B\n",
            "Inferencia bayesiana\n",
            "Para saber más\n",
            "8. Descenso de gradiente\n",
            "La idea tras el descenso de gradiente\n",
            "Estimar el gradiente\n",
            "Utilizar el gradiente\n",
            "Elegir el tamaño de paso adecuado\n",
            "Utilizar descenso de gradiente para ajustar modelos\n",
            "Descenso de gradiente en minilotes y estocástico\n",
            "Para saber más\n",
            "9. Obtener datos\n",
            "stdin y stdout\n",
            "Leer archivos\n",
            "Conocimientos básicos de los archivos de texto\n",
            "Archivos delimitados\n",
            "Raspado web\n",
            "HTML y su análisis\n",
            "Ejemplo: Controlar el congreso\n",
            "Utilizar API\n",
            "JSON y XML\n",
            "Utilizar una API no autenticada\n",
            "Encontrar API\n",
            "Ejemplo: Utilizar las API de Twitter\n",
            "Obtener credenciales\n",
            "Para saber más\n",
            "10. Trabajar con datos\n",
            "Explorar los datos\n",
            "Explorar datos unidimensionales\n",
            "Dos dimensionesMuchas dimensiones\n",
            "Utilizar NamedTuples\n",
            "Clases de datos\n",
            "Limpiar y preparar datos\n",
            "Manipular datos\n",
            "Redimensionar\n",
            "Un inciso: tqdm\n",
            "Reducción de dimensionalidad\n",
            "Para saber más\n",
            "11. Machine learning (aprendizaje automático)\n",
            "Modelos\n",
            "¿Qué es el machine learning?\n",
            "Sobreajuste y subajuste\n",
            "Exactitud\n",
            "El término medio entre sesgo y varianza\n",
            "Extracción y selección de características\n",
            "Para saber más\n",
            "12. k vecinos más cercanos\n",
            "El modelo\n",
            "Ejemplo: el conjunto de datos iris\n",
            "La maldición de la dimensionalidad\n",
            "Para saber más\n",
            "13. Naive Bayes\n",
            "Un filtro de spam realmente tonto\n",
            "Un filtro de spam más sofisticado\n",
            "Implementación\n",
            "A probar nuestro modelo\n",
            "Utilizar nuestro modelo\n",
            "Para saber más\n",
            "14. Regresión lineal simpleEl modelo\n",
            "Utilizar descenso de gradiente\n",
            "Estimación por máxima verosimilitud\n",
            "Para saber más\n",
            "15. Regresión múltiple\n",
            "El modelo\n",
            "Otros supuestos del modelo de mínimos cuadrados\n",
            "Ajustar el modelo\n",
            "Interpretar el modelo\n",
            "Bondad de ajuste\n",
            "Digresión: el bootstrap\n",
            "Errores estándares de coeficientes de regresión\n",
            "Regularización\n",
            "Para saber más\n",
            "16. Regresión logística\n",
            "El problema\n",
            "La función logística\n",
            "Aplicar el modelo\n",
            "Bondad de ajuste\n",
            "Máquinas de vectores de soporte\n",
            "Para saber más\n",
            "17. Árboles de decisión\n",
            "¿Qué es un árbol de decisión?\n",
            "Entropía\n",
            "La entropía de una partición\n",
            "Crear un árbol de decisión\n",
            "Ahora, a combinarlo todo\n",
            "Bosques aleatorios\n",
            "Para saber más\n",
            "18. Redes neuronalesPerceptrones\n",
            "Redes neuronales prealimentadas\n",
            "Retropropagación\n",
            "Ejemplo: Fizz Buzz\n",
            "Para saber más\n",
            "19. Deep learning (aprendizaje profundo)\n",
            "El tensor\n",
            "La capa de abstracción\n",
            "La capa lineal\n",
            "Redes neuronales como una secuencia de capas\n",
            "Pérdida y optimización\n",
            "Ejemplo: XOR revisada\n",
            "Otras funciones de activación\n",
            "Ejemplo: FizzBuzz revisado\n",
            "Funciones softmax y entropía cruzada\n",
            "Dropout\n",
            "Ejemplo: MNIST\n",
            "Guardar y cargar modelos\n",
            "Para saber más\n",
            "20. Agrupamiento (clustering)\n",
            "La idea\n",
            "El modelo\n",
            "Ejemplo: Encuentros\n",
            "Eligiendo k\n",
            "Ejemplo: agrupando colores\n",
            "Agrupamiento jerárquico de abajo a arriba\n",
            "Para saber más\n",
            "21. Procesamiento del lenguaje natural\n",
            "Nubes de palabras\n",
            "Modelos de lenguaje n-GramGramáticas\n",
            "Un inciso: muestreo de Gibbs\n",
            "Modelos de temas\n",
            "Vectores de palabras\n",
            "Redes neuronales recurrentes\n",
            "Ejemplo: utilizar una RNN a nivel de carácter\n",
            "Para saber más\n",
            "22. Análisis de redes\n",
            "Centralidad de intermediación\n",
            "Centralidad de vector propio\n",
            "Multiplicación de matrices\n",
            "Centralidad\n",
            "Grafos dirigidos y PageRank\n",
            "Para saber más\n",
            "23. Sistemas recomendadores\n",
            "Método manual\n",
            "Recomendar lo que es popular\n",
            "Filtrado colaborativo basado en usuarios\n",
            "Filtrado colaborativo basado en artículos\n",
            "Factorización de matrices\n",
            "Para saber más\n",
            "24. Bases de datos y SQL\n",
            "CREATE TABLE e INSERT\n",
            "UPDATE\n",
            "DELETE\n",
            "SELECT\n",
            "GROUP BY\n",
            "ORDER BY\n",
            "JOIN\n",
            "SubconsultasÍndices\n",
            "Optimización de consultas\n",
            "NoSQL\n",
            "Para saber más\n",
            "25. MapReduce\n",
            "Ejemplo: Recuento de palabras\n",
            "¿Por qué MapReduce?\n",
            "MapReduce, más general\n",
            "Ejemplo: Analizar actualizaciones de estado\n",
            "Ejemplo: Multiplicación de matrices\n",
            "Un inciso: Combinadores\n",
            "Para saber más\n",
            "26. La ética de los datos\n",
            "¿Qué es la ética de los datos?\n",
            "No, ahora en serio, ¿qué es la ética de datos?\n",
            "¿Debo preocuparme de la ética de los datos?\n",
            "Crear productos de datos de mala calidad\n",
            "Compromiso entre precisión e imparcialidad\n",
            "Colaboración\n",
            "Capacidad de interpretación\n",
            "Recomendaciones\n",
            "Datos sesgados\n",
            "Protección de datos\n",
            "En resumen\n",
            "Para saber más\n",
            "27. Sigamos haciendo ciencia de datos\n",
            "IPython\n",
            "Matemáticas\n",
            "No desde cero\n",
            "NumPypandas\n",
            "scikit-learn\n",
            "Visualización\n",
            "R\n",
            "Deep learning (aprendizaje profundo)\n",
            "Encontrar datos\n",
            "Haga ciencia de datos\n",
            "Hacker News\n",
            "Camiones de bomberos\n",
            "Camisetas\n",
            "Tuits en un globo terráqueo\n",
            "¿Y usted?\n",
            "CréditosPrefacio a la segunda edición\n",
            "Me siento excepcionalmente orgulloso de la primera edición de este libro.\n",
            "Ha resultado ser en buena parte el libro que yo quería que fuera. Pero varios\n",
            "años de desarrollos en ciencia de datos, de progreso en el ecosistema Python\n",
            "y de crecimiento personal como desarrollador y educador han cambiado lo\n",
            "que creo que debe ser un primer libro sobre ciencia de datos.\n",
            "En la vida no hay vuelta atrás, pero en la escritura de libros sí hay\n",
            "segundas ediciones.\n",
            "De acuerdo con esto, he reescrito todo el código y los ejemplos utilizando\n",
            "Python 3.6 (y muchas de sus funciones más recientes, como las anotaciones\n",
            "de tipos). En el libro hago continuamente énfasis en escribir código limpio.\n",
            "He reemplazado algunos de los ejemplos de la primera edición por otros más\n",
            "realistas, utilizando conjuntos de datos “reales”. He añadido nuevo material\n",
            "en temas como \n",
            "deep learning\n",
            ", estadísticas y procesamiento del lenguaje\n",
            "natural, que se corresponden con cosas con las que es más probable que los\n",
            "científicos de datos de hoy en día trabajen (también he eliminado otras\n",
            "informaciones que parecían ser menos relevantes). Y he repasado el libro de\n",
            "una forma muy concienzuda, arreglando errores, reescribiendo explicaciones\n",
            "que eran menos claras de lo que podrían ser y actualizando algunos de los\n",
            "chistes.\n",
            "La primera edición fue un gran libro, y esta edición es aún mejor.\n",
            "¡Disfrútela!\n",
            "Joel Grus\n",
            "Seattle, WA\n",
            "2019\n",
            "Convenciones empleadas en este libroEn este libro se utilizan las siguientes convenciones tipográficas:\n",
            "■\n",
            "Cursiva\n",
            ": Es un tipo que se usa para diferenciar términos anglosajones\n",
            "o de uso poco común. También se usa para destacar algún concepto.\n",
            "■\n",
            "Negrita\n",
            ": Le ayudará a localizar rápidamente elementos como las\n",
            "combinaciones de teclas.\n",
            "■\n",
            "Fuente\n",
            " \n",
            "especial\n",
            ": Nombres de botones y opciones de programas. Por\n",
            "ejemplo, \n",
            "Aceptar\n",
            " para hacer referencia a un botón con ese título.\n",
            "■\n",
            "Monoespacial\n",
            ": Utilizado para el código y dentro de los párrafos para\n",
            "hacer referencia a elementos como nombres de variables o funciones,\n",
            "bases de datos, tipos de datos, variables de entorno, declaraciones y\n",
            "palabras clave.\n",
            "También encontrará a lo largo del libro recuadros con elementos destacados\n",
            "sobre el texto normal, comunicándole de manera breve y rápida algún concepto\n",
            "relacionado con lo que está leyendo, un truco o advirtiéndole de algo.\n",
            "Aunque el termino \n",
            "“data science”\n",
            " es de uso generalizado y reconocido en todo\n",
            "el mundo, hemos decidido traducir este termino por “ciencia de datos” que es\n",
            "como se conoce a este área de conocimiento en castellano. Hemos preferido\n",
            "utilizar el termino en castellano por respeto a la riqueza de nuestra lengua y a\n",
            "los usuarios de los países de habla hispana.\n",
            "Uso del código de ejemplo\n",
            "Se puede descargar material adicional (ejemplos de código, ejercicios,\n",
            "etc.) de la página web de Anaya Multimedia\n",
            "(\n",
            "http://www.anayamultimedia.es\n",
            "). Vaya al botón \n",
            "Selecciona\n",
            " \n",
            "Complemento\n",
            "de la ficha del libro, donde podrá descargar el contenido para poder utilizarlo\n",
            "directamente. También puede descargar el material de la página web original\n",
            "del libro: \n",
            "https://github.com/joelgrus/data-science-from-scratch\n",
            ".\n",
            "Este libro ha sido creado para ayudarle en su trabajo. En general, puedeutilizar el código de ejemplo incluido en sus programas y en su\n",
            "documentación. No es necesario contactar con la editorial para solicitar\n",
            "permiso a menos que esté reproduciendo una gran cantidad del código. Por\n",
            "ejemplo, escribir un programa que utilice varios fragmentos de código\n",
            "tomados de este libro no requiere permiso. Sin embargo, vender o distribuir\n",
            "un CD-ROM de ejemplos de los libros de O’Reilly sí lo requiere. Responder\n",
            "una pregunta citando este libro y empleando textualmente código de ejemplo\n",
            "incluido en él no requiere permiso. Pero incorporar una importante cantidad\n",
            "de código de ejemplo de este libro en la documentación de su producto sí lo\n",
            "requeriría.\n",
            "Sobre la imagen de cubierta\n",
            "El animal de la portada de este libro es una perdiz nival o lagópodo alpino\n",
            "(\n",
            "Lagopus muta\n",
            "). Este robusto miembro de la familia de los faisánidos, del\n",
            "tamaño de un pollo, vive en la tundra del hemisferio norte, en las regiones\n",
            "árticas y subárticas de Eurasia y Norteamérica. Se alimenta de lo que\n",
            "encuentra en el suelo, recorriendo las praderas con sus patas bien\n",
            "emplumadas, comiendo brotes de abedul y sauce, así como semillas, flores,\n",
            "hojas y bayas. Los polluelos de perdiz nival también comen insectos.\n",
            "Los lagópodos alpinos son muy conocidos por los sorprendentes cambios\n",
            "anuales que sufre su enigmático camuflaje, habiendo evolucionado para\n",
            "mudar sus plumas blancas y pardas varias veces en el transcurso de un año y\n",
            "así adaptarse mejor a los cambiantes colores estacionales de su entorno. En\n",
            "invierno tienen plumas blancas; en primavera y otoño, cuando el manto\n",
            "nevado se mezcla con la dehesa, su plumaje mezcla los colores blanco y\n",
            "pardo y, en verano, sus plumas, pardas por completo, coinciden con la\n",
            "variada coloración de la tundra. Con este camuflaje, las hembras pueden\n",
            "incubar sus huevos, que dejan en nidos sobre el suelo, siendo casi invisibles.\n",
            "Las perdices nivales macho adultas tienen también una especie de cresta\n",
            "roja sobre sus ojos. Durante la temporada de cría la utilizan para el cortejo,\n",
            "así como en los combates contra otros machos (existen estudios que\n",
            "demuestran una correlación entre el tamaño de la cresta y el nivel detestosterona de los machos).\n",
            "La población de perdiz de las nieves está actualmente en declive, aunque\n",
            "en su hábitat natural siguen siendo comunes (pero difíciles de observar).\n",
            "Tienen muchos depredadores, entre otros el zorro ártico, el gerifalte, la\n",
            "gaviota común y la gaviota salteadora o escua. Además, con el tiempo, el\n",
            "cambio climático puede afectar negativamente a sus cambios de color\n",
            "estacionales.\n",
            "Muchos de los animales de las portadas de O’Reilly están en peligro de\n",
            "extinción; todos ellos son importantes para el mundo.\n",
            "La imagen de la portada procede de la obra \n",
            "Cassell’s Book of Birds\n",
            "(1875), de Thomas Rymer Jones.Prefacio a la primera edición\n",
            "Ciencia de datos o \n",
            "data science\n",
            "El trabajo de científico de datos ha sido denominado “el empleo más sexy\n",
            "del siglo XXI”,\n",
            "1\n",
            " presuntamente por alguien que no ha visitado nunca un\n",
            "parque de bomberos. Sin embargo, la ciencia de datos es un campo en pleno\n",
            "auge y crecimiento, y no hace falta ser muy perspicaz para encontrar analistas\n",
            "prediciendo sin descanso que, en los próximos 10 años, necesitaremos miles\n",
            "de millones de científicos de datos más de los que tenemos ahora.\n",
            "Pero ¿qué es la ciencia de datos? Después de todo, no podemos crear\n",
            "científicos de datos si no sabemos cuál es su trabajo. Según un diagrama de\n",
            "Venn,\n",
            "2\n",
            " que es en cierto modo famoso en este sector, la ciencia de datos\n",
            "reside en la intersección entre:\n",
            "■\n",
            "Habilidades informáticas a nivel de \n",
            "hacker\n",
            ".\n",
            "■\n",
            "Conocimiento de matemáticas y estadística.\n",
            "■\n",
            "Experiencia relevante.\n",
            "Aunque mi intención inicial era escribir un libro que hablara sobre estos\n",
            "tres puntos, rápidamente me di cuenta de que un tratamiento en profundidad\n",
            "de la expresión “experiencia relevante” requeriría cientos de miles de\n",
            "páginas. En ese momento decidí centrarme en los dos primeros. Mi objetivo\n",
            "es ayudar a los lectores a desarrollar las habilidades informáticas a nivel de\n",
            "hacker\n",
            " que necesitarán para empezar a trabajar en la ciencia de datos. Pero\n",
            "también es permitirles sentirse cómodos con las matemáticas y la estadística,\n",
            "que son el núcleo de la ciencia de datos.\n",
            "Quizá esta sea una aspiración demasiado elevada para un libro. La mejor\n",
            "forma de aprender las habilidades informáticas de un \n",
            "hacker\n",
            " es hackeando\n",
            "cosas. Leyendo este libro, los lectores podrán llegar a comprender bastantebien la forma en la que yo hackeo cosas, que no tiene por qué ser\n",
            "necesariamente la suya. También conocerán bastante bien algunas de las\n",
            "herramientas que utilizo, que no han de ser obligadamente las mejores para\n",
            "ellos. Y entenderán bien el modo en que yo abordo los problemas de datos,\n",
            "que tampoco tiene por qué ser el mejor modo para ellos. La intención (y la\n",
            "esperanza) es que mis ejemplos les inspiren a probar las cosas a su manera.\n",
            "Todo el código y los datos del libro están disponibles en GitHub\n",
            "3\n",
            " para que\n",
            "puedan ponerse manos a la obra.\n",
            "De forma similar, la mejor manera de aprender matemáticas es haciendo\n",
            "matemáticas. Este no es rotundamente un libro de mates, y en su mayor parte\n",
            "no estaremos “haciendo matemáticas”. Sin embargo, no se puede hacer\n",
            "ciencia de datos de verdad sin ciertos conocimientos de probabilidad,\n",
            "estadística y álgebra lineal. Esto significa que, donde corresponda,\n",
            "profundizaremos en ecuaciones matemáticas, intuición matemática, axiomas\n",
            "matemáticos y versiones caricaturizadas de grandes ideas matemáticas.\n",
            "Espero que los lectores no teman sumergirse conmigo.\n",
            "A lo largo de todo el libro también espero dar a entender que jugar con\n",
            "datos es divertido porque, bueno, ¡jugar con datos realmente lo es!\n",
            "(especialmente si lo comparamos con algunas alternativas, como hacer la\n",
            "declaración de la renta o trabajar en una mina).\n",
            "Partir de cero\n",
            "Hay muchísimas librerías de ciencia de datos, \n",
            "frameworks\n",
            ", módulos y kits\n",
            "de herramientas que implementan de forma eficaz los algoritmos y las\n",
            "técnicas de ciencia de datos más conocidas (así como las menos habituales).\n",
            "Si alguno de mis lectores llega a ser científico de datos, acabará estando\n",
            "íntimamente familiarizado con NumPy, scikit-learn, pandas y todas las demás\n",
            "librerías existentes. Son fabulosas para hacer ciencia de datos, pero también\n",
            "suponen una buena forma de empezar a hacer ciencia de datos sin realmente\n",
            "comprender lo que es.\n",
            "En este libro nos acercaremos a la ciencia de datos desde el principio de\n",
            "los principios. Esto significa que crearemos herramientas e implementaremosalgoritmos a mano para poder comprenderlos mejor. Pensé mucho en crear\n",
            "implementaciones y ejemplos que fueran claros y legibles y estuvieran bien\n",
            "comentados. En la mayoría de los casos, las herramientas que construiremos\n",
            "serán esclarecedoras, pero poco prácticas. Funcionarán bien en pequeños\n",
            "conjuntos de datos, pero no lo harán en otros “a gran escala”. Durante todo el\n",
            "libro iré señalando las librerías que se podrían utilizar para aplicar estas\n",
            "técnicas sobre conjuntos de datos más grandes. Pero aquí no las utilizaremos.\n",
            "Existe una sana discusión en torno al mejor lenguaje que se puede utilizar\n",
            "para aprender ciencia de datos. Mucha gente cree que es el lenguaje de\n",
            "programación estadístico R (de esas personas decimos que están\n",
            "equivocadas). Unas pocas personas sugieren Java o Scala. Sin embargo, en\n",
            "mi opinión, Python es la elección obvia.\n",
            "Python tiene varias características que le hacen ser ideal para aprender (y\n",
            "hacer) ciencia de datos:\n",
            "■\n",
            "Es gratuito.\n",
            "■\n",
            "Es relativamente sencillo para crear código (y en particular, de\n",
            "comprender).\n",
            "■\n",
            "Tiene muchas librerías asociadas a la ciencia de datos que son de gran\n",
            "utilidad.\n",
            "Dudo si decir que Python es mi lenguaje de programación favorito. Hay\n",
            "otros lenguajes que encuentro más agradables, mejor diseñados o\n",
            "simplemente más divertidos de utilizar. Pero, aun así, cada vez que inicio un\n",
            "nuevo proyecto de ciencia de datos, termino utilizando Python. Cada vez que\n",
            "necesito crear rápidamente un prototipo de algo que simplemente funcione,\n",
            "termino utilizando Python. Y cada vez que quiero demostrar conceptos de\n",
            "ciencia de datos de una forma clara y sencilla de comprender, acabo por\n",
            "utilizar Python. De ahí que este libro utilice Python.\n",
            "El objetivo de este libro no es enseñar Python (aunque es casi seguro que\n",
            "leyéndolo se aprende un poco). Llevaré a los lectores a lo largo de un curso\n",
            "acelerado de un capítulo de duración, que resalta las características más\n",
            "importantes para nuestros propósitos, pero, si no se sabe nada sobre\n",
            "programar en Python (o sobre programar en general), entonces quizáconvenga complementar este libro con algún tutorial de tipo “Python para\n",
            "principiantes”.\n",
            "El resto de nuestra introducción a la ciencia de datos seguirá este mismo\n",
            "enfoque, es decir, entrar en detalle donde ello parezca ser crucial o\n",
            "esclarecedor, pero en otras ocasiones dejarle al lector los detalles para que\n",
            "investigue por sí mismo (o lo busque en la Wikipedia).\n",
            "Durante años he formado a un buen número de científicos de datos.\n",
            "Aunque no todos han evolucionado para convertirse en revolucionarias\n",
            "estrellas del rock ninja de los datos, les he dejado siendo mejores científicos\n",
            "de datos de lo que eran cuando les conocí. Y yo he llegado a creer que\n",
            "cualquiera que tenga una cierta cantidad de aptitud matemática y una\n",
            "determinada habilidad para programar tiene los fundamentos necesarios para\n",
            "hacer ciencia de datos. Todo lo que se necesita es una mente curiosa,\n",
            "voluntad para trabajar duro y este libro. De ahí este libro.\n",
            "1\n",
            " \n",
            "https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century\n",
            ".\n",
            "2\n",
            " \n",
            "http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram\n",
            ".\n",
            "3\n",
            " \n",
            "https://github.com/joelgrus/data-science-from-scratch\n",
            ".1\n",
            " Introducción\n",
            "“¡Datos, datos, datos!”, gritó con impaciencia. “No puedo hacer ladrillos sin arcilla”.\n",
            "—Arthur Conan Doyle\n",
            "El ascenso de los datos\n",
            "Vivimos en un mundo que se está ahogando en datos. Los sitios web\n",
            "controlan cada clic de cada usuario. Los teléfonos inteligentes crean registros\n",
            "con la ubicación y velocidad de sus dueños cada segundo de cada día. Cada\n",
            "vez más autodidactas llevan puestos podómetros superpotentes que registran\n",
            "continuamente su ritmo cardíaco, sus hábitos de movimiento, su dieta y sus\n",
            "patrones de sueño. Los coches inteligentes recogen las costumbres en la\n",
            "conducción, las casas inteligentes recopilan hábitos de vida y los\n",
            "comerciantes inteligentes recolectan hábitos de compra. Internet representa\n",
            "un grafo de conocimiento gigante que contiene (entre otras cosas) una\n",
            "enorme enciclopedia con referencias cruzadas, bases de datos específicas de\n",
            "dominio sobre películas, música, resultados deportivos, máquinas de \n",
            "pinball\n",
            ",\n",
            "memes y cócteles, y tal cantidad de estadísticas gubernamentales (¡algunas de\n",
            "ellas casi ciertas!) de tantos gobiernos que no le caben a uno en la cabeza.\n",
            "Enterradas en estos datos están las respuestas a incontables preguntas que\n",
            "nadie nunca pensó en responder. En este libro aprenderemos a encontrarlas.\n",
            "¿Qué es la ciencia de datos o data science?\n",
            "Hay un chiste que dice que un científico de datos es alguien que conoce\n",
            "más estadísticas que un científico informático y más ciencia informática que\n",
            "un estadista (yo no diría que el chiste es bueno). De hecho, algunoscientíficos de datos son (a todos los efectos prácticos) estadistas, mientras\n",
            "que a otros apenas se les puede distinguir de un ingeniero de software.\n",
            "Algunos son expertos en \n",
            "machine learning\n",
            ", mientras que otros no llegaron a\n",
            "aprender ni tan siquiera por dónde se salía de la guardería. Algunos son\n",
            "doctores con impresionantes registros de publicaciones, mientras que otros\n",
            "nunca han leído un documento académico (aunque les dé vergüenza\n",
            "admitirlo). En resumen, da igual cómo se defina la ciencia de datos; siempre\n",
            "habrá profesionales para los que la definición es total y absolutamente\n",
            "errónea. Sin embargo, no dejaremos que eso nos impida seguir intentándolo.\n",
            "Diremos que un científico de datos es alguien que extrae conocimientos a\n",
            "partir de datos desordenados. El mundo de hoy en día está repleto de\n",
            "personas que intentan convertir datos en conocimiento.\n",
            "Por ejemplo, en el sitio web de citas OkCupid se les pide a sus miembros\n",
            "que respondan a cientos de preguntas para poder encontrar las parejas más\n",
            "adecuadas para ellos. Pero también analizan estos resultados para dar con\n",
            "preguntas aparentemente inocuas que se le puedan formular a alguien para\n",
            "averiguar la probabilidad de que esa persona vaya a dormir contigo en la\n",
            "primera cita.\n",
            "1\n",
            "Facebook suele preguntar a sus usuarios por su ciudad natal y su ubicación\n",
            "actual, aparentemente para que les resulte más fácil a sus amigos encontrarles\n",
            "y conectar con ellos. Pero también analiza estas ubicaciones para identificar\n",
            "patrones de migración globales\n",
            "2\n",
            " y para averiguar dónde viven las\n",
            "comunidades de aficionados de distintos equipos de fútbol.\n",
            "3\n",
            "La cadena americana de grandes almacenes Target controla las compras e\n",
            "interacciones de sus usuarios, tanto en línea como en sus tiendas físicas.\n",
            "Igualmente realiza modelos predictivos\n",
            "4\n",
            " con los datos para averiguar cuáles\n",
            "de sus clientas están embarazadas y así venderles con más facilidad productos\n",
            "relacionados con el bebé.\n",
            "En 2012, la campaña de Obama empleó a muchísimos científicos que\n",
            "investigaron con datos y experimentaron con ellos para identificar a los\n",
            "votantes que necesitaban más atención, eligiendo los métodos perfectos de\n",
            "recaudación de fondos dirigidos a determinados donantes y poniendo todos\n",
            "los esfuerzos de obtención del voto allí donde era más probable que fueran\n",
            "útiles. En 2016, la campaña Trump probó una asombrosa variedad deanuncios \n",
            "online\n",
            "5\n",
            " y analizó los datos para averiguar lo que funcionaba y lo\n",
            "que no. Lo último antes de resultar cansino: algunos científicos de datos\n",
            "utilizan también de vez en cuando sus habilidades para cosas buenas, por\n",
            "ejemplo, para que el gobierno sea más eficaz\n",
            "6\n",
            " o para ayudar a los sin techo.\n",
            "7\n",
            "Pero sin duda tampoco resultan perjudicados si lo que les gusta es buscar la\n",
            "mejor manera de conseguir que la gente haga clic en anuncios.\n",
            "Hipótesis motivadora: DataSciencester\n",
            "¡Felicidades! Le acaban de contratar para dirigir el departamento de\n",
            "Ciencia de Datos de DataSciencester, la red social para científicos de datos.\n",
            "Nota: \n",
            "Cuando escribí la primera edición de este libro, pensé que “una red\n",
            "social para científicos de datos” era una invención que podía resultar absurda,\n",
            "pero a la vez divertida. Desde entonces, se han creado redes sociales para\n",
            "científicos de datos de verdad, y sus creadores les han sacado a capitalistas de\n",
            "riesgo mucho más dinero del que yo obtuve con mi libro. Probablemente esto\n",
            "suponga una valiosa lección sobre inventos absurdos de ciencia de datos o la\n",
            "publicación de libros.\n",
            "A pesar de estar destinada a científicos de datos, DataSciencester nunca ha\n",
            "invertido realmente en crear sus propios métodos de ciencia de datos (para ser\n",
            "justo, nunca ha invertido realmente en crear siquiera su producto). Esto será\n",
            "lo que hagamos aquí. A lo largo del libro, aprenderemos conceptos de ciencia\n",
            "de datos resolviendo problemas con los que uno se puede encontrar en el\n",
            "trabajo. Algunas veces veremos datos suministrados específicamente por los\n",
            "usuarios, otras veces examinaremos datos generados por sus interacciones\n",
            "con sitios web, y en otras ocasiones incluso trataremos datos de experimentos\n",
            "que nosotros mismos diseñaremos.\n",
            "Como DataSciencester sufre terriblemente el síndrome NIH (\n",
            "Not invented\n",
            "here\n",
            ", no inventado aquí), crearemos nuestras propias herramientas desde\n",
            "cero. Al final, el lector terminará comprendiendo bastante bien los\n",
            "fundamentos de la ciencia de datos y podrá aplicar sus habilidades en unacompañía con una premisa menos inestable o en cualquier otro problema que\n",
            "le interese.\n",
            "Bienvenidos a bordo y ¡buena suerte! (se pueden llevar vaqueros los\n",
            "viernes y el baño está al fondo a la derecha).\n",
            "Localizar los conectores clave\n",
            "Es el primer día de trabajo en DataSciencester, y el vicepresidente de\n",
            "Redes tiene muchas preguntas sobre los usuarios. Hasta ahora no tenía nadie\n",
            "a quien preguntar, así que está muy emocionado de tener alguien nuevo en el\n",
            "equipo.\n",
            "En particular, le interesa identificar quiénes son los “conectores clave” de\n",
            "todos los científicos de datos. Para ello proporciona un volcado de la red\n",
            "completa de DataSciencester (en la vida real, la gente no suele pasar los datos\n",
            "que uno necesita; el capítulo 9 está dedicado a obtener datos).\n",
            "¿Qué aspecto tiene este volcado de datos? Consiste en una lista de\n",
            "usuarios, cada uno representado por un \n",
            "dict\n",
            " que contiene su \n",
            "id\n",
            " (que es un\n",
            "número) y su \n",
            "name\n",
            " (que, en una de esas fabulosas conjunciones planetarias,\n",
            "concuerda con su \n",
            "id\n",
            "):\n",
            "users = [\n",
            "{ \"id\": 0, \"name\": \"Hero\" },\n",
            "{ \"id\": 1, \"name\": \"Dunn\" },\n",
            "{ \"id\": 2, \"name\": \"Sue\" },\n",
            "{ \"id\": 3, \"name\": \"Chi\" },\n",
            "{ \"id\": 4, \"name\": \"Thor\" },\n",
            "{ \"id\": 5, \"name\": \"Clive\" },\n",
            "{ \"id\": 6, \"name\": \"Hicks\" },\n",
            "{ \"id\": 7, \"name\": \"Devin\" },\n",
            "{ \"id\": 8, \"name\": \"Kate\" },\n",
            "{ \"id\": 9, \"name\": \"Klein\" }\n",
            "]\n",
            "También ofrece los datos de “amistad” (\n",
            "friendship\n",
            "), representados como\n",
            "una lista de pares de identificadores:friendship_pairs =\n",
            "[(0, 1), (0, 2), (1, 2), (1, 3), (2, 3), (3, 4),\n",
            "(4, 5), (5, 6), (5, 7), (6, 8), (7, 8), (8, 9)]\n",
            "Por ejemplo, la tupla (0, 1) indica que los científicos de datos con \n",
            "id\n",
            " 0\n",
            "(Hero) e \n",
            "id\n",
            " 1 (Dunn) son amigos. La red aparece representada en la figura\n",
            "1.1.\n",
            "Figura 1.1. \n",
            "La red de DataSciencester.\n",
            "Representar las amistades como una lista de pares no es la forma más\n",
            "sencilla de trabajar con ellas. Para encontrar todas las amistades por usuario,\n",
            "hay que pasar repetidamente por cada par buscando pares que contengan 1. Si\n",
            "hubiera muchos pares, el proceso tardaría mucho en realizarse.\n",
            "En lugar de ello, vamos a crear un \n",
            "dict\n",
            " en el que las claves sean \n",
            "id\n",
            " de\n",
            "usuario y los valores sean listas de \n",
            "id\n",
            " de amigos (consultar cosas en un \n",
            "dict\n",
            "es muy rápido).\n",
            "Nota: \n",
            "No conviene obsesionarse demasiado con los detalles del código ahora\n",
            "mismo. En el capítulo 2 haremos un curso acelerado de Python. Por ahora,\n",
            "basta con hacerse una idea general de lo que estamos haciendo.\n",
            "Aún tendremos que consultar cada par para crear el \n",
            "dict\n",
            ", pero solamente\n",
            "hay que hacerlo una vez y, después, las consultas no costarán nada:\n",
            "# Inicializar el dict con una lista vacía para cada id de usuario:\n",
            "friendships = {user[\"id\"]: [] for user in users}\n",
            "# Y pasar por todos los pares de amistad para llenarlo:for i, j in friendship_pairs:\n",
            "friendships[i].append(j)\n",
            "# Añadir j como un amigo del usuario i\n",
            "friendships[j].append(i)\n",
            "# Añadir i como un amigo del usuario j\n",
            "Ahora que ya tenemos las amistades en un \n",
            "dict\n",
            ", podemos formular\n",
            "fácilmente preguntas sobre nuestro grafo, como por ejemplo: “¿Cuál es el\n",
            "número medio de conexiones?”.\n",
            "Primero, hallamos el número total de conexiones sumando las longitudes\n",
            "de todas las listas \n",
            "friends\n",
            ":\n",
            "def number_of_friends(user):\n",
            "\"\"\"How many friends does _user_ have?\"\"\"\n",
            "user_id = user[\"id\"]\n",
            "friend_ids = friendships[user_id]\n",
            "return len(friend_ids)\n",
            "total_connections = sum(number_of_friends(user)\n",
            "for user in users)\n",
            "# 24\n",
            "Y, después, simplemente dividimos por el número de usuarios:\n",
            "num_users = len(users)\n",
            "# longitud de la lista de\n",
            "usuarios\n",
            "avg_connections = total_connections /\n",
            "num_users\n",
            "# 24 / 10 == 2,4\n",
            "También es sencillo encontrar las personas más conectadas (las que tienen\n",
            "la mayor cantidad de amigos).\n",
            "Como no hay muchos usuarios, simplemente podemos ordenarlos de “la\n",
            "mayor cantidad de amigos” a “la menor cantidad de amigos”:\n",
            "# Crea una lista (user_id, number_of_friends).\n",
            "num_friends_by_id = [(user[\"id\"], number_of_friends(user))\n",
            "for user in users]\n",
            "num_friends_by_id.sort(\n",
            "# Ordena la lista\n",
            "key=lambda id_and_friends: id_and_friends[1],\n",
            "# por num_friends\n",
            "reverse=True)\n",
            "# del mayor al menor\n",
            "# Cada par es (user_id, num_friends):\n",
            "# [(1, 3), (2, 3), (3, 3), (5, 3), (8, 3),\n",
            "# (0, 2), (4, 2), (6, 2), (7, 2), (9, 1)]Una manera de pensar en lo que hemos hecho es como en una forma de\n",
            "identificar a las personas que son de alguna manera centrales para la red. En\n",
            "realidad, lo que acabamos de calcular es la métrica de la centralidad de grado\n",
            "de la red (véase la figura 1.2).\n",
            "Figura 1.2. \n",
            "La red de DataSciencester dimensionada por grado.\n",
            "Esto tiene la virtud de ser bastante fácil de calcular, pero no siempre da los\n",
            "resultados que se desean o esperan. Por ejemplo, en la red de DataSciencester\n",
            "Thor (\n",
            "id\n",
            " 4) solo tiene dos conexiones, mientras que Dunn (\n",
            "id\n",
            " 1) tiene tres.\n",
            "Ya cuando miramos a la red, parece intuitivo que Thor debería estar ubicado\n",
            "en una posición más central. En el capítulo 22 investigaremos las redes con\n",
            "más detalle y veremos nociones más complejas de centralidad, que pueden\n",
            "corresponderse más o menos con nuestra intuición.\n",
            "Científicos de datos que podría conocer\n",
            "Mientras aún está rellenando el papeleo de su nueva contratación, la\n",
            "vicepresidenta de Fraternización pasa por su despacho. Quiere fomentar más\n",
            "conexiones entre sus miembros y le pide que diseñe un sugeridor “Científicos\n",
            "de datos que podría conocer”.\n",
            "Lo primero que se le ocurre es sugerir que los usuarios podrían conocer a\n",
            "los amigos de sus amigos. Así que escribe un poco de código para pasar\n",
            "varias veces por sus amigos y recoger los amigos de los amigos:\n",
            "def foaf_ids_bad(user):\"\"\"foaf is short for \"friend of a friend\" \"\"\"\n",
            "return [foaf_id\n",
            "for friend_id in friendships[user[\"id\"]]\n",
            "for foaf_id in friendships[friend_id]]\n",
            "Cuando aplicamos esto sobre \n",
            "users[0]\n",
            " (Hero), produce lo siguiente:\n",
            "[0, 2, 3, 0, 1, 3]\n",
            "Incluye el usuario 0 dos veces, ya que Hero es de hecho amigo de sus dos\n",
            "amigos. Incluye los usuarios 1 y 2, aunque ambos ya son amigos de Hero. Y\n",
            "también incluye el usuario 3 dos veces, ya que se puede llegar hasta Chi a\n",
            "través de dos amigos distintos:\n",
            "print(friendships[0]) # [1, 2]\n",
            "print(friendships[1]) # [0, 2, 3]\n",
            "print(friendships[2]) # [0, 1, 3]\n",
            "Saber que las personas son amigos de amigos de diversas maneras parece\n",
            "ser información interesante, de modo que quizá en su lugar podríamos\n",
            "producir un contador de amigos mutuos. Y deberíamos probablemente\n",
            "excluir gente ya conocida por el usuario:\n",
            "from collections import Counter\n",
            "# no cargado inicialmente\n",
            "def friends_of_friends(user):\n",
            "user_id = user[“id”]\n",
            "return Counter(\n",
            "foaf_id\n",
            "for friend_id in friendships[user_id]\n",
            "# Para cada uno de mis amigos,\n",
            "for foaf_id in friendships[friend_id]\n",
            "# encuentra sus amigos\n",
            "if foaf_id != user_id\n",
            "# que no son yo\n",
            "and foaf_id not in\n",
            "friendships[user_id]\n",
            "# y no son mis amigos\n",
            ")\n",
            "print(friends_of_friends(users[3]))\n",
            "# Contador({0: 2, 5: 1})\n",
            "Esto le dice correctamente a Chi (\n",
            "id\n",
            " 3) que tiene dos amigos mutuos con\n",
            "Hero (\n",
            "id\n",
            " 0), pero solo uno con Clive (\n",
            "id\n",
            " 5).\n",
            "Uno, como científico de datos, sabe que también se puede disfrutar\n",
            "conociendo amigos con intereses comunes (este es un buen ejemplo delaspecto “experiencia relevante” de la ciencia de datos). Tras preguntar por\n",
            "ahí, conseguimos estos datos, como una lista de pares (\n",
            "user_id\n",
            ", \n",
            "interest\n",
            "):\n",
            "interests = [\n",
            "(0, \"Hadoop\"), (0, \"Big Data\"), (0, \"HBase\"), (0, \"Java\"),\n",
            "(0, \"Spark\"), (0, \"Storm\"), (0, \"Cassandra\"),\n",
            "(1, \"NoSQL\"), (1, \"MongoDB\"), (1, \"Cassandra\"), (1, \"HBase\"),\n",
            "(1, \"Postgres\"), (2, \"Python\"), (2, \"scikit-learn\"), (2, \"scipy\"),\n",
            "(2, \"numpy\"), (2, \"statsmodels\"), (2, \"pandas\"), (3, \"R\"), (3, \"Python\"),\n",
            "(3, \"statistics\"), (3, \"regression\"), (3, \"probability\"),\n",
            "(4, \"machine learning\"), (4, \"regression\"), (4, \"decision trees\"),\n",
            "(4, \"libsvm\"), (5, \"Python\"), (5, \"R\"), (5, \"Java\"), (5, \"C++\"),\n",
            "(5, \"Haskell\"), (5, \"programming languages\"), (6, \"statistics\"),\n",
            "(6, \"probability\"), (6, \"mathematics\"), (6, \"theory\"),\n",
            "(7, \"machine learning\"), (7, \"scikit-learn\"), (7, \"Mahout\"),\n",
            "(7, \"neural networks\"), (8, \"neural networks\"), (8, \"deep learning\"),\n",
            "(8, \"Big Data\"), (8, \"artificial intelligence\"), (9, \"Hadoop\"),\n",
            "(9, \"Java\"), (9, \"MapReduce\"), (9, \"Big Data\")\n",
            "]\n",
            "Por ejemplo, Hero (\n",
            "id\n",
            " 0) no tiene amigos comunes con Klein (\n",
            "id\n",
            " 9), pero\n",
            "ambos comparten intereses en Java y Big Data.\n",
            "Es fácil crear una función que encuentre usuarios con un determinado\n",
            "interés:\n",
            "def data_scientists_who_like(target_interest):\n",
            "\"\"\"Find the ids of all users who like the target interest.\"\"\"\n",
            "return [user_id\n",
            "for user_id, user_interest in interests\n",
            "if user_interest == target_interest]\n",
            "Esto funciona, pero tiene que examinar la lista completa de aficiones en\n",
            "cada búsqueda. Si tenemos muchos usuarios e intereses (o si simplemente\n",
            "queremos hacer muchas búsquedas), es probablemente mejor que nos\n",
            "dediquemos a crear un índice de intereses a usuarios:\n",
            "from collections import defaultdict\n",
            "# Las claves son intereses, los valores son listas de user_ids con ese interés\n",
            "user_ids_by_interest = defaultdict(list)\n",
            "for user_id, interest in interests:user_ids_by_interest[interest].append(user_id)\n",
            "Y otro de usuarios a intereses:\n",
            "# Las claves son user_ids, los valores son listas de intereses para ese\n",
            "user_id.\n",
            "interests_by_user_id = defaultdict(list)\n",
            "for user_id, interest in interests:\n",
            "interests_by_user_id[user_id].append(interest)\n",
            "Ahora es fácil averiguar quién tiene el mayor número de intereses en\n",
            "común con un determinado usuario:\n",
            "■\n",
            "Pasamos varias veces por los intereses del usuario.\n",
            "■\n",
            "Para cada interés, volvemos a pasar en repetidas ocasiones por los\n",
            "demás usuarios que tienen ese mismo interés.\n",
            "■\n",
            "Contamos las veces que vemos cada uno de los usuarios.\n",
            "En código:\n",
            "def most_common_interests_with(user):\n",
            "return Counter(\n",
            "interested_user_id\n",
            "for interest in interests_by_user_id[user[\"id\"]]\n",
            "for interested_user_id in user_ids_by_interest[interest]\n",
            "if interested_user_id != user[\"id\"]\n",
            ")\n",
            "Después, podríamos utilizar esto para crear una función “Científicos de\n",
            "datos que podría conocer” más completa basándonos en una combinación de\n",
            "amigos mutuos e intereses comunes. Exploraremos estos tipos de aplicación\n",
            "en el capítulo 23.\n",
            "Salarios y experiencia\n",
            "Justo cuando se iba a comer, el vicepresidente de Relaciones Públicas lepregunta si le puede suministrar datos curiosos sobre lo que ganan los\n",
            "científicos de datos. Los datos de sueldos son, por supuesto, confidenciales,\n",
            "pero se las arregla para conseguir un conjunto de datos anónimo que contiene\n",
            "el salario (\n",
            "salary\n",
            ") de cada usuario (en dólares) y su antigüedad en el puesto\n",
            "(\n",
            "tenure\n",
            ") como científico de datos (en años):\n",
            "salaries_and_tenures = [(83000, 8.7), (88000, 8.1),\n",
            "(48000, 0.7), (76000, 6),\n",
            "(69000, 6.5), (76000, 7.5),\n",
            "(60000, 2.5), (83000, 10),\n",
            "(48000, 1.9), (63000, 4.2)]\n",
            "El primer paso natural es trazar los datos en un gráfico (cosa que veremos\n",
            "cómo hacer en el capítulo 3). La figura 1.3 muestra los resultados.\n",
            "Figura 1.3. \n",
            "Salario por años de experiencia.\n",
            "Parece claro que la gente con más experiencia tiende a ganar más. ¿Cómo\n",
            "se puede convertir esto en un dato curioso? Lo primero que se nos ocurre esmirar el salario medio por antigüedad:\n",
            "# Las claves son años, los valores son listas de los salarios por antigüedad.\n",
            "salary_by_tenure = defaultdict(list)\n",
            "for salary, tenure in salaries_and_tenures:\n",
            "salary_by_tenure[tenure].append(salary)\n",
            "# Las claves son años, cada valor es el salario medio para dicha antigüedad.\n",
            "average_salary_by_tenure = {\n",
            "tenure: sum(salaries) / len(salaries)\n",
            "for tenure, salaries in salary_by_tenure.items()\n",
            "}\n",
            "Resulta que esto no es especialmente útil, ya que ninguno de los usuarios\n",
            "tiene la misma antigüedad en el puesto de trabajo, lo que significa que\n",
            "simplemente estamos informando de los salarios individuales de los usuarios:\n",
            "{0.7: 48000.0,\n",
            "1.9: 48000.0,\n",
            "2.5: 60000.0,\n",
            "4.2: 63000.0,\n",
            "6: 76000.0,\n",
            "6.5: 69000.0,\n",
            "7.5: 76000.0,\n",
            "8.1: 88000.0,\n",
            "8.7: 83000.0,\n",
            "10: 83000.0}\n",
            "Podría ser más útil poner los años de antigüedad en un \n",
            "bucket\n",
            ":\n",
            "def tenure_bucket(tenure):\n",
            "if tenure < 2:\n",
            "return \"less than two\"\n",
            "elif tenure < 5:\n",
            "return \"between two and five\"\n",
            "else:\n",
            "return \"more than five\"\n",
            "Entonces podemos agrupar los salarios correspondientes a cada \n",
            "bucket\n",
            ":# Las claves son buckets de años de antigüedad, los valores son listas de\n",
            "salarios para bucket\n",
            "salary_by_tenure_bucket = defaultdict(list)\n",
            "for salary, tenure in salaries_and_tenures:\n",
            "bucket = tenure_bucket(tenure)\n",
            "salary_by_tenure_bucket[bucket].append(salary)\n",
            "Y, por último, calcular el salario medio para cada grupo:\n",
            "# Las claves son buckets de años de antigüedad, los valores son el salario\n",
            "medio para bucket\n",
            "average_salary_by_bucket = {\n",
            "tenure_bucket: sum(salaries) / len(salaries)\n",
            "for tenure_bucket, salaries in salary_by_tenure_bucket.items()\n",
            "}\n",
            "Lo que es más interesante:\n",
            "{‘between two and five’: 61500.0,\n",
            "‘less than two’: 48000.0,\n",
            "‘more than five’: 79166.66666666667}\n",
            "Y ya tenemos nuestra proclama: “Los científicos de datos con más de\n",
            "cinco años de experiencia ganan un 65 % más que los científicos de datos con\n",
            "poca experiencia o ninguna”.\n",
            "Pero hemos elegido los \n",
            "buckets\n",
            " de una forma bastante aleatoria. Lo que\n",
            "realmente haríamos es hacer alguna declaración sobre el efecto que tiene en\n",
            "el salario (en promedio) tener un año adicional de experiencia. Además de\n",
            "conseguir un dato curioso más eficiente, esto nos permite hacer predicciones\n",
            "sobre salarios que no conocemos. Exploraremos esta idea en el capítulo 14.\n",
            "Cuentas de pago\n",
            "Cuando vuelve a su puesto de trabajo, la vicepresidenta de Finanzas le\n",
            "está esperando. Quiere entender mejor qué usuarios pagan por las cuentas y\n",
            "cuáles no (ella conoce sus nombres, pero esa información no es\n",
            "especialmente procesable).Se da cuenta de que parece haber una correspondencia entre los años de\n",
            "experiencia y las cuentas de pago:\n",
            "0.7 paid\n",
            "1.9 unpaid\n",
            "2.5 paid\n",
            "4.2 unpaid\n",
            "6.0 unpaid\n",
            "6.5 unpaid\n",
            "7.5 unpaid\n",
            "8.1 unpaid\n",
            "8.7 paid\n",
            "10.0 paid\n",
            "Los usuarios con muy pocos y muchos años de experiencia tienden a\n",
            "pagar; los usuarios con cantidades de experiencia medias no lo hacen. Según\n",
            "esto, si quería crear un modelo (aunque sin duda no son datos suficientes en\n",
            "los que basarlo), podría intentar predecir “de pago” para usuarios con muy\n",
            "pocos y muchos años de experiencia y “no de pago” para usuarios con\n",
            "cantidades de experiencia medias:\n",
            "def predict_paid_or_unpaid(years_experience):\n",
            "if years_experience < 3.0:\n",
            "return \"paid\"\n",
            "elif years_experience < 8.5:\n",
            "return \"unpaid\"\n",
            "else:\n",
            "return \"paid\"\n",
            "Por supuesto, esto lo hemos calculado a ojo.\n",
            "Con más datos (y más matemáticas), podríamos crear un modelo que\n",
            "predijera la probabilidad de que un usuario pagara, basándonos en sus años\n",
            "de experiencia. Investigaremos este tipo de problema en el capítulo 16.\n",
            "Temas de interés\n",
            "A medida que se va acercando el final de su primer día, la vicepresidentade Estrategia de Contenidos le pide datos sobre los temas que más interesan a\n",
            "los usuarios, de forma que pueda planificar adecuadamente el calendario de\n",
            "su blog. Ya disponemos de los datos sin procesar del proyecto del sugeridor\n",
            "de amigos:\n",
            "interests = [\n",
            "(0, \"Hadoop\"), (0, \"Big Data\"), (0, \"HBase\"), (0, \"Java\"),\n",
            "(0, \"Spark\"), (0, \"Storm\"), (0, \"Cassandra\"),\n",
            "(1, \"NoSQL\"), (1, \"MongoDB\"), (1, \"Cassandra\"), (1, \"HBase\"),\n",
            "(1, \"Postgres\"), (2, \"Python\"), (2, \"scikit-learn\"), (2, \"scipy\"),\n",
            "(2, \"numpy\"), (2, \"statsmodels\"), (2, \"pandas\"), (3, \"R\"), (3, \"Python\"),\n",
            "(3, \"statistics\"), (3, \"regression\"), (3, \"probability\"),\n",
            "(4, \"machine learning\"), (4, \"regression\"), (4, \"decision trees\"),\n",
            "(4, \"libsvm\"), (5, \"Python\"), (5, \"R\"), (5, \"Java\"), (5, \"C++\"),\n",
            "(5, \"Haskell\"), (5, \"programming languages\"), (6, \"statistics\"),\n",
            "(6, \"probability\"), (6, \"mathematics\"), (6, \"theory\"),\n",
            "(7, \"machine learning\"), (7, \"scikit-learn\"), (7, \"Mahout\"),\n",
            "(7, \"neural networks\"), (8, \"neural networks\"), (8, \"deep learning\"),\n",
            "(8, \"Big Data\"), (8, \"artificial intelligence\"), (9, \"Hadoop\"),\n",
            "(9, \"Java\"), (9, \"MapReduce\"), (9, \"Big Data\")\n",
            "]\n",
            "Una manera sencilla (aunque no especialmente apasionante) de encontrar\n",
            "los intereses más populares es contando las palabras:\n",
            "1\n",
            ".\n",
            "Ponemos en minúsculas todos los \n",
            "hobbies\n",
            " (ya que habrá usuarios que\n",
            "los pongan en mayúscula y otros en minúscula).\n",
            "2\n",
            ".\n",
            "Los dividimos en palabras.\n",
            "3\n",
            ".\n",
            "Contamos los resultados.\n",
            "En código:\n",
            "words_and_counts = Counter(word\n",
            "for user, interest in interests\n",
            "for word in interest.lower().split())\n",
            "Así es posible hacer fácilmente un listado con las palabras que aparecen\n",
            "más de una vez:\n",
            "for word, count in words_and_counts.most_common():if count > 1:\n",
            "print(word, count)\n",
            "Lo que da los resultados esperados (a menos que se suponga que “scikit-\n",
            "learn” ha quedado dividido en dos palabras, en cuyo caso no los da).\n",
            "learning 3\n",
            "java 3\n",
            "python 3\n",
            "big 3\n",
            "data 3\n",
            "hbase 2\n",
            "regression 2\n",
            "cassandra 2\n",
            "statistics 2\n",
            "probability 2\n",
            "hadoop 2\n",
            "networks 2\n",
            "machine 2\n",
            "neural 2\n",
            "scikit-learn 2\n",
            "r 2\n",
            "En el capítulo 21 veremos maneras más sofisticadas de extraer temas de\n",
            "datos.\n",
            "Sigamos adelante\n",
            "¡Ha sido un día bastante fructuoso! Cansado, sale del edificio\n",
            "sigilosamente, antes de que alguien pueda pedirle algo más. Descanse bien\n",
            "esta noche, porque mañana tendrá su sesión de orientación al empleado (sí,\n",
            "ha tenido un completo día de trabajo sin tan siquiera pasar por orientación al\n",
            "empleado; háblelo con RR. HH.).\n",
            "1\n",
            " \n",
            "https://theblog.okcupid.com/the-most-important-questions-on-okcupid-\n",
            "32e80bad0854\n",
            ".2\n",
            " \n",
            "https://www.facebook.com/notes/10158928002728415/\n",
            ".\n",
            "3\n",
            " \n",
            "https://www.facebook.com/notes/10158927994943415/\n",
            ".\n",
            "4\n",
            " \n",
            "https://www.nytimes.com/2012/02/19/magazine/shopping-habits.html\n",
            ".\n",
            "5\n",
            " \n",
            "https://www.wired.com/2016/11/facebook-won-trump-election-not-just-fake-news/\n",
            ".\n",
            "6\n",
            " \n",
            "https://www.marketplace.org/2014/08/22/tech/beyond-ad-clicks-using-big-data-\n",
            "social-good\n",
            ".\n",
            "7\n",
            " \n",
            "https://dssg.uchicago.edu/2014/08/20/tracking-the-paths-of-homelessness/\n",
            ".2\n",
            " Un curso acelerado de\n",
            "Python\n",
            "La gente sigue loca por Python tras veinticinco años, cosa que me resulta difícil de\n",
            "creer.\n",
            "—Michael Palin\n",
            "Todos los empleados nuevos de DataSciencester tienen que pasar\n",
            "obligadamente por orientación al empleado, cuya parte más interesante es un\n",
            "curso acelerado de Python.\n",
            "No se trata de un tutorial extenso, sino que está destinado a destacar las\n",
            "partes del lenguaje que serán más importantes para nosotros (algunas de las\n",
            "cuales no suelen ser el objetivo de los tutoriales de Python habituales). Si\n",
            "nunca había utilizado Python antes, probablemente quiera complementar esto\n",
            "con algún tipo de tutorial para principiante.\n",
            "El zen de Python\n",
            "Python tiene una descripción un poco zen de sus principios de diseño,\n",
            "1\n",
            "que se pueden encontrar dentro del propio intérprete de Python escribiendo\n",
            "import\n",
            " \n",
            "this\n",
            " (importar esto). Uno de los más discutidos es:\n",
            "There should be one—and preferably only one—obvious way to do it.\n",
            "(Solo debería haber una, y preferiblemente solo una, forma obvia de hacerlo).\n",
            "El código escrito de acuerdo con esta forma “obvia” (que no tiene por qué\n",
            "serlo en absoluto para un principiante) se describe a menudo como\n",
            "“\n",
            "pythonic\n",
            "” (emplearemos la traducción “pitónico” en castellano, aunque\n",
            "suene un poco raro). Aunque este libro no trata de Python, de vez en cuandocontrastaremos formas pitónicas y no pitónicas de realizar las mismas cosas,\n",
            "y en general tenderemos más a emplear las soluciones pitónicas a nuestros\n",
            "problemas.\n",
            "Otros principios aluden a lo estético:\n",
            "Beautiful is better than ugly. Explicit is better than implicit. Simple is better\n",
            "than complex.\n",
            "(Lo bello es mejor que lo feo. Lo explícito es mejor que lo implícito. Lo simple es mejor\n",
            "que lo complejo).\n",
            "Y representan ideales por los que lucharemos en nuestro código.\n",
            "Conseguir Python\n",
            "Nota: \n",
            "Como las instrucciones de instalación de las cosas pueden cambiar,\n",
            "mientras que los libros impresos no, se pueden encontrar instrucciones\n",
            "actualizadas para instalar Python en el repositorio GitHub del libro.\n",
            "2\n",
            "Conviene revisar las del sitio web si las incluidas aquí no funcionan.\n",
            "Se puede descargar Python desde Python.org.\n",
            "3\n",
            " Pero, si todavía no se\n",
            "dispone de él, es más recomendable instalar la distribución Anaconda,\n",
            "4\n",
            " que\n",
            "ya incluye la mayoría de las librerías necesarias para hacer ciencia de datos.\n",
            "Cuando escribí la primera versión de este volumen, Python 2.7 seguía\n",
            "siendo el preferido por la mayoría de los científicos de datos. Por eso la\n",
            "primera edición del libro estaba basada en esta versión.\n",
            "Pero, en los últimos años, casi todo el mundo ha migrado a Python 3. Las\n",
            "últimas versiones de Python tienen muchas funciones que permiten escribir\n",
            "código limpio con mayor facilidad, y nos aprovecharemos de otras que solo\n",
            "están disponibles en la versión 3.6 de Python o posterior, lo que significa que\n",
            "habría que conseguir esta versión más reciente de Python (además, muchas\n",
            "librerías útiles ya no soportan Python 2.7; otra razón más para cambiar).Entornos virtuales\n",
            "Ya desde el próximo capítulo utilizaremos la librería matplotlib para\n",
            "generar gráficas y diagramas o tablas. Esta librería no forma parte de Python;\n",
            "hay que instalarla por separado. Todos los proyectos de ciencia de datos que\n",
            "realicemos requerirán alguna combinación de librerías externas, a veces con\n",
            "versiones específicas que difieren de las empleadas en otros proyectos. Si\n",
            "tuviéramos una única instalación de Python, estas librerías entrarían en\n",
            "conflicto y provocarían todo tipo de problemas.\n",
            "La solución estándar es utilizar entornos virtuales, es decir, entornos\n",
            "aislados de Python que mantienen sus propias versiones de librerías del\n",
            "lenguaje (y, dependiendo del modo en que se configure el entorno, del\n",
            "lenguaje en sí mismo).\n",
            "Recomiendo instalar la distribución de Python denominada Anaconda, de\n",
            "modo que en esta sección explicaré cómo funcionan los entornos de\n",
            "Anaconda. También se puede utilizar el módulo venv integrado\n",
            "5\n",
            " o instalar\n",
            "virtualenv,\n",
            "6\n",
            " en cuyo caso habría que seguir sus instrucciones.\n",
            "Para crear un entorno virtual (Anaconda) basta con hacer lo siguiente:\n",
            "# crear un entorno Python 3.6 llamado \"dsfs\"\n",
            "conda create -n dsfs python=3.6\n",
            "Siguiendo los mensajes, logramos un entorno virtual llamado “dsfs”, con\n",
            "estas instrucciones:\n",
            "#\n",
            "# Para activar este entorno utilice:\n",
            "# > source activate dsfs\n",
            "#\n",
            "# Para desactivar un entorno activo utilice:\n",
            "# > source deactivate\n",
            "#\n",
            "Como se indica, el entorno se activa utilizando:\n",
            "source activate dsfsEn ese punto, la línea de comandos debería cambiar para indicar el\n",
            "entorno activo. En mi MacBook aparece ahora lo siguiente en la línea de\n",
            "comandos:\n",
            "(dsfs) ip-10-0-0-198:~ joelg$\n",
            "Siempre que este entorno esté activo, las librerías se instalarán únicamente\n",
            "en el entorno dsfs. Cuando termine este libro y cree sus propios proyectos,\n",
            "debería crear sus propios entornos para ellos.\n",
            "Ahora que tenemos el entorno, podemos instalar IPython,\n",
            "7\n",
            " que es un \n",
            "shell\n",
            "o intérprete de Python completo:\n",
            "python -m pip install ipython\n",
            "Nota:\n",
            " Anaconda incluye su propio gestor de paquetes, \n",
            "conda\n",
            ", pero se puede\n",
            "utilizar tranquilamente el gestor de paquetes estándar de Python, \n",
            "pip\n",
            ", que es lo\n",
            "que haremos.\n",
            "El resto de este libro supondrá que se ha creado y activado dicho entorno\n",
            "virtual de Python 3.6 (aunque le puede llamar como le parezca), y los últimos\n",
            "capítulos podrían hacer referencia a las librerías cuya instalación indiqué en\n",
            "anteriores capítulos.\n",
            "Por una cuestión de disciplina, sería conveniente trabajar siempre en un\n",
            "entorno virtual y no utilizar nunca la instalación “básica” de Python.\n",
            "Formato con espacios en blanco\n",
            "Muchos lenguajes utilizan llaves para delimitar los bloques de código.\n",
            "Python emplea la sangría:\n",
            "# El signo de la almohadilla marca el comienzo de un comentario. Python\n",
            "# ignora los comentarios, pero son útiles para cualquiera que lea el código.\n",
            "for i in [1, 2, 3, 4, 5]:\n",
            "print(i)\n",
            "# primera línea del bloque \"for i\"\n",
            "for j in [1, 2, 3, 4, 5]:\n",
            "print(j)\n",
            "# primera línea del bloque \"for j\"\n",
            "print(i + j)\n",
            "# última línea del bloque \"for j\"print(i)\n",
            "# última línea del bloque \"for i\"\n",
            "print(\"done looping\")\n",
            "Así, el código de Python resulta fácilmente legible, pero también significa\n",
            "que hay que tener mucho cuidado con el formato.\n",
            "Advertencia:\n",
            " Los programadores suelen debatir sobre si utilizar tabuladores o\n",
            "espacios para la sangría. En muchos lenguajes eso no importa, pero Python\n",
            "considera los tabuladores y los espacios como distintos tipos de sangría y el\n",
            "código no se ejecutará si se mezclan los dos. Al escribir en Python siempre hay\n",
            "que utilizar espacios, nunca tabuladores (si se escribe código en un editor es\n",
            "posible configurarlo de forma que la tecla \n",
            "Tab\n",
            " inserte espacios).\n",
            "Los espacios en blanco se ignoran dentro de paréntesis y corchetes, lo que\n",
            "puede resultar útil para cálculos largos:\n",
            "long_winded_computation\n",
            "=\n",
            "(1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9 + 10 + 11 + 12\n",
            "+\n",
            "13 + 14 + 15 + 16 + 17 + 18 + 19 + 20)\n",
            "Y para que el código resulte más fácil de leer:\n",
            "list_of_lists = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
            "easier_to_read_list_of_lists =\n",
            "[[1, 2, 3],\n",
            "[4, 5, 6],\n",
            "[7, 8, 9]]\n",
            "También se puede utilizar una barra invertida para indicar que una\n",
            "sentencia continúa en la siguiente línea, aunque pocas veces se hace:\n",
            "two_plus_three =\n",
            "2 + \\\n",
            "3\n",
            "Una consecuencia del formato con espacios en blanco es que puede ser\n",
            "difícil copiar y pegar código en el intérprete de Python. Por ejemplo, al\n",
            "intentar pegar este código:for i in [1, 2, 3, 4, 5]:\n",
            "# observe la línea en blanco\n",
            "print(i)\n",
            "En el \n",
            "shell\n",
            " normal de Python, aparecería este error:\n",
            "IndentationError: expected an indented block\n",
            "Porque el intérprete piensa que la línea vacía señala el final del bloque del\n",
            "bucle \n",
            "for\n",
            ".\n",
            "IPython tiene una función mágica llamada \n",
            "%paste\n",
            " que pega correctamente\n",
            "lo que haya en el portapapeles, con espacios en blanco y todo. Solamente esto\n",
            "ya es una muy buena razón para utilizar IPython.\n",
            "Módulos\n",
            "Ciertas funciones de Python no se cargan por defecto. Entre ellas, hay\n",
            "funciones que están incluidas como parte del lenguaje y funciones externas\n",
            "que cada usuario puede descargar por su cuenta. Para poder utilizar estas\n",
            "funciones es necesario importar los módulos que las contienen.\n",
            "Una forma de hacer esto es simplemente importando el propio módulo:\n",
            "import re\n",
            "my_regex = re.compile(\"[0-9]+\", re.I)\n",
            "Aquí, \n",
            "re\n",
            " es el módulo que contiene funciones y constantes para trabajar\n",
            "con expresiones regulares. Tras este tipo de \n",
            "import\n",
            " hay que poner delante de\n",
            "esas funciones el prefijo \n",
            "re.\n",
            " para poder acceder a ellas.\n",
            "Si ya había un \n",
            "re\n",
            " distinto en el código que se está utilizando, se puede\n",
            "emplear otro nombre:\n",
            "import re as regex\n",
            "my_regex = regex.compile(\"[0-9]+\", regex.I)\n",
            "También se podría hacer esto si el módulo tiene un nombre poco\n",
            "manejable o si se va a escribir muy a menudo. Por ejemplo, un convenio\n",
            "estándar cuando se visualizan datos con matplotlib es:import matplotlib.pyplot as plt\n",
            "plt.plot(...)\n",
            "Si se necesitan algunos valores específicos de un módulo, se pueden\n",
            "importar de manera explícita y utilizarlos sin reservas:\n",
            "from collections import defaultdict, Counter\n",
            "lookup = defaultdict(int)\n",
            "my_counter = Counter()\n",
            "Siendo malas personas, podríamos importar el contenido completo de un\n",
            "módulo en nuestro espacio de nombres, lo que podría sobrescribir\n",
            "involuntariamente variables que ya estaban definidas:\n",
            "match = 10\n",
            "from re import *\n",
            "# oh, oh, re tiene una función que se llama igual\n",
            "print(match)\n",
            "# \"<function match at 0x10281e6a8>\"\n",
            "Pero, como en realidad no somos malas personas, nunca haremos esto.\n",
            "Funciones\n",
            "Una función es una regla para tomar cero o más entradas y devolver una\n",
            "salida correspondiente. En Python, las funciones se definen normalmente\n",
            "utilizando \n",
            "def\n",
            ":\n",
            "def double(x):\n",
            "\"\"\"\n",
            "This is where you put an optional docstring that explains what the\n",
            "function does. For example, this function multiplies its input by 2.\n",
            "\"\"\"\n",
            "return x * 2\n",
            "Las funciones de Python son de primera clase, lo que significa que\n",
            "podemos asignarlas a variables y pasarlas a funciones como si se tratara de\n",
            "cualesquiera otros argumentos:\n",
            "def apply_to_one(f):\"\"\"Calls the function f with 1 as its argument\"\"\"\n",
            "return f(1)\n",
            "my_double = double\n",
            "# se refiere a la función anteriormente\n",
            "definida\n",
            "x =\n",
            "apply_to_one(my_double)\n",
            "# es igual a 2\n",
            "También es fácil crear funciones anónimas cortas, denominadas lambdas:\n",
            "y = apply_to_one(lambda x: x + 4)\n",
            "# es igual a 5\n",
            "Se pueden asignar lambdas a variables, aunque la mayoría de la gente dirá\n",
            "que en su lugar solo hay que utilizar \n",
            "def\n",
            ":\n",
            "another_double = lambda x: 2 * x\n",
            "# no haga esto\n",
            "def another_double(x):\n",
            "\"\"\"Do this instead\"\"\"\n",
            "return 2 * x\n",
            "A los parámetros de función también se les pueden asignar argumentos\n",
            "predeterminados, que solamente tienen que especificarse cuando se desea un\n",
            "valor distinto al predeterminado:\n",
            "def my_print(message = \"my default message\"):\n",
            "print(message)\n",
            "my_print(\"hello\")\n",
            "# imprime ‘hello’\n",
            "my_print()\n",
            "# imprime ‘my default message’\n",
            "Algunas veces es útil especificar argumentos por el nombre:\n",
            "def full_name(first = \"What’s-his-name\", last = \"Something\"):\n",
            "return first + \" \" + last\n",
            "full_name(\"Joel\", \"Grus\")\n",
            "# \"Joel Grus\"\n",
            "full_name(\"Joel\")\n",
            "# \"Joel Something\"\n",
            "full_name(last=\"Grus\")\n",
            "# \"What’s-his-name Grus\"\n",
            "Vamos a crear muchas muchas funciones.Cadenas\n",
            "Las cadenas (o \n",
            "strings\n",
            ") pueden estar delimitadas por comillas simples o\n",
            "dobles (pero las comillas tienen que ir en pares):\n",
            "single_quoted_string = ‘data science’\n",
            "double_quoted_string = \"data science\"\n",
            "Python utiliza las barras invertidas para codificar caracteres especiales.\n",
            "Por ejemplo:\n",
            "tab_string = \"\\t\"\n",
            "# representa el carácter del tabulador\n",
            "len(tab_string)\n",
            "# es 1\n",
            "Si queremos barras invertidas como tales (las que se utilizan en nombres\n",
            "de directorio de Windows o en expresiones regulares), se pueden crear\n",
            "cadenas en bruto (\n",
            "raw strings\n",
            ") utilizando \n",
            "r””\n",
            ":\n",
            "not_tab_string = r\"\\t\"\n",
            "# representa los caracteres ‘\\’ y ‘t’\n",
            "len(not_tab_string)\n",
            "# es 2\n",
            "Se pueden crear cadenas multilínea utilizando comillas triples:\n",
            "multi_line_string = \"\"\"This is the first line,\n",
            "and this is the second line\n",
            "and this is the third line.\"\"\"\n",
            "Una función nueva en Pyhton es la \n",
            "f-string\n",
            ", que ofrece una sencilla\n",
            "manera de sustituir valores por cadenas. Por ejemplo, si nos dieran el nombre\n",
            "y el apellido por separado:\n",
            "first_name = \"Joel\"\n",
            "last_name = \"Grus\"\n",
            "Querríamos combinarlos como un nombre completo. Hay distintas formas\n",
            "de construir una cadena \n",
            "full_name\n",
            ":\n",
            "full_name1 = first_name + \" \" + last_name\n",
            "# suma de cadenas\n",
            "full_name2 = \"{0} {1}\".format(first_name, last_name)\n",
            "# string.format\n",
            "Pero el método f-string es mucho más manejable:full_name3 = f”{first_name} {last_name}”\n",
            "Y lo preferiremos a lo largo del libro.\n",
            "Excepciones\n",
            "Cuando algo va mal, Python levanta una excepción. Si no se controlan\n",
            "adecuadamente, las excepciones pueden hacer que el programa se cuelgue. Se\n",
            "pueden manejar utilizando \n",
            "try\n",
            " y \n",
            "except\n",
            ":\n",
            "try:\n",
            "print(0 / 0)\n",
            "except ZeroDivisionError:\n",
            "print(\"cannot divide by zero\")\n",
            "Aunque en muchos lenguajes las excepciones no están bien consideradas,\n",
            "en Python no hay problema en utilizarlas para que el código sea más limpio,\n",
            "así que en ocasiones lo haremos.\n",
            "Listas\n",
            "Probablemente la estructura de datos más esencial de Python es la lista,\n",
            "que no es más que una colección ordenada (similar a lo que en otros\n",
            "lenguajes se podría denominar \n",
            "array\n",
            ", pero con funcionalidad añadida):\n",
            "integer_list = [1, 2, 3]\n",
            "heterogeneous_list = [\"string\", 0.1, True]\n",
            "list_of_lists = [integer_list, heterogeneous_list, []]\n",
            "list_length = len(integer_list)\n",
            "# es igual a 3\n",
            "list_sum = sum(integer_list)\n",
            "# es igual a 6\n",
            "Se puede obtener o establecer el elemento \n",
            "n\n",
            " de una lista con corchetes:\n",
            "x = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "zero = x[0]\n",
            "# es igual a 0, las listas están indexadas al 0one = x[1]\n",
            "# es igual a 1\n",
            "nine = x[-1]\n",
            "# es igual a 9, ‘pitónico’ para el último elemento\n",
            "eight = x[-2]\n",
            "# es igual a 8, ‘pitónico’ para el penúltimo elemento\n",
            "x[0] = -1\n",
            "# ahora x es [-1, 1, 2, 3, ..., 9]\n",
            "También se pueden utilizar corchetes para crear \n",
            "slices\n",
            " en listas (cortes o\n",
            "arreglos). El corte \n",
            "i:j\n",
            " significa todos los elementos desde \n",
            "i\n",
            " (incluido) hasta \n",
            "j\n",
            "(excluido). Si dejamos fuera el principio del corte, lo extraeremos desde el\n",
            "principio de la lista, pero, si dejamos fuera el final del corte, lo extraeremos\n",
            "hasta el final:\n",
            "first_three = x[:3]\n",
            "# [-1, 1, 2]\n",
            "three_to_end = x[3:]\n",
            "# [3, 4, ..., 9]\n",
            "one_to_four = x[1:5]\n",
            "# [1, 2, 3, 4]\n",
            "last_three = x[-3:]\n",
            "# [7, 8, 9]\n",
            "without_first_and_last = x[1:-1]\n",
            "# [1, 2, ..., 8]\n",
            "copy_of_x = x[:]\n",
            "# [-1, 1, 2, ..., 9]\n",
            "De forma similar se pueden crear cortes de cadenas y otros tipos\n",
            "“secuenciales”.\n",
            "Un corte puede admitir un tercer argumento para indicar su \n",
            "stride\n",
            "(avance), que puede ser negativo:\n",
            "every_third = x[::3]\n",
            "# [-1, 3, 6, 9]\n",
            "five_to_three = x[5:2:-1]\n",
            "# [5, 4, 3]\n",
            "Python tiene un operador \n",
            "in\n",
            " para comprobar los miembros de la lista:\n",
            "1 in [1, 2, 3]\n",
            "# True\n",
            "0 in [1, 2, 3]\n",
            "# False\n",
            "Esta comprobación implica examinar los elementos de la lista de uno en\n",
            "uno, lo que significa que probablemente no se debería utilizar a menos que se\n",
            "sepa que la lista es pequeña (o a menos que no nos preocupe el tiempo que\n",
            "tarde en hacerse la comprobación).\n",
            "Es fácil concatenar listas. Si se desea modificar una lista en su lugar, se\n",
            "puede utilizar \n",
            "extend\n",
            " para añadir elementos de otra colección:x = [1, 2, 3]\n",
            "x.extend([4, 5, 6])\n",
            "# x es ahora [1, 2, 3, 4, 5, 6]\n",
            "Si no queremos modificar \n",
            "x\n",
            ", podemos ampliar la lista:\n",
            "x = [1, 2, 3]\n",
            "y = x + [4, 5, 6]\n",
            "# y es [1, 2, 3, 4, 5, 6]; x no ha cambiado\n",
            "Lo más frecuente que haremos será añadir elementos a listas uno a uno:\n",
            "x = [1, 2, 3]\n",
            "x.append(0)\n",
            "# x es ahora [1, 2, 3, 0]\n",
            "y = x[-1]\n",
            "# es igual a 0\n",
            "z = len(x)\n",
            "# es igual a 4\n",
            "A menudo, es conveniente desempaquetar listas cuando se sabe cuántos\n",
            "elementos contienen:\n",
            "x, y = [1, 2]\n",
            "# ahora x es 1, y es 2\n",
            "Aunque obtendremos un \n",
            "ValueError\n",
            " si no tenemos el mismo número de\n",
            "elementos en ambos lados.\n",
            "Algo que se utiliza habitualmente es un carácter de subrayado para un\n",
            "valor del que nos vamos a deshacer:\n",
            "_, y = [1, 2]\n",
            "# ahora y == 2, no nos importa el primer elemento\n",
            "Tuplas\n",
            "Las tuplas son las primas inmutables de las listas. Casi todo lo que se le\n",
            "puede hacer a una lista que implique modificarla, se le puede hacer a una\n",
            "tupla. Se especifica una tupla utilizando paréntesis (o nada) en lugar de\n",
            "corchetes:\n",
            "my_list = [1, 2]\n",
            "my_tuple = (1, 2)other_tuple = 3, 4\n",
            "my_list[1] = 3\n",
            "# my_list es ahora[1, 3]\n",
            "try:\n",
            "my_tuple[1] = 3\n",
            "except TypeError:\n",
            "print(\"cannot modify a tuple\")\n",
            "Las tuplas son una forma cómoda de devolver varios valores de funciones:\n",
            "def sum_and_product(x, y):\n",
            "return (x + y), (x * y)\n",
            "sp = sum_and_product(2, 3)\n",
            "# sp es (5, 6)\n",
            "s, p = sum_and_product(5, 10)\n",
            "# s es 15, p es 50\n",
            "Las tuplas (y las listas) se pueden utilizar para asignación múltiple:\n",
            "x, y = 1,\n",
            "2\n",
            "# ahora x es 1, y es 2\n",
            "x, y = y,\n",
            "x\n",
            "# Forma pitónica de intercambiar variables; ahora x es 2, y es\n",
            "1\n",
            "Diccionarios\n",
            "Otra estructura de datos fundamental es un diccionario, que asocia valores\n",
            "a claves y permite recuperar rápidamente el valor correspondiente a una\n",
            "determinada clave:\n",
            "empty_dict = {}\n",
            "# pitónico\n",
            "empty_dict2 = dict()\n",
            "# menos pitónico\n",
            "grades = {\"Joel\": 80, \"Tim\": 95}\n",
            "# dict literal\n",
            "Se puede consultar el valor para una clave utilizando corchetes:\n",
            "joels_grade = grades[“Joel”]\n",
            "# es igual a 80\n",
            "Pero se obtendrá un \n",
            "KeyError\n",
            " si se pregunta por una clave que no está en\n",
            "el diccionario:try:\n",
            "kates_grade = grades[\"Kate\"]\n",
            "except KeyError:\n",
            "print(\"no grade for Kate!\")\n",
            "Se puede comprobar la existencia de una clave utilizando \n",
            "in\n",
            ":\n",
            "joel_has_grade = \"Joel\" in grades\n",
            "# True\n",
            "kate_has_grade = \"Kate\" in grades\n",
            "# False\n",
            "Esta verificación de membresía es aún más rápida para diccionarios\n",
            "grandes.\n",
            "Los diccionarios tienen un método \n",
            "get\n",
            " que devuelve un valor\n",
            "predeterminado (en lugar de levantar una excepción) cuando se consulta una\n",
            "clave que no está en el diccionario:\n",
            "joels_grade = grades.get(\"Joel\", 0)\n",
            "# es igual a 80\n",
            "kates_grade = grades.get(\"Kate\", 0)\n",
            "# es igual a 0\n",
            "no_ones_grade = grades.get(\"No One\")\n",
            "# el valor predeterminado es None\n",
            "Se pueden asignar pares clave/valor utilizando los mismos corchetes:\n",
            "grades[\"Tim\"] = 99\n",
            "# reemplaza el valor anterior\n",
            "grades[\"Kate\"] = 100\n",
            "# añade una tercera entrada\n",
            "num_students = len(grades)\n",
            "# es igual a 3\n",
            "Como vimos en el capítulo 1, se pueden utilizar diccionarios para\n",
            "representar datos estructurados:\n",
            "tweet = {\n",
            "\"user\" : \"joelgrus\",\n",
            "\"text\" : \"Data Science is Awesome\",\n",
            "\"retweet_count\" : 100,\n",
            "\"hashtags\" : [\"#data\", \"#science\", \"#datascience\", \"#awesome\", \"#yolo\"]\n",
            "}\n",
            "Aunque pronto veremos un enfoque mejor.\n",
            "Además de buscar claves específicas, también podemos mirarlas todas:tweet_keys = tweet.keys()\n",
            "# iterable para las claves\n",
            "tweet_values =\n",
            "tweet.values()\n",
            "# iterable para los valores\n",
            "tweet_items =\n",
            "tweet.items()\n",
            "# iterable para las tuplas (clave, valor)\n",
            "\"user\" in tweet_keys\n",
            "# True, pero no pitónico\n",
            "\"user\" in tweet\n",
            "# forma pitónica de comprobar claves\n",
            "\"joelgrus\" in tweet_values\n",
            "# True (es lenta, pero la única forma de\n",
            "verificar)\n",
            "Las claves de diccionario pueden ser “\n",
            "hashables\n",
            "”; en particular, no se\n",
            "pueden utilizar listas como claves. Si se necesita una clave multiparte,\n",
            "probablemente se debería utilizar una tupla o idear un modo de convertir la\n",
            "clave en una cadena.\n",
            "defaultdict\n",
            "Imaginemos que estamos intentando contar las palabras de un documento.\n",
            "Un método obvio para lograrlo es crear un diccionario en el que las claves\n",
            "sean palabras y los valores sean contadores. Al comprobar cada palabra, se\n",
            "puede incrementar su contador si ya está en el diccionario y añadirlo al\n",
            "diccionario si no estaba:\n",
            "word_counts = {}\n",
            "for word in document:\n",
            "if word in word_counts:\n",
            "word_counts[word] += 1\n",
            "else:\n",
            "word_counts[word] = 1\n",
            "Se podría utilizar también el sistema “mejor pedir perdón que permiso” y\n",
            "simplemente manejar la excepción al intentar consultar una clave inexistente:\n",
            "word_counts = {}\n",
            "for word in document:\n",
            "try:\n",
            "word_counts[word] += 1\n",
            "except KeyError:\n",
            "word_counts[word] = 1Un tercer enfoque es utilizar \n",
            "get\n",
            ", que se comporta con mucha elegancia\n",
            "con las claves inexistentes:\n",
            "word_counts = {}\n",
            "for word in document:\n",
            "previous_count = word_counts.get(word, 0)\n",
            "word_counts[word] = previous_count + 1\n",
            "Todo esto es muy poco manejable, razón por la cual \n",
            "defaultdict\n",
            " es útil.\n",
            "Un \n",
            "defaultdict\n",
            " es como un diccionario normal, excepto que, cuando se\n",
            "intenta buscar una clave que no contiene, primero añade un valor para ella\n",
            "utilizando una función de argumento cero suministrada al crearla. Para\n",
            "utilizar diccionarios \n",
            "defaultdict\n",
            "s, es necesario importarlos de \n",
            "collections\n",
            ":\n",
            "from collections import defaultdict\n",
            "word_counts = defaultdict(int)\n",
            "# int() produce 0\n",
            "for word in document:\n",
            "word_counts[word] += 1\n",
            "También pueden resultar útiles con \n",
            "list\n",
            " o \n",
            "dict\n",
            ", o incluso con nuestras\n",
            "propias funciones:\n",
            "dd_list = defaultdict(list)\n",
            "# list() produce una lista vacía\n",
            "dd_list[2].append(1)\n",
            "# ahora dd_list contiene {2: [1]}\n",
            "dd_dict = defaultdict(dict)\n",
            "# dict() produce un dict vacío\n",
            "dd_dict[\"Joel\"][\"City\"] = \"Seattle\"\n",
            "# {\"Joel\" : {\"City\": Seattle\"}}\n",
            "dd_pair = defaultdict(lambda: [0, 0])\n",
            "dd_pair[2][1] = 1\n",
            "# ahora dd_pair contiene {2: [0, 1]}\n",
            "Serán útiles cuando estemos utilizando diccionarios para “recopilar”\n",
            "resultados según alguna clave y no queramos comprobar todo el tiempo si la\n",
            "clave sigue existiendo.\n",
            "Contadores\n",
            "Un \n",
            "Counter\n",
            " convierte una secuencia de valores en un objeto de tipodefaultdict(int)\n",
            " mapeando claves en contadores:\n",
            "from collections import Counter\n",
            "c = Counter([0, 1, 2, 0])\n",
            "# c es (básicamente) {0: 2, 1: 1, 2: 1}\n",
            "Lo que nos ofrece un modo muy sencillo de resolver problemas de\n",
            "word_counts\n",
            ":\n",
            "# recuerde, document es una lista de palabras\n",
            "word_counts = Counter(document)\n",
            "Una instancia \n",
            "Counter\n",
            " tiene un método \n",
            "most_common\n",
            " que se utiliza con\n",
            "frecuencia:\n",
            "# imprime las 10 palabras más comunes y sus contadores\n",
            "for word, count in word_counts.most_common(10):\n",
            "print(word, count)\n",
            "Conjuntos\n",
            "Otra estructura de datos útil es el conjunto o \n",
            "set\n",
            ", que representa una\n",
            "colección de distintos elementos. Se pueden definir un conjunto listando sus\n",
            "elementos entre llaves:\n",
            "primes_below_10 = {2, 3, 5, 7}\n",
            "Sin embargo, esto no funciona con conjuntos vacíos, dado que \n",
            "{}\n",
            " ya\n",
            "significa “\n",
            "dict\n",
            " vacío”. En ese caso, habrá que utilizar la propia \n",
            "set()\n",
            ":\n",
            "s = set()\n",
            "s.add(1)\n",
            "# s es ahora {1}\n",
            "s.add(2)\n",
            "# s es ahora {1, 2}\n",
            "s.add(2)\n",
            "# s sigue siendo {1, 2}\n",
            "x = len(s)\n",
            "# es igual a 2\n",
            "y = 2 in s\n",
            "# es igual a True\n",
            "z = 3 in s\n",
            "# es igual a False\n",
            "Utilizaremos conjuntos por dos razones principales. La primera es que \n",
            "ines una operación muy rápida con conjuntos. Si tenemos una gran colección\n",
            "de elementos que queremos utilizar para hacer una prueba de membresía, un\n",
            "conjunto es más adecuado que una lista:\n",
            "stopwords_list = [\"a\", \"an\", \"at\"] + hundreds_of_other_words + [\"yet\", \"you\"]\n",
            "\"zip\" in stopwords_list\n",
            "# False, pero hay que verificar cada elemento\n",
            "stopwords_set = set(stopwords_list)\n",
            "\"zip\" in stopwords_set\n",
            "# muy rápido de comprobar\n",
            "La segunda razón es encontrar los elementos distintos de una colección:\n",
            "item_list = [1, 2, 3, 1, 2, 3]\n",
            "num_items = len(item_list)\n",
            "# 6\n",
            "item_set = set(item_list)\n",
            "# {1, 2, 3}\n",
            "num_distinct_items = len(item_set)\n",
            "# 3\n",
            "distinct_item_list = list(item_set)\n",
            "# [1, 2, 3]\n",
            "Utilizaremos conjuntos con menos frecuencia que diccionarios y listas.w\n",
            "Flujo de control\n",
            "Como en la mayoría de los lenguajes de programación, se puede realizar\n",
            "una acción de forma condicional utilizando \n",
            "if\n",
            ":\n",
            "if 1 > 2:\n",
            "message = \"if only 1 were greater than two...\"\n",
            "elif 1 > 3:\n",
            "message = \"elif stands for ‘else if’\"\n",
            "else:\n",
            "message = \"when all else fails use else (if you want to)\"\n",
            "Se puede también escribir un ternario if-then-else en una sola línea, cosa\n",
            "que haremos muy de tanto en tanto:\n",
            "parity = “even” if x % 2 == 0 else “odd”\n",
            "Python tiene un bucle \n",
            "while\n",
            ":x = 0\n",
            "while x < 10:\n",
            "print(f\"{x} is less than 10\")\n",
            "x += 1\n",
            "Aunque con mucha más frecuencia usaremos \n",
            "for\n",
            " e \n",
            "in\n",
            ":\n",
            "# range(10) es los números 0, 1, ..., 9\n",
            "for x in range(10):\n",
            "print(f\"{x} is less than 10\")\n",
            "Si necesitáramos lógica más compleja, podríamos utilizar \n",
            "continue\n",
            " y\n",
            "break\n",
            ":\n",
            "for x in range(10):\n",
            "if x == 3:\n",
            "continue\n",
            "# va inmediatamente a la siguiente repetición\n",
            "if x == 5:\n",
            "break\n",
            "# sale del todo del bucle\n",
            "print(x)\n",
            "Esto imprimirá 0, 1, 2 y 4.\n",
            "Verdadero o falso\n",
            "Los valores booleanos en Python funcionan igual que en casi todos los\n",
            "demás lenguajes, excepto que llevan la primera letra en mayúscula:\n",
            "one_is_less_than_two = 1 < 2\n",
            "# es igual a True\n",
            "true_equals_false = True == False\n",
            "# es igual a False\n",
            "Python utiliza el valor \n",
            "None\n",
            " para indicar un valor no existente. Es similar\n",
            "al \n",
            "null\n",
            " de otros lenguajes:\n",
            "x = None\n",
            "assert x == None, \"this is the not the Pythonic way to check for None\"\n",
            "assert x is None, \"this is the Pythonic way to check for None\"Python permite utilizar cualquier valor donde espera un booleano. Las\n",
            "siguientes expresiones son todas “falsas”:\n",
            "■\n",
            "False\n",
            ".\n",
            "■\n",
            "None\n",
            ".\n",
            "■\n",
            "[]\n",
            " (una \n",
            "list\n",
            " vacía).\n",
            "■\n",
            "{}\n",
            " (un \n",
            "dict\n",
            " vacío).\n",
            "■\n",
            "“”\n",
            ".\n",
            "■\n",
            "set()\n",
            ".\n",
            "■\n",
            "0\n",
            ".\n",
            "■\n",
            "0.0\n",
            ".\n",
            "Casi todo lo demás se trata como \n",
            "True\n",
            ". Ello permite utilizar fácilmente\n",
            "sentencias \n",
            "if\n",
            " para probar listas vacías, cadenas vacías, diccionarios vacíos,\n",
            "etc. También produce en ocasiones errores complicados si no se espera este\n",
            "comportamiento:\n",
            "s = some_function_that_returns_a_string()\n",
            "if s:\n",
            "first_char = s[0]\n",
            "else:\n",
            "first_char = \"\"\n",
            "Una forma más corta (pero posiblemente más confusa) de hacer lo mismo\n",
            "es:\n",
            "first_char = s and s[0]\n",
            "Ya que \n",
            "and\n",
            " devuelve su segundo valor cuando el primero es “verdadero”,\n",
            "y el primer valor cuando no lo es. De forma similar, si \n",
            "x\n",
            " es o bien un número\n",
            "o posiblemente \n",
            "None\n",
            ":\n",
            "safe_x = x or 0\n",
            "Es definitivamente un número, aunque:\n",
            "safe_x = x if x is not None else 0Es posiblemente más legible.\n",
            "Python tiene una función \n",
            "all\n",
            ", que toma un iterable y devuelve \n",
            "True\n",
            "exactamente cuando cada elemento es verdadero, y una función \n",
            "any\n",
            ", que\n",
            "devuelve \n",
            "True\n",
            " cuando al menos un elemento es verdad:\n",
            "all([True, 1, {3}])\n",
            "# True, todos son verdaderos\n",
            "all([True, 1, {}])\n",
            "# False, {} is falso\n",
            "any([True, 1, {}])\n",
            "# True, True is verdadero\n",
            "all([])\n",
            "# True, no hay elementos falsos en la lista\n",
            "any([])\n",
            "# False, no hay elementos verdaderos en la lista\n",
            "Ordenar\n",
            "Toda lista de Python tiene un método \n",
            "sort\n",
            " que la ordena en su lugar. Si\n",
            "no queremos estropear nuestra lista, podemos usar la función \n",
            "sorted\n",
            ", que\n",
            "devuelve una lista nueva:\n",
            "x = [4, 1, 2, 3]\n",
            "y = sorted(x)\n",
            "# y es [1, 2, 3, 4], x queda igual\n",
            "x.sort()\n",
            "# ahora x es [1, 2, 3, 4]\n",
            "Por defecto, \n",
            "sort\n",
            " (y \n",
            "sorted\n",
            ") ordena una lista de menor a mayor\n",
            "basándose en comparar inocentemente los elementos uno con otro.\n",
            "Si queremos que los elementos estén ordenados de mayor a menor, se\n",
            "puede especificar un parámetro \n",
            "reverse=True\n",
            ". Y, en lugar de comparar los\n",
            "elementos por sí mismos, se pueden comparar los resultados de una función\n",
            "que se especifica con \n",
            "key\n",
            ":\n",
            "# ordena la lista por valor absoluto de mayor a menor\n",
            "x = sorted([-4, 1, -2, 3], key=abs, reverse=True)\n",
            "# is [-4, 3, -2, 1]\n",
            "# ordena las palabras y contadores del contador mayor al menor\n",
            "wc = sorted(word_counts.items(),\n",
            "key=lambda word_and_count: word_and_count[1],\n",
            "reverse=True)Comprensiones de listas\n",
            "Con frecuencia, vamos a querer transformar una lista en otra distinta\n",
            "seleccionando solo determinados elementos, transformando elementos o\n",
            "haciendo ambas cosas. La forma pitónica de hacer esto es con \n",
            "list\n",
            "comprehensions\n",
            ", o comprensiones de listas:\n",
            "even_numbers = [x for x in range(5) if x % 2 == 0]\n",
            "# [0, 2, 4]\n",
            "squares = [x * x for x in range(5)]\n",
            "# [0, 1, 4, 9, 16]\n",
            "even_squares = [x * x for x in even_numbers]\n",
            "# [0, 4, 16]\n",
            "De forma similar, se pueden convertir listas en diccionarios o conjuntos:\n",
            "square_dict = {x: x * x for x in\n",
            "range(5)}\n",
            "# {0: 0, 1: 1, 2: 4, 3: 9, 4:\n",
            "16}\n",
            "square_set = {x * x for x in [1, -1]}\n",
            "# {1}\n",
            "Si no necesitamos el valor de la lista, es habitual utilizar un guion bajo\n",
            "como variable:\n",
            "zeros = [0 for _ in\n",
            "even_numbers]\n",
            "# tiene la misma longitud que\n",
            "even_numbers\n",
            "Una comprensión de lista puede incluir varios \n",
            "for\n",
            ":\n",
            "pairs = [(x, y)\n",
            "for x in range(10)\n",
            "for y in range(10)]\n",
            "# 100 pares (0,0) (0,1) ... (9,8), (9,9)\n",
            "Y después los \n",
            "for\n",
            " pueden utilizar los resultados de los anteriores:\n",
            "increasing_pairs = [(x, y)\n",
            "# solo pares con x < y,\n",
            "for x in range(10)\n",
            "# range(bajo, alto) es igual a\n",
            "for y in range(x + 1, 10)]\n",
            "# [bajo, bajo + 1, ..., alto–1]\n",
            "Utilizaremos mucho las comprensiones de listas.Pruebas automatizadas y assert\n",
            "Como científicos de datos, escribiremos mucho código. ¿Cómo podemos\n",
            "estar seguros de que nuestro código es correcto? Una forma es con tipos (de\n",
            "los que hablaremos en breve), pero otra forma es con \n",
            "automated tests\n",
            " o\n",
            "pruebas automatizadas.\n",
            "Hay estructuras muy complicadas para escribir y ejecutar pruebas, pero en\n",
            "este libro nos limitaremos a utilizar sentencias \n",
            "assert\n",
            ", que harán que el\n",
            "código levante un \n",
            "AssertionError\n",
            " si la condición especificada no es\n",
            "verdadera:\n",
            "assert 1 + 1 == 2\n",
            "assert 1 + 1 == 2, \"1 + 1 should equal 2 but didn’t\"\n",
            "Como podemos ver en el segundo caso, se puede añadir si se desea un\n",
            "mensaje que se imprimirá si la evaluación falla.\n",
            "No es especialmente interesante evaluar que 1 + 1 = 2, pero lo es mucho\n",
            "más verificar que las funciones que escribamos hagan lo que se espera de\n",
            "ellas:\n",
            "def smallest_item(xs):\n",
            "return min(xs)\n",
            "assert smallest_item([10, 20, 5, 40]) == 5\n",
            "assert smallest_item([1, 0, -1, 2]) == -1\n",
            "A lo largo del libro utilizaremos \n",
            "assert\n",
            " de esta forma. Es una buena\n",
            "práctica, y yo animo a utilizar libremente esta sentencia (en el código del\n",
            "libro que encontramos en GitHub se comprueba que contiene muchas más\n",
            "sentencias \n",
            "assert\n",
            " de las que aparecen impresas en el libro, lo que me permite\n",
            "estar seguro de que el código que he escrito es correcto).\n",
            "Otro uso menos habitual es evaluar cosas sobre entradas a funciones:\n",
            "def smallest_item(xs):\n",
            "assert xs, \"empty list has no smallest item\"\n",
            "return min(xs)\n",
            "Haremos esto de vez en cuando, pero será más frecuente utilizar \n",
            "assertpara verificar que el código escrito es correcto.\n",
            "Programación orientada a objetos\n",
            "Como muchos lenguajes, Python permite definir clases que encapsulan los\n",
            "datos y las funciones que operan con ellos. Las utilizaremos algunas veces\n",
            "para que nuestro código sea más limpio y sencillo. Probablemente, es más\n",
            "fácil explicarlas construyendo un ejemplo con muchas anotaciones.\n",
            "Aquí vamos a crear una clase que represente un “contador de clics”, del\n",
            "tipo de los que se ponen en la puerta para controlar cuántas personas han\n",
            "acudido al encuentro “Temas avanzados sobre ciencia de datos”.\n",
            "Mantiene un contador (\n",
            "count\n",
            "), se le puede hacer clic (\n",
            "clicked\n",
            ") para\n",
            "aumentar la cuenta, permite lectura de contador (\n",
            "read_count\n",
            ") y se puede\n",
            "reiniciar (\n",
            "reset\n",
            ") de vuelta a cero (en la vida real una de estas clases pasa de\n",
            "9999 a 0000, pero no vamos a preocuparnos de eso ahora).\n",
            "Para definir una clase, utilizamos la palabra clave \n",
            "class\n",
            " y un nombre de\n",
            "tipo PascalCase:\n",
            "class CountingClicker:\n",
            "\"\"\"A class can/should have a doctring, just like a function\"\"\"\n",
            "Una clase contiene cero o más funciones miembro. Por convenio, cada\n",
            "una toma un primer parámetro, \n",
            "self\n",
            ", que se refiere a la instancia en particular\n",
            "de la clase.\n",
            "Normalmente, una clase tiene un constructor, llamado \n",
            "__init__\n",
            ", que toma\n",
            "los parámetros que necesita para construir una instancia de dicha clase y hace\n",
            "cualquier configuración que se necesite:\n",
            "def __init__(self, count = 0):\n",
            "self.count = count\n",
            "Aunque el constructor tiene un nombre divertido, construimos las\n",
            "instancias del contador de clics utilizando solamente el nombre de la clase:clicker1 = CountingClicker()\n",
            "# inicializado a 0\n",
            "clicker2 = CountingClicker(100)\n",
            "# empieza con count=100\n",
            "clicker3 =\n",
            "CountingClicker(count=100)\n",
            "# forma más explícita de hacer lo\n",
            "mismo\n",
            "Vemos que el nombre del método \n",
            "__init__\n",
            " empieza y termina con\n",
            "guiones bajos. A veces a estos métodos “mágicos” se les llama métodos\n",
            "“dunder” (término inventado que viene de \n",
            "doubleUNDERscore\n",
            ", es decir,\n",
            "doble guion bajo) y representan comportamientos “especiales”.\n",
            "Nota:\n",
            " Los métodos de clase cuyos nombres empiezan con un guion bajo se\n",
            "consideran (por convenio) “privados”, y se supone que los usuarios de esa\n",
            "clase no les llaman directamente. Sin embargo, Python no impide a los\n",
            "usuarios llamarlos.\n",
            "Otro método similar es \n",
            "__repr__\n",
            ", que produce la representación de\n",
            "cadena de una instancia de clase:\n",
            "def __repr__(self):\n",
            "return f\"CountingClicker(count={self.count})\"\n",
            "Y finalmente tenemos que implementar la API pública de la clase que\n",
            "hemos creado:\n",
            "def click(self, num_times = 1):\n",
            "\"\"\"Click the clicker some number ot times.\"\"\"\n",
            "self.count += num_times\n",
            "def read(self):\n",
            "return self.count\n",
            "def reset(self):\n",
            "self.count = 0\n",
            "Una vez definido, utilicemos \n",
            "assert\n",
            " para escribir algunos casos de prueba\n",
            "para nuestro contador de clics:\n",
            "clicker = CountingClicker()\n",
            "assert clicker.read() == 0, \"clicker should start with count 0\"\n",
            "clicker.click()clicker.click()\n",
            "assert clicker.read() == 2, \"after two clicks, clicker should have count 2\"\n",
            "clicker.reset()\n",
            "assert clicker.read() == 0, \"after reset, clicker should be back to 0\"\n",
            "Escribir pruebas como estas nos permite estar seguros de que nuestro\n",
            "código esté funcionando tal y como está diseñado, y que esto va a seguir\n",
            "siendo así siempre que le hagamos cambios.\n",
            "También crearemos de vez en cuando subclases que heredan parte de su\n",
            "funcionalidad de una clase padre. Por ejemplo, podríamos crear un contador\n",
            "de clics no reiniciable utilizando \n",
            "CountingClicker\n",
            " como clase base y\n",
            "anulando el método \n",
            "reset\n",
            " para que no haga nada:\n",
            "# Una subclase hereda todo el comportamiento de su clase padre.\n",
            "class NoResetClicker(CountingClicker):\n",
            "# Esta clase tiene los mismos métodos que CountingClicker\n",
            "# Salvo que tiene un método reset que no hace nada.\n",
            "def reset(self):\n",
            "pass\n",
            "clicker2 = NoResetClicker()\n",
            "assert clicker2.read() == 0\n",
            "clicker2.click()\n",
            "assert clicker2.read() == 1\n",
            "clicker2.reset()\n",
            "assert clicker2.read() == 1, \"reset shouldn’t do anything\"\n",
            "Iterables y generadores\n",
            "Una cosa buena de las listas es que se pueden recuperar determinados\n",
            "elementos por sus índices. Pero ¡esto no siempre es necesario! Una lista de\n",
            "mil millones de números ocupa mucha memoria. Si solo queremos los\n",
            "elementos uno cada vez, no hay una buena razón que nos haga conservarlos a\n",
            "todos. Si solamente terminamos necesitando los primeros elementos, generar\n",
            "los mil millones es algo tremendamente inútil.\n",
            "A menudo, todo lo que necesitamos es pasar varias veces por la colección\n",
            "utilizando \n",
            "for\n",
            " e \n",
            "in\n",
            ". En este caso podemos crear generadores, que se puedeniterar igual que si fueran listas, pero generan sus valores bajo petición.\n",
            "Una forma de crear generadores es con funciones y con el operador \n",
            "yield\n",
            ":\n",
            "def generate_range(n):\n",
            "i = 0\n",
            "while i < n:\n",
            "yield I\n",
            "# cada llamada a yield produce un valor del generador\n",
            "i += 1\n",
            "El siguiente bucle consumirá uno a uno los valores a los que se ha\n",
            "aplicado \n",
            "yield\n",
            " hasta que no quede ninguno:\n",
            "for i in generate_range(10):\n",
            "print(f\"i: {i}\")\n",
            "(En realidad, \n",
            "range\n",
            " es bastante perezosa de por sí, así que hacer esto no\n",
            "tiene ningún sentido).\n",
            "Con un generador, incluso se puede crear una secuencia infinita:\n",
            "def natural_numbers():\n",
            "\"\"\"returns 1, 2, 3, ...\"\"\"\n",
            "n = 1\n",
            "while True:\n",
            "yield n\n",
            "n += 1\n",
            "Aunque probablemente no deberíamos iterar sobre él sin utilizar algún\n",
            "tipo de lógica de interrupción.\n",
            "Truco:\n",
            " La otra cara de la pereza es que solo se puede iterar una única vez por\n",
            "un generador. Si hace falta pasar varias veces, habrá que volver a crear el\n",
            "generador cada vez o bien utilizar una lista. Si generar los valores resulta caro,\n",
            "podría ser una buena razón para utilizar una lista en su lugar.\n",
            "Una segunda manera de crear generadores es utilizar las comprensiones\n",
            "envueltas en paréntesis:\n",
            "evens_below_20 = (i for i in generate_range(20) if i % 2 == 0)Una “comprensión de generador” como esta no hace nada hasta que se\n",
            "itera sobre ella (utilizando \n",
            "for\n",
            " o \n",
            "next\n",
            "). Podemos utilizar esto para crear\n",
            "complicadas líneas de proceso de datos:\n",
            "# Ninguno de estos cálculos *hace* nada hasta que iteramos\n",
            "data = natural_numbers()\n",
            "evens = (x for x in data if x % 2 == 0)\n",
            "even_squares = (x ** 2 for x in evens)\n",
            "even_squares_ending_in_six = (x for x in even_squares if x % 10 == 6)\n",
            "# y así sucesivamente\n",
            "No pocas veces, cuando estemos iterando sobre una lista o un generador,\n",
            "no querremos solamente los valores, sino también sus índices. Para este caso\n",
            "habitual, Python ofrece una función \n",
            "enumerate\n",
            ", que convierte valores en\n",
            "pares (\n",
            "index\n",
            ", \n",
            "value\n",
            "):\n",
            "names = [\"Alice\", \"Bob\", \"Charlie\", \"Debbie\"]\n",
            "# no pitónico\n",
            "for i in range(len(names)):\n",
            "print(f\"name {i} is {names[i]}\")\n",
            "# tampoco pitónico\n",
            "i = 0\n",
            "for name in names:\n",
            "print(f\"name {i} is {names[i]}\")\n",
            "i += 1\n",
            "# pitónico\n",
            "for i, name in enumerate(names):\n",
            "print(f\"name {i} is {name}\")\n",
            "Utilizaremos mucho esto.\n",
            "Aleatoriedad\n",
            "A medida que aprendamos ciencia de datos, necesitaremos con frecuencia\n",
            "generar números aleatorios, lo que podemos hacer con el módulo \n",
            "random\n",
            ":\n",
            "import random\n",
            "random.seed(10)\n",
            "# esto asegura que obtenemos los mismos resultados cada vezfour_uniform_randoms = [random.random() for _ in range(4)]\n",
            "# [0.5714025946899135,\n",
            "# random.random() produce números\n",
            "# 0.4288890546751146,\n",
            "# de manera uniforme entre 0 y 1.\n",
            "# 0.5780913011344704,\n",
            "# Es la función random que utilizaremos\n",
            "# 0.20609823213950174]\n",
            "# con más frecuencia.\n",
            "El módulo \n",
            "random\n",
            " produce en realidad números pseudoaleatorios (es\n",
            "decir, deterministas) basados en un estado interno que se puede configurar\n",
            "con \n",
            "random.seed\n",
            " si lo que se desea es obtener resultados reproducibles:\n",
            "random.seed(10)\n",
            "# establece la semilla en 10\n",
            "print(random.random())\n",
            "# 0.57140259469\n",
            "random.seed(10)\n",
            "# reinicia la semilla en 10\n",
            "print(random.random())\n",
            "# 0.57140259469 de nuevo\n",
            "Algunas veces utilizaremos \n",
            "random.randrange\n",
            ", que toma uno o dos\n",
            "argumentos y devuelve un elemento elegido aleatoriamente del \n",
            "range\n",
            "correspondiente:\n",
            "random.randrange(10)\n",
            "# selecciona aleatoriamente de range(10) = [0, 1,\n",
            "..., 9]\n",
            "random.randrange(3,\n",
            "6)\n",
            "# selecciona aleatoriamente de range(3, 6) = [3, 4,\n",
            "5]\n",
            "Hay varios métodos más que en ocasiones nos resultarán convenientes.\n",
            "Por ejemplo, \n",
            "random.shuffle\n",
            " reordena aleatoriamente los elementos de una\n",
            "lista:\n",
            "up_to_ten = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
            "random.shuffle(up_to_ten)\n",
            "print(up_to_ten)\n",
            "# [7, 2, 6, 8, 9, 4, 10, 1, 3,\n",
            "5]\n",
            "(sus resultados serán probablemente\n",
            "diferentes)\n",
            "Si se necesita elegir aleatoriamente un elemento de una lista, se puede\n",
            "utilizar \n",
            "random.choice\n",
            ":\n",
            "my_best_friend = random.choice([“Alice”, “Bob”, “Charlie”])\n",
            "# “Bob” para míY, si lo que hace falta es elegir aleatoriamente una muestra de elementos\n",
            "sin sustituto (es decir, sin duplicados), se puede utilizar \n",
            "random.sample\n",
            ":\n",
            "lottery_numbers = range(60)\n",
            "winning_numbers = random.sample(lottery_numbers,\n",
            "6)\n",
            "# [16, 36, 10, 6, 25,\n",
            "9]\n",
            "Para elegir una muestra de elementos con sustituto (es decir, que permita\n",
            "duplicados), simplemente basta con hacer varias llamadas a \n",
            "random.choice\n",
            ":\n",
            "four_with_replacement = [random.choice(range(10)) for _ in range(4)]\n",
            "print(four_with_replacement)\n",
            "# [9, 4, 4, 2]\n",
            "Expresiones regulares\n",
            "Las expresiones regulares ofrecen un modo de buscar texto. Son\n",
            "increíblemente útiles, pero también bastante complicadas (tanto, que hay\n",
            "escritos libros enteros sobre ellas). Entraremos en detalle las pocas veces que\n",
            "nos las encontremos; estos son algunos ejemplos de cómo utilizarlas en\n",
            "Python:\n",
            "import re\n",
            "re_examples = [\n",
            "# Todas son True, porque\n",
            "not re.match(\"a\", \"cat\"),\n",
            "# ‘cat’ no empieza por ‘a’\n",
            "re.search(\"a\", \"cat\"),\n",
            "# ‘cat’ contiene una ‘a’\n",
            "not re.search(\"c\", \"dog\"),\n",
            "# ‘dog’ no contiene una ‘c’.\n",
            "3 == len(re.split(\"[ab]\",\n",
            "\"carbs\")),\n",
            "# Partido en a o b para\n",
            "[‘c’,’r’,’s’].\n",
            "\"R-D-\" == re.sub(\"[0-9]\", \"-\",\n",
            "\"R2D2\")\n",
            "# Reemplaza dígitos por guiones.\n",
            "]\n",
            "assert all(re_examples), \"all the regex examples should be True\"\n",
            "Algo importante a tener en cuenta es que \n",
            "re.match\n",
            " comprueba si el\n",
            "principio de una cadena coincide con una expresión regular, mientras que\n",
            "re.search\n",
            " lo comprueba con alguna parte de una cadena. En algún momento\n",
            "es probable que se mezclen los dos y creen problemas.La documentación oficial en\n",
            "https://docs.python.org/es/3/library/re.html\n",
            " ofrece muchos más\n",
            "detalles.\n",
            "Programación funcional\n",
            "Nota:\n",
            " La primera edición de este libro presentaba en este momento las\n",
            "funciones de Python \n",
            "partial\n",
            ", \n",
            "map\n",
            ", \n",
            "reduce\n",
            " y \n",
            "filter\n",
            ". En mi viaje hacia la\n",
            "iluminación, me he dado cuenta de que es mejor evitarlas, y sus usos en el\n",
            "libro han sido reemplazados por comprensiones de listas, bucles \n",
            "for\n",
            " y otras\n",
            "construcciones más pitónicas.\n",
            "Empaquetado y desempaquetado de argumentos\n",
            "A menudo, necesitaremos empaquetar (\n",
            "zip\n",
            ") dos o más iterables juntos. La\n",
            "función \n",
            "zip\n",
            " transforma varios iterables en uno solo de tuplas de función\n",
            "correspondiente:\n",
            "list1 = [‘a’, ‘b’, ‘c’]\n",
            "list2 = [1, 2, 3]\n",
            "# zip es perezoso, de modo que hay que hacer algo como lo siguiente\n",
            "[pair for pair in zip(list1, list2)]\n",
            "# es [(‘a’, 1), (‘b’, 2), (‘c’, 3)]\n",
            "Si las listas tienen distintas longitudes, \n",
            "zip\n",
            " se detiene tan pronto como\n",
            "termina la primera lista.\n",
            "También se puede “desempaquetar” una lista utilizando un extraño truco:\n",
            "pairs = [(‘a’, 1), (‘b’, 2), (‘c’, 3)]\n",
            "letters, numbers = zip(*pairs)\n",
            "El asterisco (*) realiza desempaquetado de argumento, que utiliza los\n",
            "elementos de \n",
            "pairs\n",
            " como argumentos individuales para \n",
            "zip\n",
            ". Termina igual\n",
            "que si lo hubiéramos llamado:\n",
            "letters, numbers = zip((‘a’, 1), (‘b’, 2), (‘c’, 3))Se puede utilizar desempaquetado de argumento con cualquier función:\n",
            "def add(a, b): return a + b\n",
            "add(1, 2)\n",
            "# devuelve 3\n",
            "try:\n",
            "add([1, 2])\n",
            "except TypeError:\n",
            "print(\"add expects two inputs\")\n",
            "add(*[1, 2])\n",
            "# devuelve 3\n",
            "Es raro que encontremos esto útil, pero, cuando lo hacemos, es un truco\n",
            "genial.\n",
            "args y kwargs\n",
            "Digamos que queremos crear una función de máximo orden que requiere\n",
            "como entrada una función \n",
            "f\n",
            " y devuelve una función nueva que para cualquier\n",
            "entrada devuelve el doble del valor de \n",
            "f\n",
            ":\n",
            "def doubler(f):\n",
            "# Aquí definimos una nueva función que mantiene una referencia a f\n",
            "def g(x):\n",
            "return 2 * f(x)\n",
            "# Y devuelve esa nueva función\n",
            "return g\n",
            "Esto funciona en algunos casos:\n",
            "def f1(x):\n",
            "return x + 1\n",
            "g = doubler(f1)\n",
            "assert g(3) == 8, \"(3 + 1) * 2 should equal 8\"\n",
            "assert g(-1) == 0, \"(-1 + 1) * 2 should equal 0\"\n",
            "Sin embargo, no sirve con funciones que requieren algo más que un solo\n",
            "argumento:\n",
            "def f2(x, y):return x + y\n",
            "g = doubler(f2)\n",
            "try:\n",
            "g(1, 2)\n",
            "except TypeError:\n",
            "print(\"cas defined, g only takes one argument\")\n",
            "Lo que necesitamos es una forma de especificar una función que tome\n",
            "argumentos arbitrarios. Podemos hacerlo con desempaquetado de argumento\n",
            "y un poco de magia:\n",
            "def magic(*args, **kwargs):\n",
            "print(\"unnamed args:\", args)\n",
            "print(\"keyword args:\", kwargs)\n",
            "magic(1, 2, key=\"word\", key2=\"word2\")\n",
            "# imprime\n",
            "# argumentos sin nombre: (1, 2)\n",
            "# argumentos de palabra clave: {‘key’: ‘word’, ‘key2’: ‘word2’}\n",
            "Es decir, cuando definimos una función como esta, \n",
            "args\n",
            " es una tupla de\n",
            "sus argumentos sin nombre y \n",
            "kwargs\n",
            " es un \n",
            "dict\n",
            " de sus argumentos con\n",
            "nombre. Funciona también a la inversa, si queremos utilizar una \n",
            "list\n",
            " (o\n",
            "tuple\n",
            ") y \n",
            "dict\n",
            " para proporcionar argumentos a una función:\n",
            "def other_way_magic(x, y, z):\n",
            "return x + y + z\n",
            "x_y_list = [1, 2]\n",
            "z_dict = {\"z\": 3}\n",
            "assert other_way_magic(*x_y_list, **z_dict) == 6, \"1 + 2 + 3 should be 6\"\n",
            "Se podría hacer todo tipo de trucos extraños con esto; solo lo utilizaremos\n",
            "para producir funciones de máximo orden cuyas entradas puedan aceptar\n",
            "argumentos arbitrarios:\n",
            "def doubler_correct(f):\n",
            "\"\"\"works no matter what kind of inputs f expects\"\"\"\n",
            "def g(*args, **kwargs):\n",
            "\"\"\"whatever arguments g is supplied, pass them through to f\"\"\"\n",
            "return 2 * f(*args, **kwargs)\n",
            "return gg = doubler_correct(f2)\n",
            "assert g(1, 2) == 6, \"doubler should work now\"\n",
            "Como regla general, el código que escribamos será más correcto y legible\n",
            "si somos explícitos en lo que se refiere a los tipos de argumentos que las\n",
            "funciones que usemos requieren; de ahí que vayamos a utilizar \n",
            "args\n",
            " y \n",
            "kwargs\n",
            "solo cuando no tengamos otra opción.\n",
            "Anotaciones de tipos\n",
            "Python es un lenguaje de tipos dinámicos. Esto significa que en general no\n",
            "le importan los tipos de objetos que utilicemos, siempre que lo hagamos de\n",
            "formas válidas:\n",
            "def add(a, b):\n",
            "return a + b\n",
            "assert add(10, 5) == 15, \"+ is valid for numbers\"\n",
            "assert add([1, 2], [3]) == [1, 2, 3], \"+ is valid for lists\"\n",
            "assert add(\"hi \", \"there\") == \"hi there\", \"+ is valid for strings\"\n",
            "try:\n",
            "add(10, \"five\")\n",
            "except TypeError:\n",
            "print(\"cannot add an int to a string\")\n",
            "Mientras que en un lenguaje de tipos estáticos nuestras funciones y\n",
            "objetos tendrían tipos específicos:\n",
            "def add(a: int, b: int) -> int:\n",
            "return a + b\n",
            "add(10, 5)\n",
            "# le gustaría que esto fuera correcto\n",
            "add(\"hi \", \"there\")\n",
            "# le gustaría que esto no fuera correcto\n",
            "En realidad, las versiones más recientes de Python tienen (más o menos)\n",
            "esta funcionalidad. ¡La versión anterior de \n",
            "add\n",
            " con las anotaciones de tipos\n",
            "int\n",
            " es válida en Python 3.6! Sin embargo, estas anotaciones de tipos no\n",
            "hacen realmente nada. Aún se puede utilizar la función anotada \n",
            "add\n",
            " paraañadir cadenas, y la llamada a \n",
            "add(10,\n",
            " \n",
            "“five”)\n",
            " seguirá levantando\n",
            "exactamente el mismo \n",
            "TypeError\n",
            ".\n",
            "Dicho esto, sigue habiendo (al menos) cuatro buenas razones para utilizar\n",
            "anotaciones de tipos en el código Python que escribamos:\n",
            "■\n",
            "Los tipos son una forma importante de documentación. Esto es\n",
            "doblemente cierto en un libro que utiliza código para enseñar\n",
            "conceptos teóricos y matemáticos. Comparemos las siguientes dos\n",
            "líneas de función:\n",
            "def dot_product(x, y): ...\n",
            "# aún no hemos definido Vector, pero imagínese que lo habíamos hecho\n",
            "def dot_product(x: Vector, y: Vector) -> float: ...\n",
            "Encuentro el segundo extremadamente más informativo; espero que\n",
            "también se lo parezca (en este punto me he acostumbrado tanto a la\n",
            "determinación de tipos que ahora sin ello encuentro Python difícil de\n",
            "leer).\n",
            "■\n",
            "Hay herramientas externas (siendo la más popular \n",
            "mypy\n",
            ") que leerán el\n",
            "código que escribamos, inspeccionarán las anotaciones de tipos y\n",
            "ofrecerán errores de tipos antes siquiera de ejecutar el código. Por\n",
            "ejemplo, si ejecutamos \n",
            "mypy\n",
            " en un archivo que contiene \n",
            "add(“hi\n",
            "“,”there”)\n",
            ", avisaría de lo siguiente:\n",
            "error: Argument 1 to “add” has incompatible type “str”; expected “int”\n",
            "Al igual que la prueba \n",
            "assert\n",
            ", esta es una buena forma de encontrar\n",
            "errores en el código antes de ejecutarlo. La narración del libro no\n",
            "implicará tal comprobación de tipo; sin embargo, ejecutaré una en\n",
            "segundo plano, lo que me permitirá asegurarme de que el libro en sí es\n",
            "correcto.\n",
            "■\n",
            "Tener que pensar en los tipos de nuestro código nos obliga a diseñar\n",
            "funciones e interfaces más limpios:\n",
            "from typing import Union\n",
            "def secretly_ugly_function(value, operation): ...def ugly_function(value: int,\n",
            "operation: Union[str, int, float, bool]) -> int:\n",
            "...\n",
            "Aquí tenemos una función cuyo parámetro de operación puede ser un\n",
            "string\n",
            ", un \n",
            "int\n",
            ", un \n",
            "float\n",
            " o un \n",
            "bool\n",
            ". Es muy probable que esta función sea\n",
            "frágil y difícil de utilizar, pero aún queda más claro cuando los tipos resultan\n",
            "explícitos. Hacer esto nos obligará a diseñar de un modo menos torpe, cosa\n",
            "que nuestros usuarios nos agradecerán.\n",
            "■\n",
            "Utilizar tipos permite al editor que utilicemos ayudarnos con cosas\n",
            "como autocompletar (véase la figura 2.1) y enfadarnos por los errores\n",
            "de escritura.\n",
            "Figura 2.1. \n",
            "VSCode, pero probablemente otro editor haga lo mismo.\n",
            "A veces, la gente insiste en que las comprobaciones de tipo pueden ser\n",
            "valiosas en proyectos grandes, pero no merecen la pena en otros más\n",
            "pequeños. No obstante, como casi no se tardan nada en escribir y permiten al\n",
            "editor ahorrarnos tiempo, yo mantengo que de verdad permiten escribir\n",
            "código con mayor rapidez, incluso en proyectos pequeños.\n",
            "Por todas estas razones, todo el código del resto de este libro utilizará\n",
            "anotaciones de tipos. Supongo que algunos lectores se sentirán desanimados\n",
            "por utilizarlas, pero sospecho que al final del libro habrán cambiado de\n",
            "opinión.\n",
            "Cómo escribir anotaciones de tipos\n",
            "Como hemos visto, para tipos internos como \n",
            "int\n",
            ", \n",
            "bool\n",
            " y \n",
            "float\n",
            " basta con\n",
            "utilizar el propio tipo como anotación. Pero ¿qué pasa si tenemos (porejemplo) un \n",
            "list\n",
            "?\n",
            "def total(xs: list) -> float:\n",
            "return sum(total)\n",
            "Esto no es erróneo, pero el tipo no es lo bastante específico. Está claro que\n",
            "realmente queremos que \n",
            "xs\n",
            " sea un \n",
            "list\n",
            " de valores \n",
            "float\n",
            ", no (por ejemplo)\n",
            "un \n",
            "list\n",
            " de cadenas.\n",
            "El módulo \n",
            "typing\n",
            " ofrece una serie de tipos parametrizados que podemos\n",
            "utilizar para hacer precisamente esto:\n",
            "from typing import List\n",
            "# observe la L mayúscula\n",
            "def total(xs: List[float]) -> float:\n",
            "return sum(total)\n",
            "Hasta ahora hemos especificado solamente anotaciones para parámetros\n",
            "de función y tipos de retorno. Para las propias variables suele ser obvio cuál\n",
            "es el tipo:\n",
            "# Así es como se anota el tipo de variables cuando se definen.\n",
            "# Pero esto es innecesario; es \"obvio\" que x es un int.\n",
            "x: int = 5\n",
            "No obstante, algunas veces no es obvio:\n",
            "values = []\n",
            "# ¿cuál es mi tipo?\n",
            "best_so_far = None\n",
            "# ¿cuál es mi tipo?\n",
            "En estos casos suministraremos las comprobaciones de tipos \n",
            "inline\n",
            ":\n",
            "from typing import Optional\n",
            "values: List[int] = []\n",
            "best_so_far: Optional[float] = None\n",
            "# permitido ser un float o None\n",
            "El módulo \n",
            "typing\n",
            " contiene muchos otros tipos, de los que solo\n",
            "emplearemos unos pocos:\n",
            "# las anotaciones de tipo de este fragmento son todas innecesarias\n",
            "from typing import Dict, Iterable, Tuple# las claves son strings, los valores son ints\n",
            "counts: Dict[str, int] = {‘data’: 1, ‘science’: 2}\n",
            "# las listas y los generadores son ambos iterables\n",
            "if lazy:\n",
            "evens: Iterable[int] = (x for x in range(10) if x % 2 == 0)\n",
            "else:\n",
            "evens = [0, 2, 4, 6, 8]\n",
            "# las tuplas especifican un tipo para cada elemento\n",
            "triple: Tuple[int, float, int] = (10, 2.3, 5)\n",
            "Finalmente, como Python tiene funciones de primera clase, necesitamos\n",
            "un tipo que las represente también. Este es un ejemplo bastante forzado:\n",
            "from typing import Callable\n",
            "# La comprobación de tipos dice que el repetidor es una función que admite\n",
            "# dos argumentos, un string y un int, y devuelve un string.\n",
            "def twice(repeater: Callable[[str, int], str], s: str) -> str:\n",
            "return repeater(s, 2)\n",
            "def comma_repeater(s: str, n: int) -> str:\n",
            "n_copies = [s for _ in range(n)]\n",
            "return ‘, ‘.join(n_copies)\n",
            "assert twice(comma_repeater, \"type hints\") == \"type hints, type hints\"\n",
            "Como las anotaciones de tipos son solo objetos Python, podemos\n",
            "asignarles variables para que sea más fácil hacer referencia a ellos:\n",
            "Number = int\n",
            "Numbers = List[Number]\n",
            "def total(xs: Numbers) -> Number:\n",
            "return sum(xs)\n",
            "Para cuando lleguemos al final del libro, el lector estará bastante\n",
            "familiarizado con leer y escribir anotaciones de tipos, y espero que las utilice\n",
            "en su código.\n",
            "Bienvenido a DataSciencester\n",
            "Esto concluye la orientación al empleado. Ah, otra cosa: intente no“distraer” nada.\n",
            "Para saber más\n",
            "■\n",
            "No faltan tutoriales de Python en el mundo. El oficial en\n",
            "https://docs.python.org/es/3/tutorial/\n",
            " no es mal punto de\n",
            "partida para empezar.\n",
            "■\n",
            "El tutorial oficial de IPython en\n",
            "http://ipython.readthedocs.io/en/stable/interactive/index.html\n",
            "le permitirá empezar con IPython, si decide utilizarlo. Por favor,\n",
            "utilícelo.\n",
            "■\n",
            "La documentación de \n",
            "mypy\n",
            " en\n",
            "https://mypy.readthedocs.io/en/stable/\n",
            " le dará más información\n",
            "de la que nunca quiso tener sobre anotaciones de tipos y\n",
            "comprobaciones de tipos de Python.\n",
            "1\n",
            " \n",
            "http://legacy.python.org/dev/peps/pep-0020/\n",
            "2\n",
            " \n",
            "https://github.com/joelgrus/data-science-from-scratch/blob/master/INSTALL.md\n",
            ".\n",
            "3\n",
            " \n",
            "https://www.python.org/\n",
            ".\n",
            "4\n",
            " \n",
            "https://www.anaconda.com/products/distribution\n",
            ".\n",
            "5\n",
            " \n",
            "https://docs.python.org/es/3/library/venv.html\n",
            ".\n",
            "6\n",
            " \n",
            "https://virtualenv.pypa.io/en/latest/\n",
            ".\n",
            "7\n",
            " \n",
            "http://ipython.org/\n",
            ".3\n",
            " Visualizar datos\n",
            "Creo que la visualización es uno de los medios más poderosos de lograr objetivos\n",
            "personales.\n",
            "—Harvey Mackay\n",
            "La visualización de datos es una parte fundamental del kit de herramientas\n",
            "de un científico de datos. Es muy fácil crear visualizaciones, pero es mucho\n",
            "más difícil lograr que sean buenas. Tiene dos usos principales:\n",
            "■\n",
            "Explorar datos.\n",
            "■\n",
            "Comunicar datos.\n",
            "En este capítulo, nos centraremos en adquirir las habilidades necesarias\n",
            "para empezar a explorar nuestros propios datos y producir las visualizaciones\n",
            "que vamos a utilizar a lo largo del libro. Al igual que la mayoría de los temas\n",
            "que se tratan en sus capítulos, la visualización de datos es un campo de\n",
            "estudio tan profundo que merece un libro entero. No obstante, trataré de darle\n",
            "una idea de lo que conduce a una buena visualización de datos y lo que no.\n",
            "matplotlib\n",
            "Existe una gran variedad de herramientas para visualizar datos.\n",
            "Emplearemos la librería de matplotlib\n",
            "1\n",
            ", la más utilizada (aunque ya se le\n",
            "notan un poco los años). Si lo que queremos es producir una visualización\n",
            "elaborada e interactiva para la web, probablemente no es la mejor opción,\n",
            "pero sirve a la perfección para sencillos gráficos de barras, líneas y\n",
            "dispersión. Como ya mencioné anteriormente, matplotlib no es parte de la\n",
            "librería esencial de Python. Con el entorno virtual activado (para configurar\n",
            "uno, repase las instrucciones dadas en el apartado “Entornos virtuales” del\n",
            "capítulo 2), lo instalamos utilizando este comando:python -m pip install matplotlib\n",
            "Emplearemos el módulo \n",
            "matplotlib.pyplot\n",
            ". En su uso más sencillo,\n",
            "pyplot\n",
            " mantiene un estado interno en el que se crea una visualización paso a\n",
            "paso. En cuanto está lista, se puede guardar con \n",
            "savefig\n",
            " o mostrar con \n",
            "show\n",
            ".\n",
            "Por ejemplo, hacer gráficos simples (como el de la figura 3.1) es bastante\n",
            "fácil:\n",
            "from matplotlib import pyplot as plt\n",
            "years = [1950, 1960, 1970, 1980, 1990, 2000, 2010]\n",
            "gdp = [300.2, 543.3, 1075.9, 2862.5, 5979.6, 10289.7, 14958.3]\n",
            "# crea un gráfico de líneas, años en el eje x, cantidades en el eje y\n",
            "plt.plot(years, gdp, color=’green’, marker=’o’, linestyle=’solid’)\n",
            "# añade un título\n",
            "plt.title(\"Nominal GDP\")\n",
            "# añade una etiqueta al eje y\n",
            "plt.ylabel(\"Billions of $\")\n",
            "plt.show()\n",
            "Figura 3.1. \n",
            "Un sencillo gráfico de líneas.\n",
            "Crear gráficos con una calidad apta para publicaciones es más complicado,y va más allá del objetivo de este capítulo. Hay muchas formas de\n",
            "personalizar los gráficos, por ejemplo, con etiquetas de ejes, estilos de línea y\n",
            "marcadores de puntos. En lugar de explicar estas opciones con todo detalle,\n",
            "simplemente utilizaremos algunas en nuestros ejemplos (y llamaré la atención\n",
            "sobre ello).\n",
            "Nota:\n",
            " Aunque no vayamos a utilizar mucho esta funcionalidad, matplotlib es\n",
            "capaz de producir complicados gráficos dentro de gráficos, aplicar formato de\n",
            "maneras sofisticadas y crear visualizaciones interactivas. En su documentación\n",
            "se puede encontrar información más detallada de la que ofrecemos en este\n",
            "libro.\n",
            "Gráficos de barras\n",
            "Un gráfico de barras es una buena elección cuando se desea mostrar cómo\n",
            "varía una cierta cantidad a lo largo de un conjunto discreto de elementos. Por\n",
            "ejemplo, la figura 3.2 muestra el número de Óscar que les fueron otorgados a\n",
            "cada una de una serie de películas:\n",
            "movies = [\"Annie Hall\", \"Ben-Hur\", \"Casablanca\", \"Gandhi\", \"West Side Story\"]\n",
            "num_oscars = [5, 11, 3, 8, 10]\n",
            "# dibuja barras con coordenadas x de la izquierda [0, 1, 2, 3, 4], alturas\n",
            "[num_oscars]\n",
            "plt.bar(range(len(movies)), num_oscars)\n",
            "plt.title(\"My Favorite Movies\")\n",
            "# añade un título\n",
            "plt.ylabel(\"# of Academy Awards\")\n",
            "# etiqueta el eje y\n",
            "# etiqueta el eje x con los nombres de las películas en el centro de las barras\n",
            "plt.xticks(range(len(movies)), movies)\n",
            "plt.show()\n",
            "Un gráfico de barras también puede ser una buena opción para trazar\n",
            "histogramas de valores numéricos ordenados por cubos o \n",
            "buckets\n",
            ", como en la\n",
            "figura 3.3, con el fin de explorar visualmente el modo en que los valores\n",
            "están distribuidos:\n",
            "from collections import Countergrades = [83, 95, 91, 87, 70, 0, 85, 82, 100, 67, 73, 77, 0]\n",
            "# Agrupa las notas en bucket por decil, pero pone 100 con los 90\n",
            "histogram = Counter(min(grade // 10 * 10, 90) for grade in grades)\n",
            "plt.bar([x + 5 for x in\n",
            "histogram.keys()],\n",
            "# Mueve barras a la derecha en 5\n",
            "histogram.values(),\n",
            "# Da a cada barra su altura\n",
            "correcta\n",
            "10,\n",
            "# Da a cada barra una anchura de 10\n",
            "edgecolor=(0, 0, 0))\n",
            "# Bordes negros para cada barra\n",
            "plt.axis([-5, 105, 0, 5])\n",
            "# eje x desde -5 hasta 105,\n",
            "# eje y desde 0 hasta 5\n",
            "plt.xticks([10 * i for i in\n",
            "range(11)])\n",
            "# etiquetas de eje x en 0, 10, ...,\n",
            "100\n",
            "plt.xlabel(\"Decile\")\n",
            "plt.ylabel(\"# of Students\")\n",
            "plt.title(\"Distribution of Exam 1\n",
            "Grades\")\n",
            "plt.show()\n",
            "Figura 3.2. \n",
            "Un sencillo gráfico de barras.Figura 3.3. \n",
            "Utilizando un gráfico de barras para un histograma.\n",
            "El tercer argumento de \n",
            "plt.bar\n",
            " especifica la anchura de las barras. Hemos\n",
            "elegido una anchura de 10, para llenar así todo el decil. También hemos\n",
            "desplazado las barras a la derecha en 5, de forma que, por ejemplo, la barra\n",
            "“10” (que corresponde al decil 10-20) tendría su centro en 15 y, por lo tanto,\n",
            "ocuparía el rango correcto. También añadimos un borde negro a cada barra\n",
            "para distinguirlas de forma visual.\n",
            "La llamada a \n",
            "plt.axis\n",
            " indica que queremos que el eje x vaya desde -5\n",
            "hasta 105 (solo para dejar un poco de espacio a la izquierda y a la derecha), y\n",
            "que el eje y varíe de 0 a 5; la llamada a \n",
            "plt.xticks\n",
            " pone las etiquetas del eje\n",
            "x en 0, 10, 20, ..., 100.\n",
            "Conviene ser juiciosos al utilizar \n",
            "plt.axis\n",
            ". Cuando se crean gráficos de\n",
            "barras, está especialmente mal considerado que el eje y no empiece en 0, ya\n",
            "que de ese modo la gente se confunde con mucha facilidad (véase la figura\n",
            "3.4):\n",
            "mentions = [500, 505]\n",
            "years = [2017, 2018]\n",
            "plt.bar(years, mentions, 0.8)plt.xticks(years)\n",
            "plt.ylabel(\"# of times I heard someone say ‘data science’\")\n",
            "# si no se hace esto, matplotlib etiquetará el eje x con 0, 1\n",
            "# y añadirá +2.013e3 en la esquina (¡qué malo es matplotlib!)\n",
            "plt.ticklabel_format(useOffset=False)\n",
            "# el eje y erróneo solo muestra la parte sobre 500\n",
            "plt.axis([2016.5, 2018.5, 499, 506])\n",
            "plt.title(\"Look at the ‘Huge’ Increase!\")\n",
            "plt.show()\n",
            "Figura 3.4. \n",
            "Un gráfico con el eje y erróneo.\n",
            "En la figura 3.5 utilizamos ejes más sensatos, aunque así no queda tan\n",
            "impresionante:\n",
            "plt.axis([2016.5, 2018.5, 0, 550])\n",
            "plt.title(\"Not So Huge Anymore\")\n",
            "plt.show()Figura 3.5. \n",
            "El mismo gráfico con un eje y nada confuso.\n",
            "Gráficos de líneas\n",
            "Como ya hemos visto, podemos hacer gráficos de líneas utilizando\n",
            "plt.plot\n",
            ". Son una buena elección para mostrar tendencias, como se ilustra\n",
            "en la figura 3.6:\n",
            "variance = [1, 2, 4, 8, 16, 32, 64, 128, 256]\n",
            "bias_squared = [256, 128, 64, 32, 16, 8, 4, 2, 1]\n",
            "total_error = [x + y for x, y in zip(variance, bias_squared)]\n",
            "xs = [i for i, _ in enumerate(variance)]\n",
            "# Podemos hacer varias llamadas a plt.plot\n",
            "# para mostrar varias series en el mismo gráfico\n",
            "plt.plot(xs, variance, ‘g-’, label=’variance’)\n",
            "# línea continua\n",
            "plt.plot(xs, bias_squared, ‘r-.’, label=’bias^2’)\n",
            "# línea de puntos y guiones\n",
            "plt.plot(xs, total_error, ‘b:’, label=’total error’)\n",
            "# línea de puntos\n",
            "# Como asignamos etiquetas a cada serie,\n",
            "# obtenemos una leyenda gratis (loc=9 significa \"arriba centro\")\n",
            "plt.legend(loc=9)plt.xlabel(\"model complexity\")\n",
            "plt.xticks([])\n",
            "plt.title(\"The Bias-Variance Tradeoff\")\n",
            "plt.show()\n",
            "Figura 3.6. \n",
            "Varios gráficos de líneas con una leyenda.\n",
            "Gráficos de dispersión\n",
            "Un gráfico de dispersión es la opción adecuada para visualizar la relación\n",
            "entre dos conjuntos de datos emparejados. Por ejemplo, la figura 3.7 ilustra la\n",
            "relación entre el número de amigos que tienen sus usuarios y el número de\n",
            "minutos que pasan cada día en el sitio:\n",
            "friends = [ 70, 65, 72, 63, 71, 64, 60, 64, 67]\n",
            "minutes = [175, 170, 205, 120, 220, 130, 105, 145, 190]\n",
            "labels = [‘a’, ‘b’, ‘c’, ‘d’, ‘e’, ‘f’, ‘g’, ‘h’, ‘i’]\n",
            "plt.scatter(friends, minutes)\n",
            "# etiqueta cada punto\n",
            "for label, friend_count, minute_count in zip(labels, friends, minutes):\n",
            "plt.annotate(label,xy=(friend_count, minute_count),\n",
            "# Pone la etiqueta con su punto\n",
            "xytext=(5, -5),\n",
            "# pero un poco desplazada\n",
            "textcoords=’offset points’)\n",
            "plt.title(\"Daily Minutes vs. Number of Friends\")\n",
            "plt.xlabel(\"# of friends\")\n",
            "plt.ylabel(\"daily minutes spent on the site\")\n",
            "plt.show()\n",
            "Si estamos representando variables comparables, podríamos obtener una\n",
            "imagen confusa si dejáramos que matplotlib eligiera la escala, como en la\n",
            "figura 3.8.\n",
            "Figura 3.7. \n",
            "Un gráfico de dispersión de amigos y tiempo en el sitio.\n",
            "ºwFigura 3.8. \n",
            "Un gráfico de dispersión con ejes imposibles de comparar.\n",
            "test_1_grades = [ 99, 90, 85, 97, 80]\n",
            "test_2_grades = [100, 85, 60, 90, 70]\n",
            "plt.scatter(test_1_grades, test_2_grades)\n",
            "plt.title(\"Axes Aren’t Comparable\")\n",
            "plt.xlabel(\"test 1 grade\")\n",
            "plt.ylabel(\"test 2 grade\")\n",
            "plt.show()\n",
            "Si incluimos una llamada a \n",
            "plt.axis(“equal”)\n",
            ", el gráfico (figura 3.9)\n",
            "muestra con mayor precisión que la mayor parte de la variación tiene lugar en\n",
            "la prueba 2.\n",
            "Con esto basta para empezar con la visualización. Aprenderemos mucho\n",
            "más sobre la visualización a lo largo del libro.Figura 3.9. \n",
            "El mismo gráfico de dispersión con ejes iguales.\n",
            "Para saber más\n",
            "■\n",
            "La galería de matplotlib, en\n",
            "https://matplotlib.org/stable/gallery/index.html\n",
            ", da una idea\n",
            "bastante buena del tipo de cosas que se pueden hacer con matplotlib (y\n",
            "de cómo hacerlas).\n",
            "■\n",
            "seaborn, en \n",
            "https://seaborn.pydata.org/\n",
            ", se ha creado en base a\n",
            "matplotlib y permite producir fácilmente visualizaciones más bonitas\n",
            "(y complejas).\n",
            "■\n",
            "Altair, en \n",
            "https://altair-viz.github.io/\n",
            ", es una nueva librería de\n",
            "Python para crear visualizaciones declarativas.\n",
            "■\n",
            "D3.js, en \n",
            "https://d3js.org\n",
            ", es una librería de JavaScript para\n",
            "producir sofisticadas visualizaciones interactivas para la web. Aunque\n",
            "no está en Python, se utiliza mucho y vale la pena familiarizarse con\n",
            "ella.\n",
            "■\n",
            "Bokeh, en \n",
            "https://bokeh.pydata.org\n",
            ", es una librería que permite\n",
            "incorporar a Python visualizaciones de estilo D3.1\n",
            " \n",
            "https://matplotlib.org/\n",
            ".4\n",
            " Álgebra lineal\n",
            "¿Hay algo más inútil o menos útil que el álgebra?\n",
            "—Billy Conolly\n",
            "El álgebra lineal es la rama de las matemáticas que se ocupa de los\n",
            "espacios vectoriales. Aunque no espero que el lector aprenda álgebra lineal en\n",
            "un breve capítulo, se apoya en un gran número de conceptos y técnicas de\n",
            "ciencia de datos, lo que significa que al menos les debo un intento. Lo que\n",
            "vamos a aprender en este capítulo lo utilizaremos mucho a lo largo del libro.\n",
            "Vectores\n",
            "Definidos de una forma abstracta, los vectores son objetos que se pueden\n",
            "sumar para formar nuevos vectores y se pueden multiplicar por escalares (es\n",
            "decir, números), también para formar nuevos vectores.\n",
            "De una forma más concreta (para nosotros), digamos que los vectores son\n",
            "puntos de un espacio de dimensión finita. Aunque no se nos suele ocurrir\n",
            "pensar en los datos como vectores, a menudo son una forma útil de\n",
            "representar datos numéricos.\n",
            "Por ejemplo, si tenemos las alturas, pesos y edades de un gran número de\n",
            "personas, podemos tratar los datos como vectores tridimensionales \n",
            "[height,\n",
            "weight,\n",
            " \n",
            "age]\n",
            ". Si tuviéramos una clase con cuatro exámenes, podríamos\n",
            "tratar las notas de los alumnos como vectores de cuatro dimensiones \n",
            "[exam1,\n",
            "exam2,\n",
            " \n",
            "exam3,\n",
            " \n",
            "exam4]\n",
            ".\n",
            "El enfoque más sencillo para aprender esto desde cero es representar los\n",
            "vectores como una lista de números. Una lista de tres números corresponde a\n",
            "un vector en un espacio tridimensional y viceversa.\n",
            "Realizaremos esto con un alias de tipo que dice que un \n",
            "Vector\n",
            " es solo una\n",
            "list\n",
            " de valores de tipo \n",
            "float\n",
            ":from typing import List\n",
            "Vector = List[float]\n",
            "height_weight_age = [70,\n",
            "# pulgadas,\n",
            "170,\n",
            "# libras,\n",
            "40 ]\n",
            "# años\n",
            "grades = [95,\n",
            "# examen1\n",
            "80,\n",
            "# examen2\n",
            "75,\n",
            "# examen3\n",
            "62 ]\n",
            "# examen4\n",
            "También querremos realizar aritmética con los vectores. Como las \n",
            "list\n",
            " de\n",
            "Python no son vectores (y por lo tanto no dan facilidades para la aritmética\n",
            "con vectores), tendremos que crear nosotros mismos estas herramientas de\n",
            "aritmética. Así que vamos allá.\n",
            "Para empezar, muy a menudo necesitaremos sumar dos vectores. Los\n",
            "vectores se suman componente a componente, lo que significa que, si dos\n",
            "vectores \n",
            "v\n",
            " y \n",
            "w\n",
            " tienen la misma longitud, su suma es sencillamente el vector\n",
            "cuyo primer elemento es \n",
            "v[0]\n",
            " \n",
            "+\n",
            " \n",
            "w[0]\n",
            ", cuyo segundo elemento es \n",
            "v[1]\n",
            " \n",
            "+\n",
            "w[1]\n",
            ", y así sucesivamente (si no tienen la misma longitud, entonces no se\n",
            "pueden sumar). Por ejemplo, sumar los vectores \n",
            "[1,\n",
            " \n",
            "2]\n",
            " y \n",
            "[2,\n",
            " \n",
            "1]\n",
            " da como\n",
            "resultado \n",
            "[1\n",
            " \n",
            "+\n",
            " \n",
            "2,\n",
            " \n",
            "2\n",
            " \n",
            "+\n",
            " \n",
            "1]\n",
            " o \n",
            "[3,3]\n",
            ", como muestra la figura 4.1.\n",
            "Podemos implementar esto fácilmente comprimiendo los vectores con \n",
            "zip\n",
            "y utilizando una comprensión de lista para sumar los elementos\n",
            "correspondientes:\n",
            "def add(v: Vector, w: Vector) -> Vector:\n",
            "\"\"\"Adds corresponding elements\"\"\"\n",
            "assert len(v) == len(w), \"vectors must be the same length\"\n",
            "return [v_i + w_i for v_i, w_i in zip(v, w)]\n",
            "assert add([1, 2, 3], [4, 5, 6]) == [5, 7, 9]\n",
            "De forma similar, para restar dos vectores simplemente restamos los\n",
            "elementos correspondientes:\n",
            "def subtract(v: Vector, w: Vector) -> Vector:\n",
            "\"\"\"Subtracts corresponding elements\"\"\"\n",
            "assert len(v) == len(w), \"vectors must be the same length\"\n",
            "return [v_i–w_i for v_i, w_i in zip(v, w)]assert subtract([5, 7, 9], [4, 5, 6]) == [1, 2, 3]\n",
            "Figura 4.1. \n",
            "Sumando dos vectores.\n",
            "También querremos en ocasiones sumar una lista de vectores por\n",
            "componentes (es decir, crear un nuevo vector cuyo primer elemento es la\n",
            "suma de todos los primeros elementos y cuyo segundo elemento es la suma\n",
            "de todos los segundos elementos, y así sucesivamente):\n",
            "def vector_sum(vectors: List[Vector]) -> Vector:\n",
            "\"\"\"Sums all corresponding elements\"\"\"\n",
            "# Comprueba que los vectores no estén vacíos\n",
            "assert vectors, \"no vectors provided!\"\n",
            "# Comprueba que los vectores tienen el mismo tamaño\n",
            "num_elements = len(vectors[0])\n",
            "assert all(len(v) == num_elements for v in vectors), \"different sizes!\"\n",
            "# el elemento i del resultado es la suma de cada vector [i]\n",
            "return [sum(vector[i] for vector in vectors)\n",
            "for i in range(num_elements)]\n",
            "assert vector_sum([[1, 2], [3, 4], [5, 6], [7, 8]]) == [16, 20]\n",
            "También tendremos que ser capaces de multiplicar un vector por un\n",
            "escalar, cosa que hacemos sencillamente multiplicando cada elemento delvector por dicho número:\n",
            "def scalar_multiply(c: float, v: Vector) -> Vector:\n",
            "\"\"\"Multiplies every element by c\"\"\"\n",
            "return [c * v_i for v_i in v]\n",
            "assert scalar_multiply(2, [1, 2, 3]) == [2, 4, 6]\n",
            "Esto nos permite calcular la media por componentes de una lista de\n",
            "vectores (del mismo tamaño):\n",
            "def vector_mean(vectors: List[Vector]) -> Vector:\n",
            "\"\"\"Computes the element-wise average\"\"\"\n",
            "n = len(vectors)\n",
            "return scalar_multiply(1/n, vector_sum(vectors))\n",
            "assert vector_mean([[1, 2], [3, 4], [5, 6]]) == [3, 4]\n",
            "Una herramienta menos obvia es el producto punto. El producto punto de\n",
            "dos vectores es la suma de los productos de sus componentes:\n",
            "def dot(v: Vector, w: Vector) -> float:\n",
            "\"\"\"Computes v_1 * w_1 + ... + v_n * w_n\"\"\"\n",
            "assert len(v) == len(w), \"vectors must be same length\"\n",
            "return sum(v_i * w_i for v_i, w_i in zip(v, w))\n",
            "assert dot([1, 2, 3], [4, 5, 6]) == 32\n",
            "# 1 * 4 + 2 * 5 + 3 * 6\n",
            "Si \n",
            "w\n",
            " tiene magnitud 1, el producto punto mide hasta dónde se extiende el\n",
            "vector \n",
            "v\n",
            " en la dirección \n",
            "w\n",
            ". Por ejemplo, si \n",
            "w\n",
            " \n",
            "=\n",
            " \n",
            "[1,\n",
            " \n",
            "0]\n",
            ", entonces \n",
            "dot(v,\n",
            " \n",
            "w)\n",
            " es\n",
            "el primer componente de \n",
            "v\n",
            ". Otra forma de decir esto es que es la longitud del\n",
            "vector que se obtendría si se proyectara \n",
            "v\n",
            " en \n",
            "w\n",
            " (véase la figura 4.2).Figura 4.2. \n",
            "El producto punto como proyección de vector.\n",
            "Utilizando esto, es fácil calcular la suma de cuadrados de un vector:\n",
            "def sum_of_squares(v: Vector) -> float:\n",
            "\"\"\"Returns v_1 * v_1 + ... + v_n * v_n\"\"\"\n",
            "return dot(v, v)\n",
            "assert sum_of_squares([1, 2, 3]) == 14\n",
            "# 1 * 1 + 2 * 2 + 3 * 3\n",
            "Que podemos utilizar para calcular su magnitud (o longitud):\n",
            "import math\n",
            "def magnitude(v: Vector) -> float:\n",
            "\"\"\"Returns the magnitude (or length) of v\"\"\"\n",
            "return\n",
            "math.sqrt(sum_of_squares(v))\n",
            "# math.sqrt es la función raíz\n",
            "cuadrada\n",
            "assert magnitude([3, 4]) == 5\n",
            "Ahora tenemos todas las piezas necesarias para calcular la distancia entre\n",
            "dos vectores, definida como:En código:\n",
            "def squared_distance(v: Vector, w: Vector) -> float:\n",
            "\"\"\"Computes (v_1–w_1) ** 2 + ... + (v_n–w_n) ** 2\"\"\"\n",
            "return sum_of_squares(subtract(v, w))\n",
            "def distance(v: Vector, w: Vector) -> float:\n",
            "\"\"\"Computes the distance between v and w\"\"\"\n",
            "return math.sqrt(squared_distance(v, w))\n",
            "Quizá esto quede más claro si lo escribimos como (el equivalente):\n",
            "def distance(v: Vector, w: Vector) -> float:\n",
            "return magnitude(subtract(v, w))\n",
            "Esto debería ser suficiente para empezar. Vamos a utilizar muchísimo\n",
            "estas funciones a lo largo del libro.\n",
            "Nota:\n",
            " Utilizar listas como vectores es excelente de cara a la galería, pero\n",
            "terrible para el rendimiento.\n",
            "En código de producción, nos interesará más utilizar la librería NumPy, que\n",
            "incluye una clase de objetos \n",
            "array\n",
            " de alto rendimiento con todo tipo de\n",
            "operaciones aritméticas incluidas.\n",
            "Matrices\n",
            "Una matriz es una colección de números bidimensional. Representaremos\n",
            "las matrices como listas de listas, teniendo cada lista interior el mismo\n",
            "tamaño y representando una fila de la matriz. Si \n",
            "A\n",
            " es una matriz, entonces\n",
            "A[i][j]\n",
            " es el elemento de la fila\n",
            " i\n",
            " y la columna \n",
            "j\n",
            ". Por convenio matemático,\n",
            "utilizaremos con frecuencia letras mayúsculas para representar matrices. Por\n",
            "ejemplo:# Otro alias de tipo\n",
            "Matrix = List[List[float]]\n",
            "A = [[1, 2, 3],\n",
            "# A tiene 2 filas y 3 columnas\n",
            "[4, 5, 6]]\n",
            "B = [[1, 2],\n",
            "# B tiene 3 filas y 2 columnas\n",
            "[3, 4],\n",
            "[5, 6]]\n",
            "Nota:\n",
            " En matemáticas, se suele denominar a la primera fila de la matriz “fila 1”\n",
            "y a la primera columna “columna 1”. Como estamos representando matrices\n",
            "con \n",
            "list\n",
            " de Python, que están indexadas al 0, llamaremos a la primera fila de\n",
            "la matriz “fila 0” y a la primera columna “columna 0”.\n",
            "Dada esta representación de lista de listas, la matriz \n",
            "A\n",
            " tiene \n",
            "len(A)\n",
            " filas y\n",
            "len(A[0])\n",
            " columnas, lo que consideramos su \n",
            "shape\n",
            ":\n",
            "from typing import Tuple\n",
            "def shape(A: Matrix) -> Tuple[int, int]:\n",
            "\"\"\"Returns (# of rows of A,\n",
            "# of columns of A)\"\"\"\n",
            "num_rows = len(A)\n",
            "num_cols = len(A[0]) if A else 0\n",
            "# número de elementos de la\n",
            "primera fila\n",
            "return num_rows, num_cols\n",
            "assert shape([[1, 2, 3], [4, 5, 6]]) ==\n",
            "(2, 3)\n",
            "# 2 filas, 3 columnas\n",
            "Si una matriz tiene \n",
            "n\n",
            " filas y \n",
            "k\n",
            " columnas, nos referiremos a ella como una\n",
            "matriz \n",
            "n\n",
            " x \n",
            "k\n",
            ". Podemos (y a veces lo haremos) pensar en cada fila de una\n",
            "matriz \n",
            "n\n",
            " x \n",
            "k\n",
            " como un vector de longitud \n",
            "k\n",
            ", y en cada columna como en un\n",
            "vector de longitud \n",
            "n\n",
            ":\n",
            "def get_row(A: Matrix, i: int) -> Vector:\n",
            "\"\"\"Returns the i-th row of A (as a Vector)\"\"\"\n",
            "return A[i]\n",
            "# A[i] es ya la fila i\n",
            "def get_column(A: Matrix, j: int) -> Vector:\n",
            "\"\"\"Returns the j-th column of A (as a Vector)\"\"\"\n",
            "return [A_i[j]\n",
            "# elemento j de la fila A_i\n",
            "for A_i in A]\n",
            "# para cada fila A_i\n",
            "También querremos poder crear una matriz dada su forma y una funciónpara generar sus elementos. Podemos hacer esto utilizando una comprensión\n",
            "de lista anidada:\n",
            "from typing import Callable\n",
            "def make_matrix(num_rows: int,\n",
            "num_cols: int,\n",
            "entry_fn: Callable[[int, int], float]) -> Matrix:\n",
            "\"\"\"\n",
            "Returns a num_rows x num_cols matrix\n",
            "whose (i,j)-th entry is entry_fn(i, j)\n",
            "\"\"\"\n",
            "return [[entry_fn(i, j)\n",
            "# dado i, crea una lista\n",
            "for j in range(num_cols)]\n",
            "# [entry_fn(i, 0), ... ]\n",
            "for i in range(num_rows)]\n",
            "# crea una lista por cada i\n",
            "Dada esta función, se podría crear una matriz identidad 5 x 5 (con unos en\n",
            "la diagonal y ceros en el resto) de esta forma:\n",
            "def identity_matrix(n: int) -> Matrix:\n",
            "\"\"\"Returns the n x n identity matrix\"\"\"\n",
            "return make_matrix(n, n, lambda i, j: 1 if i == j else 0)\n",
            "assert identity_matrix(5) ==\n",
            "[[1, 0, 0, 0, 0],\n",
            "[0, 1, 0, 0, 0],\n",
            "[0, 0, 1, 0, 0],\n",
            "[0, 0, 0, 1, 0],\n",
            "[0, 0, 0, 0, 1]]\n",
            "Las matrices serán importantes para nosotros por varias razones.\n",
            "En primer lugar, podemos utilizar una matriz para representar un conjunto\n",
            "de datos formado por varios vectores, simplemente considerando cada vector\n",
            "como una fila de la matriz. Por ejemplo, si tuviéramos las alturas, pesos y\n",
            "edades de 1.000 personas, podríamos poner estos datos en una matriz 1.000 x\n",
            "3:\n",
            "data = [[70, 170, 40],\n",
            "[65, 120, 26],\n",
            "[77, 250, 19],\n",
            "# ....\n",
            "]\n",
            "En segundo lugar, como veremos más tarde, podemos utilizar una matriz \n",
            "nx \n",
            "k\n",
            " para representar una función lineal que transforme vectores de \n",
            "k\n",
            "dimensiones en vectores de \n",
            "n\n",
            " dimensiones. Varias de nuestras técnicas y\n",
            "conceptos implicarán tales funciones.\n",
            "Tercero, las matrices se pueden utilizar para representar relaciones\n",
            "binarias. En el capítulo 1, representamos los bordes de una red como una\n",
            "colección de pares \n",
            "(i,\n",
            " \n",
            "j)\n",
            ". Una representación alternativa sería crear una\n",
            "matriz \n",
            "A\n",
            " tal que \n",
            "A[i][j]\n",
            " sea 1 si los nodos \n",
            "i\n",
            " y \n",
            "j\n",
            " están conectados y 0 en otro\n",
            "caso.\n",
            "Recordemos que antes teníamos:\n",
            "friendships = [(0, 1), (0, 2), (1, 2), (1, 3), (2, 3), (3, 4),\n",
            "(4, 5), (5, 6), (5, 7), (6, 8), (7, 8), (8, 9)]\n",
            "También podemos representar esto como:\n",
            "#\n",
            "usuario 0 1 2 3 4 5 6 7 8 9\n",
            "#\n",
            "friend_matrix = [[0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "# usuario 0\n",
            "[1, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
            "# usuario 1\n",
            "[1, 1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "# usuario 2\n",
            "[0, 1, 1, 0, 1, 0, 0, 0, 0, 0],\n",
            "# usuario 3\n",
            "[0, 0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
            "# usuario 4\n",
            "[0, 0, 0, 0, 1, 0, 1, 1, 0, 0],\n",
            "# usuario 5\n",
            "[0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
            "# usuario 6\n",
            "[0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
            "# usuario 7\n",
            "[0, 0, 0, 0, 0, 0, 1, 1, 0, 1],\n",
            "# usuario 8\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]]\n",
            "# usuario 9\n",
            "Si hay pocas conexiones, esta representación es mucho menos eficaz, ya\n",
            "que terminamos teniendo que almacenar muchos ceros. No obstante, con la\n",
            "representación en matriz se comprueba mucho más rápido si dos nodos están\n",
            "conectados (basta con hacer una búsqueda en la matriz en lugar de,\n",
            "posiblemente, inspeccionar cada borde):\n",
            "assert friend_matrix[0][2] == 1, \"0 and 2 are friends\"\n",
            "assert friend_matrix[0][8] == 0, \"0 and 8 are not friends\"\n",
            "De forma similar, para encontrar las conexiones de un nodo, basta con\n",
            "inspeccionar la columna (o la fila) correspondiente a ese nodo:# basta con mirar en una fila\n",
            "friends_of_five = [i\n",
            "for i, is_friend in enumerate(friend_matrix[5])\n",
            "if is_friend]\n",
            "Con un gráfico de pequeño tamaño se podría añadir una lista de\n",
            "conexiones a cada objeto de nodo para acelerar este proceso, pero, con uno\n",
            "más grande y en constante evolución, hacer esto sería probablemente\n",
            "demasiado caro y difícil de mantener.\n",
            "Revisaremos las matrices a lo largo del libro.\n",
            "Para saber más\n",
            "■\n",
            "Los científicos de datos utilizan mucho el álgebra lineal (lo que se da\n",
            "por sentado con frecuencia, aunque no con tanta por personas que no lo\n",
            "comprenden). No sería mala idea leer un libro de texto. Se pueden\n",
            "encontrar varios disponibles gratuitamente en línea:\n",
            "■\n",
            "Linear Algebra\n",
            ", en \n",
            "http://joshua.smcvt.edu/linearalgebra/\n",
            ",\n",
            "de Jim Hefferon (Saint Michael’s College).\n",
            "■\n",
            "Linear Algebra\n",
            ", en\n",
            "https://www.math.ucdavis.edu/~linear/linear-guest.pdf\n",
            ", de\n",
            "David Cherney, Tom Denton, Rohit Thomas y Andrew Waldron\n",
            "(UC Davis).\n",
            "■\n",
            "Si se siente aventurero, \n",
            "Linear Algebra Done Wrong\n",
            ", en\n",
            "https://www.math.brown.edu/~treil/papers/LADW/LADW_2017-\n",
            "09-04.pdf\n",
            ", de Sergei Treil (Brown University), es una introducción\n",
            "más avanzada.\n",
            "■\n",
            "Toda la maquinaria que hemos creado en este capítulo se puede\n",
            "conseguir de forma gratuita utilizando NumPy, en\n",
            "http://www.numpy.org\n",
            " (también se obtiene mucho más, incluyendo\n",
            "mucho mejor rendimiento).5\n",
            " Estadística\n",
            "Los hechos son obstinados, pero las estadísticas son más maleables.\n",
            "—Mark Twain\n",
            "El término estadística hace referencia a las matemáticas y a las técnicas\n",
            "con las que comprendemos los datos. Es un campo rico y extenso, más\n",
            "adecuado para una estantería (o una sala entera) de una biblioteca que para un\n",
            "capítulo de un libro, de modo que necesariamente mi exposición no podrá ser\n",
            "profunda. Trataré de enseñar lo justo para que resulte comprometido y active\n",
            "el interés lo suficiente como para seguir adelante y aprender aún más.\n",
            "Describir un solo conjunto de datos\n",
            "Mediante una combinación de boca a boca y suerte, DataSciencester ha\n",
            "crecido y ahora tiene muchísimos miembros, y el vicepresidente de\n",
            "Recaudación de fondos quiere algún tipo de descripción de la cantidad de\n",
            "amigos que tienen sus miembros para poder incluirla en sus discursos de\n",
            "presentación.\n",
            "Utilizando las técnicas del capítulo 1, es muy sencillo producir estos\n",
            "datos. Pero ahora nos enfrentamos al problema de cómo describirlos. Una\n",
            "descripción obvia de cualquier conjunto de datos es sencillamente los propios\n",
            "datos:\n",
            "num_friends = [100, 49, 41, 40, 25,\n",
            "# ... y muchos más\n",
            "]\n",
            "Con un conjunto de datos bastante pequeño, esta podría ser la mejor\n",
            "descripción. Pero, con otro más grande, resulta difícil de manejar y\n",
            "probablemente opaco (imagínese tener que mirar fijamente una lista de 1millón de números). Por esta razón, utilizamos las estadísticas para sintetizar\n",
            "y comunicar las características relevantes de nuestros datos. Como primer\n",
            "enfoque, ponemos los contadores de amigos en un histograma utilizando\n",
            "Counter\n",
            " y \n",
            "plt.bar\n",
            " (véase la figura 5.1):\n",
            "from collections import Counter\n",
            "import matplotlib.pyplot as plt\n",
            "friend_counts = Counter(num_friends)\n",
            "xs = range(101)\n",
            "# el valor mayor es 100\n",
            "ys = [friend_counts[x] for x in\n",
            "xs]\n",
            "# la altura es justamente núm. de\n",
            "amigos\n",
            "plt.bar(xs, ys)\n",
            "plt.axis([0, 101, 0, 25])\n",
            "plt.title(\"Histogram of Friend Counts\")\n",
            "plt.xlabel(\"# of friends\")\n",
            "plt.ylabel(\"# of people\")\n",
            "plt.show()\n",
            "Figura 5.1. \n",
            "Un histograma de contadores de amigos.\n",
            "Por desgracia, sigue siendo demasiado difícil meter este gráfico en las\n",
            "conversaciones. De modo que empezamos a generar algunas estadísticas;probablemente la más sencilla es el número de puntos de datos:\n",
            "num_points = len(num_friends)\n",
            "# 204\n",
            "Probablemente también estemos interesados en los valores mayor y\n",
            "menorww:\n",
            "largest_value = max(num_friends)\n",
            "# 100\n",
            "smallest_value = min(num_friends)\n",
            "# 1\n",
            "Que son simplemente casos especiales de querer saber cuáles son los\n",
            "valores de determinadas posiciones:\n",
            "sorted_values = sorted(num_friends)\n",
            "smallest_value = sorted_values[0]\n",
            "# 1\n",
            "second_smallest_value = sorted_values[1]\n",
            "# 1\n",
            "second_largest_value = sorted_values[-2]\n",
            "# 49\n",
            "Pero solo estamos empezando.\n",
            "Tendencias centrales\n",
            "Normalmente, querremos tener alguna noción del lugar en el que nuestros\n",
            "datos están centrados. Lo más habitual es que usemos la media (o promedio),\n",
            "que no es más que la suma de los datos dividida por el número de datos:\n",
            "def mean(xs: List[float]) -> float:\n",
            "return sum(xs) / len(xs)\n",
            "mean(num_friends)\n",
            "# 7,333333\n",
            "Si tenemos dos puntos de datos, la media es simplemente el punto a mitad\n",
            "de camino entre los dos. A medida que se añaden más puntos, la media se va\n",
            "desplazando, pero siempre depende del valor de cada punto. Por ejemplo, si\n",
            "tenemos 10 puntos de datos y aumentamos el valor de cualquiera de ellos en\n",
            "1, la media aumenta en 0,1.\n",
            "También estaremos interesados en ocasiones en la mediana, que es el\n",
            "valor más céntrico (si el número de puntos de datos es impar) o el promediode los dos valores más céntricos (si el número de puntos de datos es par).\n",
            "Por ejemplo, si tenemos cinco puntos de datos en un vector ordenado \n",
            "x\n",
            ", la\n",
            "mediana es \n",
            "x[5\n",
            " \n",
            "//\n",
            " \n",
            "2]\n",
            " o \n",
            "x[2]\n",
            ". Si tenemos seis puntos de datos, queremos el\n",
            "promedio de \n",
            "x[2]\n",
            " (el tercer punto) y \n",
            "x[3]\n",
            " (el cuarto punto).\n",
            "Tengamos en cuenta que (a diferencia de la media) la mediana no depende\n",
            "por completo de cada valor de los datos. Por ejemplo, si el punto más grande\n",
            "lo hacemos aún mayor (o el punto más pequeño menor), los puntos medios\n",
            "no cambian, lo que significa que la mediana sí lo hace.\n",
            "Escribiremos distintas funciones para los casos par e impar y las\n",
            "combinaremos:\n",
            "# Los guiones bajos indican que son funciones \"privadas\", destinadas a\n",
            "# ser llamadas por nuestra función mediana pero no por otras personas\n",
            "# que utilicen nuestra librería de estadísticas.\n",
            "def _median_odd(xs: List[float]) -> float:\n",
            "\"\"\"If len(xs) is odd, the median is the middle element\"\"\"\n",
            "return sorted(xs)[len(xs) // 2]\n",
            "def _median_even(xs: List[float]) -> float:\n",
            "\"\"\"If len(xs) is even, it’s the average of the middle two elements\"\"\"\n",
            "sorted_xs = sorted(xs)\n",
            "hi_midpoint = len(xs) // 2\n",
            "# p.ej. longitud 4 => hi_midpoint 2\n",
            "return (sorted_xs[hi_midpoint–1] + sorted_xs[hi_midpoint]) / 2\n",
            "def median(v: List[float]) -> float:\n",
            "\"\"\"Finds the ‘middle-most’ value of v\"\"\"\n",
            "return _median_even(v) if len(v) % 2 == 0 else _median_odd(v)\n",
            "assert median([1, 10, 2, 9, 5]) == 5\n",
            "assert median([1, 9, 2, 10]) == (2 + 9) / 2\n",
            "Y ahora podemos calcular el número medio de amigos:\n",
            "print(median(num_friends))\n",
            "# 6\n",
            "Sin duda, la media es más sencilla de calcular y varía ligeramente cuando\n",
            "nuestros datos cambian. Si tenemos \n",
            "n\n",
            " puntos de datos y uno de ellos aumenta\n",
            "en una cierta pequeña cantidad \n",
            "e\n",
            ", entonces la media necesariamente\n",
            "aumentará en \n",
            "e\n",
            " / \n",
            "n\n",
            " (lo que consigue que la media sea susceptible a todo tipo\n",
            "de trucos de cálculo). Pero, para hallar la mediana, tenemos que ordenar los\n",
            "datos. Y cambiar uno de nuestros puntos de datos en una pequeña cantidad \n",
            "epodría aumentar la mediana también en \n",
            "e\n",
            ", en una cantidad inferior a \n",
            "e\n",
            " o en\n",
            "nada en absoluto (dependiendo del resto de datos).\n",
            "Nota:\n",
            " En realidad, existen trucos no evidentes para calcular medianas\n",
            "eficazmente\n",
            "1\n",
            " sin ordenar los datos. Sin embargo, están más allá del objetivo de\n",
            "este libro, de modo que toca ordenar los datos.\n",
            "Al mismo tiempo, la media es muy sensible a los valores atípicos de\n",
            "nuestros datos. Si nuestro usuario más sociable tuviera 200 amigos (en lugar\n",
            "de 100), entonces la media subiría a 7,82, mientras que la mediana seguiría\n",
            "siendo la misma. Si es probable que los valores atípicos sean datos erróneos\n",
            "(o no representativos del fenómeno que estemos tratando de comprender),\n",
            "entonces la media puede darnos a veces una imagen equívoca. Por ejemplo, a\n",
            "menudo se cuenta la historia de que, a mediados de los años 80, la asignatura\n",
            "de la Universidad de Carolina del Norte con el salario inicial medio más alto\n",
            "era geografía, principalmente debido a la estrella de la NBA (y valor atípico)\n",
            "Michael Jordan.\n",
            "Una generalización de la mediana es el cuantil, que representa el valor\n",
            "bajo el cual reside un determinado percentil de los datos (la mediana\n",
            "representa el valor bajo el cual reside el 50 % de los datos):\n",
            "def quantile(xs: List[float], p: float) -> float:\n",
            "\"\"\"Returns the pth-percentile value in x\"\"\"\n",
            "p_index = int(p * len(xs))\n",
            "return sorted(xs)[p_index]\n",
            "assert quantile(num_friends, 0.10) == 1\n",
            "assert quantile(num_friends, 0.25) == 3\n",
            "assert quantile(num_friends, 0.75) == 9\n",
            "assert quantile(num_friends, 0.90) == 13\n",
            "Menos habitual sería que quisiéramos mirar la moda, es decir, el valor o\n",
            "valores más comunes:\n",
            "def mode(x: List[float]) -> List[float]:\n",
            "\"\"\"Returns a list, since there might be more than one mode\"\"\"\n",
            "counts = Counter(x)\n",
            "max_count = max(counts.values())return [x_i for x_i, count in counts.items()\n",
            "if count == max_count]\n",
            "assert set(mode(num_friends)) == {1, 6}\n",
            "Pero lo más habitual es que utilicemos la media.\n",
            "Dispersión\n",
            "Dispersión se refiere a las medidas de dispersión de nuestros datos.\n",
            "Normalmente son estadísticas para las que los valores cercanos a cero\n",
            "significan “no disperso en absoluto” y para las que los valores grandes (lo\n",
            "que sea que eso signifique) quieren decir “muy disperso”. Por ejemplo, una\n",
            "medida muy sencilla es el rango, que no es otra cosa que la diferencia entre\n",
            "los elementos mayor y menor:\n",
            "# \"range\" ya significa algo en Python, así que usaremos otro nombre\n",
            "def data_range(xs: List[float]) -> float:\n",
            "return max(xs)–min(xs)\n",
            "assert data_range(num_friends) == 99\n",
            "El rango es cero precisamente cuando el \n",
            "max\n",
            " y el \n",
            "min\n",
            " son iguales, cosa que\n",
            "solo puede ocurrir si los elementos de \n",
            "x\n",
            " son todos iguales, lo que significa\n",
            "que los datos están tan poco dispersos como es posible. A la inversa, si el\n",
            "rango es grande, entonces el \n",
            "max\n",
            " es mucho más grande que el \n",
            "min\n",
            " y los datos\n",
            "están más dispersos.\n",
            "Al igual que ocurre con la mediana, en realidad el rango no depende del\n",
            "conjunto de datos entero. Un conjunto de datos cuyos puntos son todos 0 o\n",
            "100 tiene el mismo rango que otro cuyos valores sean 0, 100 y muchos 50.\n",
            "Pero parece que el primer conjunto de datos “debería” estar más disperso.\n",
            "Una medida más compleja de dispersión es la varianza, que se calcula\n",
            "como:\n",
            "from scratch.linear_algebra import sum_of_squares\n",
            "def de_mean(xs: List[float]) -> List[float]:\n",
            "\"\"\"Translate xs by subtracting its mean (so the result has mean 0)\"\"\"\n",
            "x_bar = mean(xs)\n",
            "return [x–x_bar for x in xs]def variance(xs: List[float]) -> float:\n",
            "\"\"\"Almost the average squared deviation from the mean\"\"\"\n",
            "assert len(xs) >= 2, \"variance requires at least two elements\"\n",
            "n = len(xs)\n",
            "deviations = de_mean(xs)\n",
            "return sum_of_squares(deviations) / (n–1)\n",
            "assert 81.54 < variance(num_friends) < 81.55\n",
            "Nota:\n",
            " Parece que esto sea casi la desviación cuadrática promedio respecto a\n",
            "la media, salvo que estamos dividiendo por \n",
            "n - 1\n",
            " en lugar de por \n",
            "n\n",
            ". De hecho,\n",
            "cuando tratamos con una muestra de una población mayor, \n",
            "x_bar\n",
            " es solamente\n",
            "una estimación de la media real, lo que significa que en promedio \n",
            "(x_i - x_bar)\n",
            "** 2\n",
            " es una subestimación de la desviación cuadrática de \n",
            "x_i\n",
            " con respecto a la\n",
            "media, razón por la cual dividimos por \n",
            "n - 1\n",
            " en lugar de por \n",
            "n\n",
            ". Consulte la\n",
            "Wikipedia.\n",
            "2\n",
            "Ahora, sin importar en qué unidades estén nuestros datos (por ejemplo,\n",
            "“amigos”), todas nuestras medidas de tendencia central están en la misma\n",
            "unidad, igual que el rango. Pero la varianza, por otro lado, tiene unidades que\n",
            "son el cuadrado de las originales (es decir, “amigos al cuadrado”). Como\n",
            "puede resultar difícil darle sentido a esto, a menudo recurrimos en su lugar a\n",
            "la desviación estándar:\n",
            "import math\n",
            "def standard_deviation(xs: List[float]) -> float:\n",
            "\"\"\"The standard deviation is the square root of the variance\"\"\"\n",
            "return math.sqrt(variance(xs))\n",
            "assert 9.02 < standard_deviation(num_friends) < 9.04\n",
            "Tanto el rango como la desviación estándar tienen el mismo problema de\n",
            "valor atípico que vimos antes con la media. Utilizando el mismo ejemplo, si\n",
            "nuestro usuario más sociable tuviera realmente 200 amigos, la desviación\n",
            "estándar sería 14,89 (¡más del 60 % más elevada!).\n",
            "Una alternativa más robusta calcula la diferencia entre los percentiles 75 y\n",
            "25:\n",
            "def interquartile_range(xs: List[float]) -> float:\n",
            "\"\"\"Returns the difference between the 75%-ile and the 25%-ile\"\"\"\n",
            "return quantile(xs, 0.75)–quantile(xs, 0.25)assert interquartile_range(num_friends) == 6\n",
            "Que apenas se ve afectada por una pequeña cantidad de valores atípicos.\n",
            "Correlación\n",
            "La vicepresidenta de Crecimiento de DataSciencester tiene una teoría\n",
            "según la cual la cantidad de tiempo que la gente se queda en el sitio está\n",
            "relacionada con el número de amigos que tienen en él (ella no es\n",
            "vicepresidenta porque sí), y quiere verificar esta afirmación.\n",
            "Tras escarbar en los registros de tráfico, obtenemos una lista llamada\n",
            "daily_minutes\n",
            ", que muestra los minutos al día que se pasa cada usuario en\n",
            "DataSciencester, y la hemos ordenado de forma que sus elementos se\n",
            "correspondan con los elementos de nuestra lista anterior \n",
            "num_friends\n",
            ". Nos\n",
            "gustaría investigar la relación entre estas dos métricas.\n",
            "Primero, veremos la covarianza, la análoga emparejada de la varianza.\n",
            "Mientras la varianza mide la desviación de la media de una sola variable, la\n",
            "covarianza mide la variación de dos variables en tándem con respecto a sus\n",
            "medias:\n",
            "from scratch.linear_algebra import dot\n",
            "def covariance(xs: List[float], ys: List[float]) -> float:\n",
            "assert len(xs) == len(ys), \"xs and ys must have same number of elements\"\n",
            "return dot(de_mean(xs), de_mean(ys)) / (len(xs)–1)\n",
            "assert 22.42 < covariance(num_friends, daily_minutes) < 22.43\n",
            "assert 22.42 / 60 < covariance(num_friends, daily_hours) < 22.43 / 60\n",
            "Recordemos que \n",
            "dot\n",
            " suma los productos de los pares de elementos\n",
            "correspondientes. Cuando los elementos correspondientes de \n",
            "x\n",
            " e \n",
            "y\n",
            " están\n",
            "ambos por encima o por debajo de sus medias, un número positivo entra en la\n",
            "suma. Cuando uno está por encima de la media y el otro por debajo, es un\n",
            "número negativo lo que entra en la suma. De acuerdo con esto, una\n",
            "covarianza positiva “grande” significa que \n",
            "x\n",
            " tiende a ser grande cuando \n",
            "y\n",
            " es\n",
            "grande y pequeño cuando \n",
            "y\n",
            " es pequeño. Una covarianza negativa “grande”significa lo contrario: que \n",
            "x\n",
            " tiende a ser pequeño cuando \n",
            "y\n",
            " es grande y\n",
            "viceversa. Una covarianza cercana a cero significa que no existe tal relación.\n",
            "No obstante, este número puede ser difícil de interpretar por varias\n",
            "razones:\n",
            "■\n",
            "Sus unidades son el producto de las unidades de las entradas (por\n",
            "ejemplo, amigos-minutos-al-día), lo que puede ser difícil de entender\n",
            "(¿qué es un “amigo-minuto-al-día”?).\n",
            "■\n",
            "Si cada usuario tuviera el doble de amigos (pero el mismo número de\n",
            "minutos), la covarianza sería el doble de grande. Pero, en cierto\n",
            "sentido, las variables estarían igual de interrelacionadas. Dicho de otro\n",
            "modo, es difícil decir lo que cuenta como una covarianza “grande”.\n",
            "Por esta razón, es más común mirar la correlación, que divide las\n",
            "desviaciones estándares de ambas variables:\n",
            "def correlation(xs: List[float], ys: List[float]) -> float:\n",
            "\"\"\"Measures how much xs and ys vary in tandem about their means\"\"\"\n",
            "stdev_x = standard_deviation(xs)\n",
            "stdev_y = standard_deviation(ys)\n",
            "if stdev_x > 0 and stdev_y > 0:\n",
            "return covariance(xs, ys) / stdev_x / stdev_y\n",
            "else:\n",
            "return 0\n",
            "# si no hay variación, la correlación es cero\n",
            "assert 0.24 < correlation(num_friends, daily_minutes) < 0.25\n",
            "assert 0.24 < correlation(num_friends, daily_hours) < 0.25\n",
            "La \n",
            "correlation\n",
            " no tiene unidad y siempre está entre -1 (anticorrelación\n",
            "perfecta) y 1 (correlación perfecta). Un número como 0,25 representa una\n",
            "correlación positiva relativamente débil. Sin embargo, una cosa que\n",
            "olvidamos hacer fue examinar nuestros datos. Veamos la figura 5.2.\n",
            "La persona que tiene 100 amigos (y que pasa únicamente 1 minuto al día\n",
            "en el sitio) es un enorme valor atípico, y la correlación puede ser muy\n",
            "sensible a estos valores. ¿Qué ocurre si le ignoramos?\n",
            "outlier = num_friends.index(100)\n",
            "# índice de valor atípico\n",
            "num_friends_good = [x\n",
            "for i, x in enumerate(num_friends)if i != outlier]\n",
            "daily_minutes_good = [x\n",
            "for i, x in enumerate(daily_minutes)\n",
            "if i != outlier]\n",
            "daily_hours_good = [dm / 60 for dm in daily_minutes_good]\n",
            "assert 0.57 < correlation(num_friends_good, daily_minutes_good) < 0.58\n",
            "assert 0.57 < correlation(num_friends_good, daily_hours_good) < 0.58\n",
            "Sin el valor atípico, hay una correlación mucho más fuerte (véase la figura\n",
            "5.3).\n",
            "Figura 5.2. \n",
            "Correlación con un valor atípico.Figura 5.3. \n",
            "Correlación tras eliminar el valor atípico.\n",
            "Seguimos investigando para descubrir que el valor atípico era realmente\n",
            "una cuenta de prueba interna que nadie se había preocupado nunca de\n",
            "eliminar. Así que su exclusión está totalmente justificada.\n",
            "La paradoja de Simpson\n",
            "Una sorpresa no poco habitual al analizar datos es la paradoja de Simpson,\n",
            "en la que las correlaciones pueden ser erróneas cuando se ignoran las\n",
            "variables de confusión.\n",
            "Por ejemplo, imaginemos que podemos identificar todos nuestros\n",
            "miembros como científicos de datos de la costa este u oeste de EE. UU.\n",
            "Decidimos examinar los científicos de datos de qué costa son más amigables:\n",
            "Costa\n",
            "Nº de miembros\n",
            "Nº medio de amigos\n",
            "Costa oeste\n",
            "101\n",
            "8,2Costa este\n",
            "103\n",
            "6,5\n",
            "Sin duda parece que los científicos de datos de la costa oeste son más\n",
            "amigables que los de la costa este. Sus compañeros de trabajo avanzan todo\n",
            "tipo de teorías sobre la razón por la que podría ocurrir esto: ¿quizá es el sol,\n",
            "el café, los productos ecológicos o el ambiente relajado del Pacífico?\n",
            "Pero, jugando con los datos, descubrimos algo muy extraño. Si solamente\n",
            "miramos las personas con doctorado, los científicos de datos de la costa este\n",
            "tienen más amigos en promedio.\n",
            "Pero, si miramos solo las personas sin doctorado, ¡los científicos de datos\n",
            "de la costa este tienen también más amigos de media!\n",
            "Costa\n",
            "Doctorado\n",
            "Nº de miembros\n",
            "Nº medio de amigos\n",
            "Costa oeste\n",
            "Sí\n",
            "35\n",
            "3,1\n",
            "Costa este\n",
            "Sí\n",
            "70\n",
            "3,2\n",
            "Costa oeste\n",
            "No\n",
            "66\n",
            "10,9\n",
            "Costa este\n",
            "No\n",
            "33\n",
            "13,4\n",
            "En cuanto se tienen en cuenta los doctorados de los usuarios, la\n",
            "correlación se va en la dirección contraria. Agrupar los datos en \n",
            "buckets\n",
            "como Costa Este/Costa Oeste disfrazó el hecho de que los científicos de datos\n",
            "de la costa este se inclinaban muchísimo más hacia los tipos con doctorado.\n",
            "Este fenómeno ocurre en el mundo real con cierta regularidad. Lo esencial\n",
            "es que la correlación está midiendo la relación entre las dos variables, siendo\n",
            "todo lo demás igual. Si las clases de datos se asignan de forma aleatoria,\n",
            "como podría perfectamente ocurrir en un experimento bien diseñado, “siendo\n",
            "todo lo demás igual” podría no ser una suposición horrible.\n",
            "La única forma real de evitar esto es conociendo los datos y haciendo lo\n",
            "posible por asegurarse de que se han revisado en busca de posibles factores\n",
            "de confusión. Es obvio que esto no es siempre posible. Si no tuviéramos\n",
            "datos sobre los logros académicos de estos 200 científicos de datos,podríamos simplemente concluir que había algo intrínsecamente más\n",
            "amigable en la costa oeste.\n",
            "Otras advertencias sobre la correlación\n",
            "Una correlación de cero indica que no hay relación lineal entre las dos\n",
            "variables. Sin embargo, pueden existir otras formas de relaciones. Por\n",
            "ejemplo, si:\n",
            "x = [-2, -1, 0, 1, 2]\n",
            "y = [ 2, 1, 0, 1, 2]\n",
            "Entonces \n",
            "x\n",
            " e \n",
            "y\n",
            " tienen correlación cero. Pero sin duda están relacionados:\n",
            "cada elemento de \n",
            "y\n",
            " es igual al valor absoluto del elemento correspondiente de\n",
            "x\n",
            ". Lo que no tienen es una relación en la que saber cómo se compara \n",
            "x_i\n",
            " con\n",
            "mean(x)\n",
            " nos ofrece información sobre cómo \n",
            "y_i\n",
            " se compara con \n",
            "mean(y)\n",
            ".\n",
            "Este es el tipo de relación que la correlación busca.\n",
            "Además, la correlación no nos dice nada sobre lo grande que es la\n",
            "relación:\n",
            "x = [-2, -1, 0, 1, 2]\n",
            "y = [99.98, 99.99, 100, 100.01, 100.02]\n",
            "Las variables están perfectamente correlacionadas, pero (dependiendo de\n",
            "cómo estemos midiendo) es muy posible que esta relación no sea tan\n",
            "interesante.\n",
            "Correlación y causación\n",
            "Es probable que en algún momento haya oído que “correlación no es\n",
            "causación”, dicho lo más probable por alguien en busca de datos que\n",
            "plantearan un desafío a partes de su visión del mundo que era reacio a\n",
            "cuestionar. Sin embargo, este es un punto importante: si \n",
            "x\n",
            " e \n",
            "y\n",
            " están\n",
            "fuertemente correlacionados, podría significar que \n",
            "x\n",
            " causa \n",
            "y\n",
            ", que \n",
            "y\n",
            " causa \n",
            "x\n",
            ",que cada uno causa el otro, que un tercer factor causa ambos, o nada de esto\n",
            "en absoluto.\n",
            "Pensemos en la relación entre \n",
            "num_friends\n",
            " y \n",
            "daily_minutes\n",
            ". Es posible\n",
            "que tener más amigos en el sitio cause que los usuarios de DataSciencester\n",
            "pasen más tiempo en el sitio. Este podría ser el caso si cada amigo sube una\n",
            "cierta cantidad de contenido cada día, lo que significa que cuantos más\n",
            "amigos se tengan, más tiempo se necesita para mantenerse al día de sus\n",
            "actualizaciones.\n",
            "Sin embargo, es también posible que, cuanto más tiempo pasen los\n",
            "usuarios discutiendo en foros de DataSciencester, con más frecuencia\n",
            "encuentren personas con su misma forma de pensar y se hagan amigos de\n",
            "ellas. Es decir, pasar más tiempo en el sitio causa que los usuarios tengan más\n",
            "amigos.\n",
            "Una tercera posibilidad es que los usuarios más apasionados por la ciencia\n",
            "de datos pasen más tiempo en el sitio (porque lo encuentran más interesante)\n",
            "y consigan de forma más activa amigos de ciencia de datos (porque no\n",
            "quieren asociarse con ningún otro).\n",
            "Una forma de sentirse más cómodos con la causalidad es realizando\n",
            "ensayos aleatorios. Si es posible dividir aleatoriamente los usuarios en dos\n",
            "grupos con demografías similares y dar a uno de los grupos una experiencia\n",
            "algo distinta, entonces se observa con bastante seguridad que las distintas\n",
            "experiencias están causando los diferentes resultados.\n",
            "Por ejemplo, si no nos importara que nos acusasen con indignación de\n",
            "experimentar con los usuarios,\n",
            "3\n",
            " podríamos elegir aleatoriamente un\n",
            "subconjunto de usuarios y mostrarles contenido únicamente de una parte de\n",
            "sus amigos. Si después este subconjunto se pasara menos tiempo en el sitio,\n",
            "ello nos daría una cierta confianza en pensar que tener más amigos causa\n",
            "pasar más tiempo en el sitio.\n",
            "Para saber más\n",
            "■\n",
            "SciPy en \n",
            "https://www.scipy.org\n",
            ", pandas enhttp://pandas.pydata.org\n",
            " y StatsModels en\n",
            "http://www.statsmodels.org\n",
            ", incluyen todos una gran variedad de\n",
            "funciones estadísticas.\n",
            "■\n",
            "La estadística es importante. Si quiere ser un científico de datos mejor,\n",
            "sería una buena idea leer un libro de texto sobre estadística. En la red\n",
            "hay muchos disponibles, como por ejemplo:\n",
            "■\n",
            "Introductory Statistics\n",
            ", en\n",
            "https://open.umn.edu/opentextbooks/textbooks/introductory-\n",
            "statistics\n",
            ", de Douglas Shafer y Zhiyi Zhang (Saylor Foundation).\n",
            "■\n",
            "OnlineStatBook\n",
            ", en \n",
            "http://onlinestatbook.com/\n",
            ", de David Lane\n",
            "(Rice University).\n",
            "■\n",
            "Introductory Statistics\n",
            ", en\n",
            "https://openstax.org/details/introductory-statistics\n",
            ", de\n",
            "OpenStax (OpenStax College).\n",
            "1\n",
            " \n",
            "http://en.wikipedia.org/wiki/Quickselect\n",
            ".\n",
            "2\n",
            "https://es.wikipedia.org/wiki/Estimaci%C3%B3n_de_la_desviaci%C3%B3n_est%C3%A1ndar_no_sesgada\n",
            "3\n",
            " \n",
            "https://www.nytimes.com/2014/06/30/technology/facebook-tinkers-with-users-\n",
            "emotions-in-news-feed-experiment-stirring-outcry.html?searchResultPosition=1\n",
            ".6\n",
            " Probabilidad\n",
            "Las leyes de la probabilidad, tan verdaderas en general, tan falaces en particular.\n",
            "—Edward Gibbon\n",
            "Es difícil hacer ciencia de datos sin un cierto conocimiento de la\n",
            "probabilidad y sus matemáticas. Al igual que ocurrió con nuestro tratamiento\n",
            "de la estadística en el capítulo 5, agitaremos mucho las manos y\n",
            "suprimiremos muchos de los tecnicismos.\n",
            "Para nuestros fines lo mejor es pensar en la probabilidad como en una\n",
            "forma de cuantificar la incertidumbre asociada a los eventos elegidos desde\n",
            "un universo de eventos. En lugar de ponerse técnicos sobre lo que significan\n",
            "estas palabras, mejor pensemos en tirar un dado. El universo consiste en\n",
            "todos los resultados posibles, y cualquier subconjunto de estos resultados es\n",
            "un evento. Por ejemplo, “el dado saca un 1” o “el dado saca un número par”.\n",
            "Utilizando notación matemática, escribimos \n",
            "P\n",
            "(\n",
            "E\n",
            ") para indicar “la\n",
            "probabilidad del evento \n",
            "E\n",
            "”.\n",
            "Utilizaremos la teoría de la probabilidad para crear modelos. Y para\n",
            "evaluar modelos. La emplearemos para todo.\n",
            "Podríamos, si quisiéramos, profundizar en la filosofía del significado de la\n",
            "teoría de la probabilidad (lo que se haría mejor con unas cervezas). Pero no\n",
            "haremos eso.\n",
            "Dependencia e independencia\n",
            "A grandes rasgos, digamos que dos eventos \n",
            "E\n",
            " y \n",
            "F\n",
            " son dependientes si\n",
            "saber algo sobre si \n",
            "E\n",
            " ocurre nos da información sobre si \n",
            "F\n",
            " ocurre (y\n",
            "viceversa). De otro modo, son independientes.\n",
            "Por ejemplo, si lanzamos una moneda dos veces, saber que el primer\n",
            "lanzamiento es cara no nos da información alguna sobre si en el segundolanzamiento saldrá también cara. Estos eventos son independientes. Por otro\n",
            "lado, saber si el primer lanzamiento es cara sin duda nos da información\n",
            "sobre si en ambos lanzamientos saldrá cruz (si en el primer lanzamiento sale\n",
            "cara, entonces definitivamente no es el caso de que en ambos lanzamientos\n",
            "salga cruz). Estos dos eventos son dependientes.\n",
            "Matemáticamente, decimos que dos eventos \n",
            "E\n",
            " y \n",
            "F\n",
            " son independientes si la\n",
            "probabilidad de que ambos ocurran es el producto de las probabilidades de\n",
            "que cada uno ocurre:\n",
            "P\n",
            "(\n",
            "E\n",
            ", \n",
            "F\n",
            ") = \n",
            "P\n",
            "(\n",
            "E\n",
            ")\n",
            "P\n",
            "(\n",
            "F\n",
            ")\n",
            "En el ejemplo, la probabilidad de “primer lanzamiento cara” es de 1/2, y la\n",
            "probabilidad de “ambos lanzamientos cruz” es de 1/4, pero la probabilidad de\n",
            "“primer lanzamiento cara y ambos lanzamientos cruz” es de 0.\n",
            "Probabilidad condicional\n",
            "Cuando dos eventos \n",
            "E\n",
            " y \n",
            "F\n",
            " son independientes, entonces por definición\n",
            "tenemos:\n",
            "P\n",
            "(\n",
            "E\n",
            ", \n",
            "F\n",
            ") = \n",
            "P\n",
            "(\n",
            "E\n",
            ")\n",
            "P\n",
            "(\n",
            "F\n",
            ")\n",
            "Si no son necesariamente independientes (y si la probabilidad de \n",
            "F\n",
            " no es\n",
            "cero), entonces definimos la probabilidad de \n",
            "E\n",
            " “condicionada por \n",
            "F\n",
            "” como:\n",
            "P\n",
            "(\n",
            "E\n",
            "|\n",
            "F\n",
            ") = \n",
            "P\n",
            "(\n",
            "E\n",
            ",\n",
            "F\n",
            ")/\n",
            "P\n",
            "(\n",
            "F\n",
            ")\n",
            "Tendríamos que pensar en esto como la probabilidad de que \n",
            "E\n",
            " ocurra,\n",
            "dado que sabemos que \n",
            "F\n",
            " ocurre.\n",
            "A menudo esto lo reescribimos así:\n",
            "P\n",
            "(\n",
            "E\n",
            ",\n",
            "F\n",
            ") = \n",
            "P\n",
            "(\n",
            "E\n",
            "|\n",
            "F\n",
            ")\n",
            "P\n",
            "(\n",
            "F\n",
            ")Cuando \n",
            "E\n",
            " y \n",
            "F\n",
            " son independientes, se puede verificar que esto da:\n",
            "P\n",
            "(\n",
            "E\n",
            "|\n",
            "F\n",
            ") = \n",
            "P\n",
            "(\n",
            "E\n",
            ")\n",
            "Que es la forma matemática de expresar que saber que \n",
            "F\n",
            " ocurrió no nos da\n",
            "información adicional sobre si \n",
            "E\n",
            " ocurrió.\n",
            "Un ejemplo habitual y bastante complejo es el de una familia con dos\n",
            "hijos (desconocidos). Si suponemos que:\n",
            "■\n",
            "Cada hijo tiene la misma probabilidad de ser niño o niña.\n",
            "■\n",
            "El género del segundo hijo es independiente del género del primer hijo.\n",
            "Entonces el evento “no niñas” tiene una probabilidad de 1/4, el evento “un\n",
            "niño, una niña” tiene probabilidad 1/4, y el evento “dos niñas” tiene una\n",
            "probabilidad también de 1/4.\n",
            "Ahora podemos preguntar: ¿cuál es la probabilidad del evento “ambos\n",
            "hijos son niñas” (\n",
            "B\n",
            ") condicionado por el evento “el hijo mayor es una niña”\n",
            "(\n",
            "G\n",
            ")? Utilizando la definición de probabilidad condicional:\n",
            "P\n",
            "(\n",
            "B\n",
            "|\n",
            "G\n",
            ") = \n",
            "P\n",
            "(\n",
            "B\n",
            ",\n",
            "G\n",
            ")/\n",
            "P\n",
            "(\n",
            "G\n",
            ") = \n",
            "P\n",
            "(\n",
            "B\n",
            ")/\n",
            "P\n",
            "(\n",
            "G\n",
            ") = 1/2\n",
            "Ya que el evento \n",
            "B\n",
            " y \n",
            "G\n",
            " (“ambos hijos son niñas y el otro hijo es una\n",
            "niña”) es precisamente el evento \n",
            "B\n",
            " (en cuanto sabemos que ambos hijos son\n",
            "niñas, es necesariamente cierto que el hijo mayor sea una niña).\n",
            "Lo más probable es que este resultado esté de acuerdo con su intuición.\n",
            "También podríamos preguntar por la probabilidad del evento “ambos hijos\n",
            "son niñas” condicionado por el evento “al menos uno de los hijos es una\n",
            "niña” (\n",
            "L\n",
            "). Sorprendentemente, ¡la respuesta es distinta a la anterior!\n",
            "Como antes, el evento \n",
            "B\n",
            " y \n",
            "L\n",
            " (“ambos hijos son niñas y al menos uno de\n",
            "los hijos es una niña”) es justamente el evento \n",
            "B\n",
            ". Esto significa que tenemos:\n",
            "P\n",
            "(\n",
            "B\n",
            "|\n",
            "L\n",
            ") = \n",
            "P\n",
            "(\n",
            "B\n",
            ",\n",
            "L\n",
            ")/\n",
            "P\n",
            "(\n",
            "L\n",
            ") = \n",
            "P\n",
            "(\n",
            "B\n",
            ")/\n",
            "P\n",
            "(\n",
            "L\n",
            ") = 1/3\n",
            "¿Cómo puede ser esto así? Bueno, si todo lo que sabemos es que al menos\n",
            "uno de los hijos es una niña, entonces es el doble de probable que la familia\n",
            "tenga un niño y una niña que tenga dos niñas.Podemos comprobarlo “generando” muchas familias:\n",
            "import enum, random\n",
            "# Un Enum es un conjunto con nombre de valores enumerados.\n",
            "# Podemos usarlos para que el código sea más descriptivo y legible.\n",
            "class Kid(enum.Enum):\n",
            "BOY = 0\n",
            "GIRL = 1\n",
            "def random_kid() -> Kid:\n",
            "return random.choice([Kid.BOY, Kid.GIRL])\n",
            "both_girls = 0\n",
            "older_girl = 0\n",
            "either_girl = 0\n",
            "random.seed(0)\n",
            "for _ in range(10000):\n",
            "younger = random_kid()\n",
            "older = random_kid()\n",
            "if older == Kid.GIRL:\n",
            "older_girl += 1\n",
            "if older == Kid.GIRL and younger == Kid.GIRL:\n",
            "both_girls += 1\n",
            "if older == Kid.GIRL or younger == Kid.GIRL:\n",
            "either_girl += 1\n",
            "print(\"P(both | older):\", both_girls / older_girl)\n",
            "# 0.514 ~ 1/2\n",
            "print(\"P(both | either): \", both_girls / either_girl)\n",
            "# 0.342 ~ 1/3\n",
            "Teorema de Bayes\n",
            "Uno de los mejores amigos del científico de datos es el teorema de Bayes,\n",
            "una forma de “revertir” las probabilidades condicionales. Digamos que\n",
            "necesitamos conocer la probabilidad de un cierto evento \n",
            "E\n",
            " condicionado\n",
            "porque algún otro evento \n",
            "F\n",
            " ocurra. Pero solamente tenemos información\n",
            "sobre la probabilidad de \n",
            "F\n",
            " condicionado porque \n",
            "E\n",
            " ocurra. Emplear la\n",
            "definición de probabilidad condicional dos veces nos dice que:\n",
            "P\n",
            "(\n",
            "E\n",
            "|\n",
            "F\n",
            ") = \n",
            "P\n",
            "(\n",
            "E\n",
            ",\n",
            "F\n",
            ")/\n",
            "P\n",
            "(\n",
            "F\n",
            ") = \n",
            "P\n",
            "(\n",
            "F\n",
            "|\n",
            "E\n",
            ")\n",
            "P\n",
            "(\n",
            "E\n",
            ")/\n",
            "P\n",
            "(\n",
            "F\n",
            ")\n",
            "El evento \n",
            "F\n",
            " puede dividirse en los dos eventos mutuamente exclusivos “\n",
            "F\n",
            "y \n",
            "E\n",
            "” y “\n",
            "F\n",
            " y no \n",
            "E\n",
            "”. Si escribimos ¬E por “no \n",
            "E\n",
            "” (es decir, “\n",
            "E\n",
            " no ocurre”),entonces:\n",
            "P\n",
            "(\n",
            "F\n",
            ") = \n",
            "P\n",
            "(\n",
            "F\n",
            ",\n",
            "E\n",
            ") + \n",
            "P\n",
            "(\n",
            "F\n",
            ",¬E)\n",
            "De modo que:\n",
            "P\n",
            "(\n",
            "E\n",
            "|\n",
            "F\n",
            ") = \n",
            "P\n",
            "(\n",
            "F\n",
            "|\n",
            "E\n",
            ")\n",
            "P\n",
            "(\n",
            "E\n",
            ")/[\n",
            "P\n",
            "(\n",
            "F\n",
            "|\n",
            "E\n",
            ")\n",
            "P\n",
            "(\n",
            "E\n",
            ") + \n",
            "P\n",
            "(\n",
            "F\n",
            "|¬E)\n",
            "P\n",
            "(¬E)]\n",
            "Que es como se suele enunciar el teorema de Bayes.\n",
            "Este teorema se utiliza a menudo para demostrar por qué los científicos de\n",
            "datos son más inteligentes que los médicos. Imaginemos una cierta\n",
            "enfermedad que afecta a 1 de cada 10.000 personas. Supongamos que existe\n",
            "una prueba para esta enfermedad que da el resultado correcto (“enfermo” si\n",
            "se tiene la enfermedad y “no enfermo” si no se tiene) el 99 % de las veces.\n",
            "¿Qué significa una prueba positiva? Utilicemos \n",
            "T\n",
            " para el evento “la\n",
            "prueba es positiva” y \n",
            "D\n",
            " para el evento “tiene la enfermedad”. Entonces, el\n",
            "teorema de Bayes dice que la probabilidad de que tenga la enfermedad,\n",
            "condicionada porque la prueba sea positiva, es:\n",
            "P\n",
            "(\n",
            "D\n",
            "|\n",
            "T\n",
            ") = \n",
            "P\n",
            "(\n",
            "T\n",
            "|\n",
            "D\n",
            ")\n",
            "P\n",
            "(\n",
            "D\n",
            ")/[\n",
            "P\n",
            "(\n",
            "T\n",
            "|\n",
            "D\n",
            ")\n",
            "P\n",
            "(\n",
            "D\n",
            ") + \n",
            "P\n",
            "(\n",
            "T\n",
            "|¬\n",
            "D\n",
            ")\n",
            "P\n",
            "(¬\n",
            "D\n",
            ")]\n",
            "Aquí sabemos que \n",
            "P\n",
            "(\n",
            "T\n",
            "|\n",
            "D\n",
            "), la probabilidad de que la prueba sea positiva en\n",
            "alguien que tenga la enfermedad, es 0,99. \n",
            "P\n",
            "(\n",
            "D\n",
            "), la probabilidad de que\n",
            "cualquier persona tenga la enfermedad, es 1/10.000 = 0,0001. \n",
            "P\n",
            "(\n",
            "T\n",
            "|¬\n",
            "D\n",
            "), la\n",
            "probabilidad de que alguien que no tenga la enfermedad dé positivo en la\n",
            "prueba, es de 0,01. Y \n",
            "P\n",
            "(¬\n",
            "D\n",
            "), la probabilidad de que cualquier persona no\n",
            "tenga la enfermedad, es 0,9999. Si se sustituyen estos números en el teorema\n",
            "de Bayes, se obtiene:\n",
            "P\n",
            "(\n",
            "D\n",
            "|\n",
            "T\n",
            ") = 0,98%\n",
            "Es decir, menos del 1 % de las personas cuya prueba fue positiva tienen\n",
            "realmente la enfermedad.\n",
            "Nota:\n",
            " Esto supone que las personas se hacen la prueba más o menos\n",
            "aleatoriamente. Si solo las personas con determinados síntomas se hicieran laprueba, en lugar de ello tendríamos que condicionar con el evento “prueba\n",
            "positiva y síntomas” y el número sería seguramente mucho más alto.\n",
            "Una forma más intuitiva de ver esto es imaginar una población de 1 millón\n",
            "de personas. Podríamos esperar que 100 de ellas tuvieran la enfermedad, y\n",
            "que 99 de esas 100 dieran positivo. Por otro lado, supondríamos que 999.990\n",
            "de ellas no tendrían la enfermedad, y que 9.999 de ellas darían positivo. Eso\n",
            "significa que se esperaría que solo 99 de (99 + 9.999) personas con la prueba\n",
            "positiva tuvieran realmente la enfermedad.\n",
            "Variables aleatorias\n",
            "Una variable aleatoria es una variable cuyos posibles valores tienen una\n",
            "distribución de probabilidad asociada. Una variable aleatoria muy sencilla es\n",
            "igual a 1 si al lanzar una moneda sale cara y a 0 si sale cruz. Otra más\n",
            "complicada mediría el número de caras que se observan al lanzar una moneda\n",
            "10 veces o un valor tomado de \n",
            "range(10)\n",
            ", donde cada número es igualmente\n",
            "probable.\n",
            "La distribución asociada da las probabilidades de que la variable realice\n",
            "cada uno de sus posibles valores. La variable lanzamiento de moneda es igual\n",
            "a 0 con una probabilidad de 0,5 y a 1 con una probabilidad de 0,5. La variable\n",
            "range(10)\n",
            " tiene una distribución que asigna una probabilidad de 0,1 a cada\n",
            "uno de los números de 0 a 9.\n",
            "En ocasiones, hablaremos del valor esperado de una variable aleatoria, que\n",
            "es la media de sus valores ponderados por sus probabilidades. La variable\n",
            "lanzamiento de moneda tiene un valor esperado de 1/2 (= 0 * 1/2 + 1 * 1/2), y\n",
            "la variable \n",
            "range(10)\n",
            " tiene un valor esperado de 4,5.\n",
            "Las variables aleatorias pueden estar condicionadas por eventos igual que\n",
            "el resto de eventos puede estarlo. Volviendo al ejemplo de los dos hijos de la\n",
            "sección “Probabilidad condicional”, si \n",
            "X\n",
            " es la variable aleatoria que\n",
            "representa el número de niñas, \n",
            "X\n",
            " es igual a 0 con una probabilidad de 1/4, 1\n",
            "con una probabilidad de 1/2 y 2 con una probabilidad de 1/4.Podemos definir una nueva variable aleatoria \n",
            "Y\n",
            " que da el número de niñas\n",
            "condicionado por al menos que uno de los hijos sea una niña. Entonces \n",
            "Y\n",
            " es\n",
            "igual a 1 con una probabilidad de 2/3 y a 2 con una probabilidad de 1/3. Y\n",
            "una variable \n",
            "Z\n",
            " que es el número de niñas condicionado porque el otro hijo sea\n",
            "una niña es igual a 1 con una probabilidad de 1/2 y a 2 con una probabilidad\n",
            "de 1/2.\n",
            "La mayor parte de las veces estaremos utilizando variables aleatorias de\n",
            "forma implícita en lo que hagamos sin atraer especialmente la atención hacia\n",
            "ellas. Pero si mira atentamente las verá.\n",
            "Distribuciones continuas\n",
            "El lanzamiento de una moneda se corresponde con una distribución\n",
            "discreta, que asocia probabilidad positiva con resultados discretos. A menudo\n",
            "querremos modelar distribuciones a lo largo de una serie de resultados (para\n",
            "nuestros fines, estos resultados siempre serán números reales, aunque ese no\n",
            "sea siempre el caso en la vida real). Por ejemplo, la distribución uniforme\n",
            "pone el mismo peso en todos los números entre 0 y 1.\n",
            "Como hay infinitos números entre 0 y 1, eso significa que el peso que\n",
            "asigna a puntos individuales debe ser necesariamente 0. Por esta razón\n",
            "representamos una distribución continua con una función de densidad de\n",
            "probabilidad PDF (\n",
            "Probability Density Function\n",
            ") tal que la probabilidad de\n",
            "ver un valor en un determinado intervalo es igual a la integral de la función\n",
            "de densidad sobre el intervalo.\n",
            "Nota:\n",
            " Si tiene un poco oxidado el cálculo de integrales, una forma más sencilla\n",
            "de comprender esto es que si una distribución tiene la función de densidad ƒ,\n",
            "entonces la probabilidad de ver un valor entre \n",
            "x\n",
            " y \n",
            "x\n",
            " + \n",
            "h\n",
            " es aproximadamente de\n",
            "h\n",
            " * ƒ(\n",
            "x\n",
            ") si h es pequeño.\n",
            "La función de densidad para la distribución uniforme es sencillamente:\n",
            "def uniform_pdf(x: float) -> float:return 1 if 0 <= x < 1 else 0\n",
            "La probabilidad de que una variable aleatoria siguiendo esa distribución\n",
            "esté entre 0,2 y 0,3 es de 1/10, como era de esperar. La variable\n",
            "random.random\n",
            " de Python es (pseudo)aleatoria con una densidad uniforme.\n",
            "Con frecuencia estaremos más interesados en la función de distribución\n",
            "acumulativa CDF (\n",
            "Cumulative Distribution Function\n",
            "), que da la probabilidad\n",
            "de que una variable aleatoria sea menor o igual a un determinado valor. No es\n",
            "difícil crear la función CDF para la distribución uniforme (véase la figura\n",
            "6.1):\n",
            "def uniform_cdf(x: float) -> float:\n",
            "\"\"\"Returns the probability that a uniform random variable is <= x\"\"\"\n",
            "if x < 0: return 0\n",
            "# aleatoria uniforme nunca es menor que 0\n",
            "elif x < 1: return x\n",
            "# p.ej. P(X <= 0.4) = 0.4\n",
            "else: return 1\n",
            "# aleatoria uniforme es siempre menor que 1\n",
            "Figura 6.1. \n",
            "La función CDF uniforme.La distribución normal\n",
            "La distribución normal es la distribución clásica en forma de campana y se\n",
            "determina completamente con dos parámetros: su media \n",
            "μ\n",
            " (mu) y su\n",
            "desviación estándar σ (sigma). La media indica dónde está centrada la\n",
            "campana, y la desviación estándar lo “ancha” que es.\n",
            "Tiene la función PDF:\n",
            "Que podemos implementar como:\n",
            "import math\n",
            "SQRT_TWO_PI = math.sqrt(2 * math.pi)\n",
            "def normal_pdf(x: float, mu: float = 0, sigma: float = 1) -> float:\n",
            "return (math.exp(-(x-mu) ** 2 / 2 / sigma ** 2) / (SQRT_TWO_PI * sigma))\n",
            "En la figura 6.2 trazamos algunas de estas funciones PDF para ver cómo\n",
            "quedan:\n",
            "import matplotlib.pyplot as plt\n",
            "xs = [x / 10.0 for x in range(-50, 50)]\n",
            "plt.plot(xs,[normal_pdf(x,sigma=1) for x in xs],’-’,label=’mu=0,sigma=1’)\n",
            "plt.plot(xs,[normal_pdf(x,sigma=2) for x in xs],’—’,label=’mu=0,sigma=2’)\n",
            "plt.plot(xs,[normal_pdf(x,sigma=0.5) for x in xs],’:’,label=’mu=0,sigma=0.5’)\n",
            "plt.plot(xs,[normal_pdf(x,mu=-1) for x in xs],’-.’,label=’mu=-1,sigma=1’)\n",
            "plt.legend()\n",
            "plt.title(\"Various Normal pdfs\")\n",
            "plt.show()Figura 6.2. \n",
            "Varias funciones PDF normales.\n",
            "Cuando \n",
            "μ\n",
            " = 0 y σ = 1, se denomina distribución normal estándar. Si \n",
            "Z\n",
            " es\n",
            "una variable aleatoria normal estándar, entonces resulta que:\n",
            "X\n",
            " = σ\n",
            "Z\n",
            " + \n",
            "μ\n",
            "También es normal, pero con media \n",
            "μ\n",
            " y desviación estándar σ. A la\n",
            "inversa, si \n",
            "X\n",
            " es una variable aleatoria normal con media \n",
            "μ\n",
            " y desviación\n",
            "estándar σ:\n",
            "Z\n",
            " = (\n",
            "X\n",
            "- \n",
            "μ\n",
            ")/σ\n",
            "Es una variable normal estándar.\n",
            "La función CDF para la distribución normal no se puede escribir de una\n",
            "forma “elemental”, pero podemos hacerlo utilizando la función de error\n",
            "math.erf\n",
            " de Python:\n",
            "1\n",
            "def normal_cdf(x: float, mu: float = 0, sigma: float = 1) -> float:\n",
            "return (1 + math.erf((x–mu) / math.sqrt(2) / sigma)) / 2De nuevo, en la figura 6.3 trazamos algunas CDF:\n",
            "xs = [x / 10.0 for x in range(-50, 50)]\n",
            "plt.plot(xs,[normal_cdf(x,sigma=1) for x in xs],’-’,label=’mu=0,sigma=1’)\n",
            "plt.plot(xs,[normal_cdf(x,sigma=2) for x in xs],’—’,label=’mu=0,sigma=2’)\n",
            "plt.plot(xs,[normal_cdf(x,sigma=0.5) for x in xs],’:’,label=’mu=0,sigma=0.5’)\n",
            "plt.plot(xs,[normal_cdf(x,mu=-1) for x in xs],’-.’,label=’mu=-1,sigma=1’)\n",
            "plt.legend(loc=4) # bottom right\n",
            "plt.title(\"Various Normal cdfs\")\n",
            "plt.show()\n",
            "Figura 6.3. \n",
            "Varias CDF normales.\n",
            "Algunas veces tendremos que invertir \n",
            "normal_cdf\n",
            " para encontrar el valor\n",
            "correspondiente a una determinada probabilidad. No hay una forma sencilla\n",
            "de calcular su inverso, pero \n",
            "normal_cdf\n",
            " es continuo y estrictamente\n",
            "creciente, de modo que utilizaremos una búsqueda binaria:\n",
            "2\n",
            "def inverse_normal_cdf(p: float,\n",
            "mu: float = 0,\n",
            "sigma: float = 1,\n",
            "tolerance: float = 0.00001) -> float:\n",
            "\"\"\"Find approximate inverse using binary search\"\"\"\n",
            "# si no es estándar, calcula estándar y redimensionaif mu != 0 or sigma != 1:\n",
            "return mu + sigma * inverse_normal_cdf(p, tolerance=tolerance)\n",
            "low_z = -10.0\n",
            "# normal_cdf(-10) es (muy cercano a) 0\n",
            "hi_z = 10.0\n",
            "# normal_cdf(10) es (muy cercano a) 1\n",
            "while hi_z–low_z > tolerance:\n",
            "mid_z = (low_z + hi_z) /\n",
            "2\n",
            "# Considera el punto medio\n",
            "mid_p =\n",
            "normal_cdf(mid_z)\n",
            "# y el valor de la CDF allí\n",
            "if mid_p < p:\n",
            "low_z = mid_z\n",
            "# Punto medio demasiado bajo, busca por\n",
            "encima\n",
            "else:\n",
            "hi_z = mid_z\n",
            "# Punto medio demasiado alto, busca por\n",
            "debajo\n",
            "return mid_z\n",
            "La función bisecciona repetidamente intervalos hasta que se estrecha en\n",
            "una \n",
            "Z\n",
            " que esté lo bastante cerca de la probabilidad deseada.\n",
            "El teorema central del límite\n",
            "Una razón por la que la distribución normal es tan útil es el teorema\n",
            "central del límite, que dice (básicamente) que una variable aleatoria, definida\n",
            "como la media de un gran número de variables aleatorias independientes y\n",
            "distribuidas de manera idéntica, está en sí misma aproximadamente y\n",
            "normalmente distribuida.\n",
            "En particular, si \n",
            "x\n",
            "1, ..., \n",
            "x\n",
            "n son variables aleatorias con media \n",
            "μ\n",
            " y\n",
            "desviación estándar σ, y si \n",
            "n\n",
            " es grande, entonces:\n",
            "Está aproximadamente y normalmente distribuida con media \n",
            "μ\n",
            " y\n",
            "desviación estándar\n",
            ". De forma equivalente (pero a menudo más útil):Está aproximadamente y normalmente distribuida con media 0 y\n",
            "desviación estándar 1.\n",
            "Una forma sencilla de ilustrar esto es mirando las variables aleatorias\n",
            "binomiales, que tienen dos parámetros \n",
            "n\n",
            " y \n",
            "p\n",
            ". Una variable aleatoria\n",
            "Binomial(\n",
            "n\n",
            ",\n",
            "p\n",
            ") no es más que la suma de \n",
            "n\n",
            " variables aleatorias independientes\n",
            "Bernoulli(\n",
            "p\n",
            "), cada una de las cuales es igual a 1 con una probabilidad de \n",
            "p\n",
            " y a\n",
            "0 con una probabilidad 1 - \n",
            "p\n",
            ":\n",
            "def bernoulli_trial(p: float) -> int:\n",
            "\"\"\"Returns 1 with probability p and 0 with probability 1-p\"\"\"\n",
            "return 1 if random.random() < p else 0\n",
            "def binomial(n: int, p: float) -> int:\n",
            "\"\"\"Returns the sum of n bernoulli(p) trials\"\"\"\n",
            "return sum(bernoulli_trial(p) for _ in range(n))\n",
            "La media de una variable Bernoulli(\n",
            "p\n",
            ") es \n",
            "p\n",
            ", y su desviación estándar es \n",
            ". El teorema central del límite dice que cuando \n",
            "n\n",
            " es más grande, una\n",
            "variable Binomial(\n",
            "n\n",
            ",\n",
            "p\n",
            ") es aproximadamente una variable aleatoria normal\n",
            "con media \n",
            "μ\n",
            " = \n",
            "np\n",
            " y desviación estándar \n",
            ".\n",
            "Si trazamos ambas, se puede ver fácilmente el parecido:\n",
            "from collections import Counter\n",
            "def binomial_histogram(p: float, n: int, num_points: int) -> None:\n",
            "\"\"\"Picks points from a Binomial(n, p) and plots their histogram\"\"\"\n",
            "data = [binomial(n, p) for _ in range(num_points)]\n",
            "# usa un gráfico de barras para mostrar las muestras binomiales reales\n",
            "histogram = Counter(data)\n",
            "plt.bar([x–0.4 for x in histogram.keys()],\n",
            "[v / num_points for v in histogram.values()],\n",
            "0.8,\n",
            "color=’0.75’)\n",
            "mu = p * n\n",
            "sigma = math.sqrt(n * p * (1–p))\n",
            "# usa un gráfico de líneas para mostrar la aproximación normal\n",
            "xs = range(min(data), max(data) + 1)\n",
            "ys = [normal_cdf(i + 0.5, mu, sigma)–normal_cdf(i–0.5, mu, sigma)\n",
            "for i in xs]plt.plot(xs,ys)\n",
            "plt.title(\"Binomial Distribution vs. Normal Approximation\")\n",
            "plt.show()\n",
            "Por ejemplo, cuando llamamos a \n",
            "make_hist(0.75,\n",
            " \n",
            "100,\n",
            " \n",
            "10000)\n",
            ",\n",
            "obtenemos el gráfico de la figura 6.4.\n",
            "La moraleja de esta aproximación es que, si queremos conocer la\n",
            "probabilidad de que (supongamos) al lanzar una moneda se saquen más de 60\n",
            "caras en 100 lanzamientos, se puede estimar como la probabilidad de que un\n",
            "Normal(50,5) es mayor que 60, que es más fácil que calcular la función CDF\n",
            "Binomial(100,0.5) (aunque en la mayoría de las aplicaciones probablemente\n",
            "utilizaríamos software estadístico que calcularía felizmente cualesquiera\n",
            "probabilidades deseadas).\n",
            "Figura 6.4. \n",
            "El resultado de \n",
            "binomial_histogram\n",
            ".\n",
            "Para saber más■\n",
            "scipy.stats, en\n",
            "https://docs.scipy.org/doc/scipy/reference/stats.html\n",
            ",\n",
            "contiene funciones PDF y CDF para la mayoría de las distribuciones de\n",
            "probabilidad más conocidas.\n",
            "■\n",
            "¿Recuerda que, al final del capítulo 5, dije que sería una buena idea\n",
            "estudiar un libro de texto de estadística? Pues también lo sería\n",
            "estudiarlo de probabilidad. El mejor que conozco que está disponible\n",
            "en la red es \n",
            "Introduction to ProbabilityK\n",
            ", en\n",
            "https://math.dartmouth.edu/~prob/prob/prob.pdf\n",
            ", de Charles M.\n",
            "Grinstead y J. Laurie Snell (American Mathematical Society).\n",
            "1\n",
            " \n",
            "https://es.wikipedia.org/wiki/Funci%C3%B3n_error\n",
            ".\n",
            "2\n",
            " \n",
            "https://es.wikipedia.org/wiki/B%C3%BAsqueda_binaria\n",
            ".7\n",
            " Hipótesis e inferencia\n",
            "Es signo de una persona realmente inteligente el sentirse conmovida por las\n",
            "estadísticas.\n",
            "—George Bernard Shaw\n",
            "¿Qué haremos con toda esta estadística y toda esta teoría de la\n",
            "probabilidad? La parte científica de la ciencia de datos implica habitualmente\n",
            "la formación y comprobación de hipótesis sobre nuestros datos y sobre los\n",
            "procesos que los generan.\n",
            "Comprobación de hipótesis estadísticas\n",
            "A menudo, como científicos de datos, querremos probar si una\n",
            "determinada hipótesis es probable que sea cierta. Para nuestros fines, las\n",
            "hipótesis son aseveraciones como “esta moneda está equilibrada”, o “los\n",
            "científicos de datos prefieren Python a R”, o “es más probable que la gente\n",
            "salga de la página sin haber leído el contenido si aparece un irritante anuncio\n",
            "intercalado con un botón de cerrar diminuto y difícil de encontrar”, que se\n",
            "pueden traducir en estadísticas sobre datos. Bajo diferentes supuestos, se\n",
            "pueden considerar esas estadísticas como observaciones de variables\n",
            "aleatorias de distribuciones conocidas, lo que nos permite hacer afirmaciones\n",
            "sobre la probabilidad de que esos supuestos se cumplan.\n",
            "En una configuración clásica, tenemos una hipótesis nula, \n",
            "H\n",
            "0\n",
            ", que\n",
            "representa una cierta posición predeterminada, y otra hipótesis alternativa,\n",
            "H\n",
            "1\n",
            ", con la que nos gustaría compararla. Utilizamos la estadística para decidir\n",
            "si podemos rechazar \n",
            "H\n",
            "0\n",
            " como falsa o no. Probablemente esto tiene más\n",
            "sentido con un ejemplo.Ejemplo: Lanzar una moneda\n",
            "Imaginemos que tenemos una moneda y queremos comprobar si es justa.\n",
            "Haremos la suposición de que la moneda tiene una cierta probabilidad \n",
            "p\n",
            " de\n",
            "sacar cara, de modo que nuestra hipótesis nula es que la moneda es justa (es\n",
            "decir, que \n",
            "p\n",
            " = 0,5). Comprobaremos esto frente a la hipótesis alternativa \n",
            "p\n",
            " ≠\n",
            "0,5.\n",
            "En particular, nuestra prueba implicará lanzar la moneda un número \n",
            "n\n",
            " de\n",
            "veces y contar el número de caras que salen, \n",
            "X\n",
            ". Cada lanzamiento de la\n",
            "moneda es un ensayo de Bernoulli, lo que significa que \n",
            "X\n",
            " es una variable\n",
            "aleatoria Binomial(\n",
            "n\n",
            ",\n",
            "p\n",
            "), la cual (como ya vimos en el capítulo 6) podemos\n",
            "aproximar utilizando la distribución normal:\n",
            "from typing import Tuple\n",
            "import math\n",
            "def normal_approximation_to_binomial(n: int, p: float) -> Tuple[float, float]:\n",
            "\"\"\"Returns mu and sigma corresponding to a Binomial(n, p)\"\"\"\n",
            "mu = p * n\n",
            "sigma = math.sqrt(p * (1–p) * n)\n",
            "return mu, sigma\n",
            "Siempre que una variable aleatoria siga una distribución normal, podemos\n",
            "utilizar \n",
            "normal_cdf\n",
            " para averiguar la probabilidad de que su valor realizado\n",
            "esté dentro o fuera de un determinado intervalo:\n",
            "from scratch.probability import normal_cdf\n",
            "# La normal cdf _es_ la probabilidad de que la variable esté por debajo de un\n",
            "límite\n",
            "normal_probability_below = normal_cdf\n",
            "# Está por encima del límite si no está por debajo\n",
            "def normal_probability_above(lo: float,\n",
            "mu: float = 0,\n",
            "sigma: float = 1) -> float:\n",
            "\"\"\"The probability that an N(mu, sigma) is greater than lo.\"\"\"\n",
            "return 1–normal_cdf(lo, mu, sigma)\n",
            "# Está en medio si es menor que hi, pero no menor que lo\n",
            "def normal_probability_between(lo: float,\n",
            "hi: float,\n",
            "mu: float = 0,\n",
            "sigma: float = 1) -> float:\"\"\"The probability that an N(mu, sigma) is between lo and hi.\"\"\"\n",
            "return normal_cdf(hi, mu, sigma)–normal_cdf(lo, mu, sigma)\n",
            "# Está fuera si no está en medio\n",
            "def normal_probability_outside(lo: float,\n",
            "hi: float,\n",
            "mu: float = 0,\n",
            "sigma: float = 1) -> float:\n",
            "\"\"\"The probability that an N(mu, sigma) is not between lo and hi.\"\"\"\n",
            "return 1–normal_probability_between(lo, hi, mu, sigma)\n",
            "También podemos hacer lo contrario: encontrar o bien la región que no\n",
            "esté en un extremo o el intervalo (simétrico) en torno a la media que se tiene\n",
            "en cuenta para un determinado nivel de probabilidad. Por ejemplo, si\n",
            "queremos encontrar un intervalo centrado en la media y que contenga un 60\n",
            "% de probabilidad, entonces tenemos que hallar los límites en los que los\n",
            "extremos superior e inferior contienen cada uno un 20 % de la probabilidad\n",
            "(dejando el 60 %):\n",
            "from scratch.probability import inverse_normal_cdf\n",
            "def normal_upper_bound(probability: float,\n",
            "mu: float = 0,\n",
            "sigma: float = 1) -> float:\n",
            "\"\"\"Returns the z for which P(Z <= z) = probability\"\"\"\n",
            "return inverse_normal_cdf(probability, mu, sigma)\n",
            "def normal_lower_bound(probability: float,\n",
            "mu: float = 0,\n",
            "sigma: float = 1) -> float:\n",
            "\"\"\"Returns the z for which P(Z >= z) = probability\"\"\"\n",
            "return inverse_normal_cdf(1–probability, mu, sigma)\n",
            "def normal_two_sided_bounds(probability: float,\n",
            "mu: float = 0,\n",
            "sigma: float = 1) -> Tuple[float, float]:\n",
            "\"\"\"\n",
            "Returns the symmetric (about the mean) bounds\n",
            "that contain the specified probability\n",
            "\"\"\"\n",
            "tail_probability = (1–probability) / 2\n",
            "# el extremo superior tendría tail_probability por encima\n",
            "upper_bound = normal_lower_bound(tail_probability, mu, sigma)\n",
            "# el extremo inferior tendría tail_probability por debajo\n",
            "lower_bound = normal_upper_bound(tail_probability, mu, sigma)\n",
            "return lower_bound, upper_boundEn particular, digamos que elegimos lanzar la moneda \n",
            "n\n",
            " = 1.000 veces. Si\n",
            "nuestra hipótesis nula es cierta, \n",
            "X\n",
            " debería estar distribuida aproximadamente\n",
            "normal con una media de 500 y una desviación estándar de 15,8:\n",
            "mu_0, sigma_0 = normal_approximation_to_binomial(1000, 0.5)\n",
            "Tenemos que tomar una decisión sobre la significancia (lo dispuestos que\n",
            "estamos a cometer un error tipo 1 o “falso positivo”, en el que rechazamos\n",
            "H\n",
            "0\n",
            " incluso aunque sea verdadero). Por razones perdidas en los anales de la\n",
            "historia, esta voluntad se suele establecer en un 5 % o en un 1 %. Elijamos un\n",
            "5 %.\n",
            "Consideremos la prueba que rechaza \n",
            "H\n",
            "0\n",
            " si \n",
            "X\n",
            " queda fuera de los extremos\n",
            "dados por:\n",
            "# (469, 531)\n",
            "lower_bound, upper_bound = normal_two_sided_bounds(0.95, mu_0, sigma_0)\n",
            "Suponiendo que \n",
            "p\n",
            " es de verdad igual a 0,5 (es decir, \n",
            "H\n",
            "0\n",
            " es verdadero),\n",
            "solamente hay un 5 % de posibilidades de que observemos una \n",
            "X\n",
            " que esté\n",
            "fuera de este intervalo, que es exactamente la significancia que queríamos.\n",
            "Dicho de otro modo, si \n",
            "H\n",
            "0\n",
            " es verdadero, entonces aproximadamente 19 veces\n",
            "de 20 esta prueba dará el resultado correcto.\n",
            "También nos interesaremos a menudo por la potencia de una prueba de\n",
            "hipótesis, que es la probabilidad de no cometer un error tipo 2 (“falso\n",
            "negativo”), en el que no rechazamos \n",
            "H\n",
            "0\n",
            " incluso aunque sea falso. Para medir\n",
            "esto, tenemos que especificar lo que significa exactamente que \n",
            "H\n",
            "0\n",
            " sea falso\n",
            "(saber simplemente que \n",
            "p\n",
            " no es 0,5 no nos da mucha información sobre la\n",
            "distribución de \n",
            "X\n",
            "). En particular, comprobemos lo que ocurre si \n",
            "p\n",
            " es\n",
            "realmente 0,55, o sea, que la moneda tiende levemente hacia la cara.\n",
            "En ese caso, podemos calcular la potencia de la prueba con:\n",
            "# extremos en 95 % basados en suponer que p es 0,5\n",
            "lo, hi = normal_two_sided_bounds(0.95, mu_0, sigma_0)\n",
            "# mu y sigma reales basadas en p = 0,55\n",
            "mu_1, sigma_1 = normal_approximation_to_binomial(1000, 0.55)\n",
            "# un error tipo 2 significa que no rechazamos la hipótesis nula\n",
            "# lo que ocurrirá cuando X siga en nuestro intervalo original\n",
            "type_2_probability = normal_probability_between(lo, hi, mu_1, sigma_1)\n",
            "power = 1–type_2_probability\n",
            "# 0.887Imaginemos, en lugar de esto, que nuestra hipótesis nula fuera que la\n",
            "moneda no estuviera inclinada hacia la cara, o que \n",
            "p\n",
            " ≤ 0,5. En ese caso,\n",
            "queremos una prueba de una sola cara, que rechace la hipótesis nula cuando\n",
            "X\n",
            " es mucho mayor que 500, pero no cuando \n",
            "X\n",
            " es menor que 500. Así, una\n",
            "prueba de significancia del 5 % implica utilizar \n",
            "normal_probability_below\n",
            "para encontrar el límite bajo el que se sitúa el 95 % de la probabilidad:\n",
            "hi = normal_upper_bound(0.95, mu_0, sigma_0)\n",
            "# es 526 (<531, ya que necesitamos más probabilidad en el límite superior)\n",
            "type_2_probability = normal_probability_below(hi, mu_1, sigma_1)\n",
            "power = 1–type_2_probability\n",
            "# 0.936\n",
            "Esta es una comprobación más potente, dado que ya no rechaza \n",
            "H\n",
            "0\n",
            "cuando \n",
            "X\n",
            " está por debajo de 469 (que es muy improbable que ocurra si \n",
            "H\n",
            "1\n",
            " es\n",
            "verdadero), y en su lugar rechaza \n",
            "H\n",
            "0\n",
            " cuando \n",
            "X\n",
            " está entre 526 y 531 (lo que\n",
            "tiene alguna probabilidad de ocurrir si \n",
            "H\n",
            "1\n",
            " es verdadero).\n",
            "Valores p\n",
            "Una forma distinta de pensar en la prueba anterior involucra a los valores\n",
            "p\n",
            " o \n",
            "p-values\n",
            ". En vez de elegir límites basándonos en un tope de probabilidad,\n",
            "calculamos la probabilidad (suponiendo que \n",
            "H\n",
            "0\n",
            " sea verdadero) de ver un\n",
            "valor al menos tan extremo como el que realmente observamos.\n",
            "Para nuestra prueba de dos caras de si la moneda es justa, hacemos estos\n",
            "cálculos:\n",
            "def two_sided_p_value(x: float, mu: float = 0, sigma: float = 1) -> float:\n",
            "\"\"\"\n",
            "How likely are we to see a value at least as extreme as x (in either\n",
            "direction) if our values are from an N(mu, sigma)?\n",
            "\"\"\"\n",
            "if x >= mu:\n",
            "# x es mayor que la media, así el extremo es todo lo que es mayor que x\n",
            "return 2 * normal_probability_above(x, mu, sigma)\n",
            "else:# x es menor que la media, así el extremo es todo lo que es menor que x\n",
            "return 2 * normal_probability_below(x, mu, sigma)\n",
            "Si viéramos 530 caras, este sería el cálculo:\n",
            "two_sided_p_value(529.5, mu_0, sigma_0) # 0.062\n",
            "Nota:\n",
            " ¿Por qué hemos utilizado un valor de \n",
            "529.5\n",
            " en lugar de utilizar \n",
            "530\n",
            "? Esto\n",
            "es lo que se llama corrección por continuidad.\n",
            "1\n",
            " Refleja el hecho de que\n",
            "normal_probability_between(529.5,\n",
            " \n",
            "530.5,\n",
            " \n",
            "mu_0,\n",
            " \n",
            "sigma_0)\n",
            " es una mejor\n",
            "estimación de la probabilidad de ver 530 caras que\n",
            "normal_probability_between(530,\n",
            " \n",
            "531,\n",
            " \n",
            "mu_0,\n",
            " \n",
            "sigma_0)\n",
            ".\n",
            "En consecuencia, \n",
            "normal_probability_above(529.5,\n",
            " \n",
            "mu_0,\n",
            " \n",
            "sigma_0)\n",
            " es una mejor\n",
            "estimación de la probabilidad de ver al menos 530 caras. Quizá se haya dado\n",
            "cuenta de que también hemos utilizado esto en el código que producía la figura\n",
            "6.4.\n",
            "Una forma de autoconvencernos de que es una estimación razonable es\n",
            "utilizando una simulación:\n",
            "import random\n",
            "extreme_value_count = 0\n",
            "for _ in range(1000):\n",
            "num_heads = sum(1 if random.random() < 0.5\n",
            "else 0\n",
            "# Cuenta el nº de caras\n",
            "for _ in range(1000))\n",
            "# en 1.000 lanzamientos,\n",
            "if num_heads >= 530 or num_heads <= 470:\n",
            "# y cuenta con qué\n",
            "frecuencia\n",
            "extreme_value_count += 1\n",
            "# el nº es ‘extremo’\n",
            "# el p-value era 0,062 => ~62 valores extremos de 1.000\n",
            "assert 59 < extreme_value_count < 65, f\"{extreme_value_count}\"\n",
            "Como el valor \n",
            "p\n",
            " es mayor que nuestra significancia del 5 %, no\n",
            "rechazamos la hipótesis nula. Si viéramos sin embargo 532 caras, el valor \n",
            "p\n",
            "sería:\n",
            "two_sided_p_value(531.5, mu_0, sigma_0)\n",
            "# 0,0463\n",
            "Que es menor que la significancia del 5 %, lo que indica que sí la\n",
            "rechazaríamos. Es exactamente la misma prueba que antes, solo que con unaforma diferente de enfocar las estadísticas.\n",
            "De forma similar, tendríamos:\n",
            "upper_p_value = normal_probability_above\n",
            "lower_p_value = normal_probability_below\n",
            "Para nuestra prueba de una sola cara, si viéramos 525 caras calcularíamos:\n",
            "upper_p_value(524.5, mu_0, sigma_0)\n",
            "# 0,061\n",
            "Lo que significa que no rechazaríamos la hipótesis nula. Si viéramos 527\n",
            "caras, el cálculo sería:\n",
            "upper_p_value(526.5, mu_0, sigma_0)\n",
            "# 0,047\n",
            "Y sí rechazaríamos la hipótesis nula.\n",
            "Advertencia:\n",
            " Asegúrese de que sus datos están más o menos normalmente\n",
            "distribuidos antes de utilizar \n",
            "normal_probability_above\n",
            " para calcular valores \n",
            "p\n",
            ".\n",
            "Los anales de la ciencia de datos mal practicada están llenos de ejemplos de\n",
            "personas opinando que la posibilidad de que algún evento observado se\n",
            "produzca aleatoriamente es una entre un millón, cuando lo que realmente\n",
            "quieren decir es “la posibilidad, suponiendo que los datos estén normalmente\n",
            "distribuidos”, lo que no tiene mucho sentido si los datos no lo están.\n",
            "Existen diferentes pruebas estadísticas para la normalidad, pero incluso trazar\n",
            "los datos es un buen comienzo.\n",
            "Intervalos de confianza\n",
            "Hemos estado probando hipótesis sobre el valor de la probabilidad \n",
            "p\n",
            " de\n",
            "que salga cara, que es un parámetro de la distribución desconocida “cara”.\n",
            "Cuando es este el caso, un tercer método es construir un intervalo de\n",
            "confianza en torno al valor observado del parámetro.\n",
            "Por ejemplo, podemos estimar la probabilidad de la moneda injusta\n",
            "mirando el valor medio de las variables de Bernoulli correspondientes a cada\n",
            "lanzamiento (1 si es cara, 0 si es cruz). Si observamos 525 caras en 1.000lanzamientos, entonces estimamos que \n",
            "p\n",
            " es igual a 0,525.\n",
            "¿Qué confianza podemos tener en esta estimación? Bueno, si\n",
            "conociéramos el valor exacto de \n",
            "p\n",
            ", el teorema central del límite (recuerde la\n",
            "sección del mismo nombre del capítulo 6) nos dice que la media de dichas\n",
            "variables de Bernoulli debería ser aproximadamente normal, con una media\n",
            "de \n",
            "p\n",
            " y una desviación estándar de:\n",
            "math.sqrt(p * (1–p) / 1000)\n",
            "Aquí no conocemos \n",
            "p\n",
            ", así que por eso utilizamos nuestra estimación:\n",
            "p_hat = 525 / 1000\n",
            "mu = p_hat\n",
            "sigma = math.sqrt(p_hat * (1–p_hat) / 1000)\n",
            "# 0,0158\n",
            "Esto no está del todo justificado, pero la gente parece hacerlo de todas\n",
            "formas. Utilizando la aproximación normal, concluimos que “tenemos una\n",
            "confianza del 95 %” en que el siguiente intervalo contiene el verdadero\n",
            "parámetro \n",
            "p\n",
            ":\n",
            "normal_two_sided_bounds(0.95, mu, sigma)\n",
            "# [0.4940, 0.5560]\n",
            "Nota:\n",
            " Esta es una afirmación sobre el intervalo, no sobre \n",
            "p\n",
            ". Se debería\n",
            "entender como la aseveración de que, si repitiéramos el experimento muchas\n",
            "veces, el 95 % del tiempo el parámetro “verdadero” (que es el mismo cada vez)\n",
            "estaría dentro del intervalo de confianza observado (que podría ser diferente\n",
            "cada vez).\n",
            "En particular, no concluimos que la moneda sea injusta, ya que 0,5 está\n",
            "dentro de nuestro intervalo de confianza.\n",
            "Si lo que viéramos fueran 540 caras, entonces tendríamos:\n",
            "p_hat = 540 / 1000\n",
            "mu = p_hat\n",
            "sigma = math.sqrt(p_hat * (1–p_hat) / 1000)\n",
            "# 0,0158\n",
            "normal_two_sided_bounds(0.95, mu, sigma)\n",
            "# [0.5091, 0.5709]\n",
            "Aquí, “moneda justa” no está en el intervalo de confianza (la hipótesis de“moneda justa” no pasa una prueba que se supone que debiera pasar el 95 %\n",
            "de las veces si fuera verdadera).\n",
            "p-hacking\n",
            " o dragado de datos\n",
            "Un procedimiento que rechace erróneamente la hipótesis nula solo el 5 %\n",
            "de las veces rechazará (por definición) erróneamente la hipótesis nula el 5 %\n",
            "de las veces:\n",
            "from typing import List\n",
            "def run_experiment() -> List[bool]:\n",
            "\"\"\"Flips a fair coin 1000 times, True = heads, False = tails\"\"\"\n",
            "return [random.random() < 0.5 for _ in range(1000)]\n",
            "def reject_fairness(experiment: List[bool]) -> bool:\n",
            "\"\"\"Using the 5% significance levels\"\"\"\n",
            "num_heads = len([flip for flip in experiment if flip])\n",
            "return num_heads < 469 or num_heads > 531\n",
            "random.seed(0)\n",
            "experiments = [run_experiment() for _ in range(1000)]\n",
            "num_rejections = len([experiment\n",
            "for experiment in experiments\n",
            "if reject_fairness(experiment)])\n",
            "assert num_rejections == 46\n",
            "Lo que esto significa es que, si pretendemos encontrar resultados\n",
            "“significativos”, es posible hallarlos. Probando las hipótesis suficientes sobre\n",
            "nuestro conjunto de datos, casi con seguridad una de ellas será significativa.\n",
            "Si eliminamos los valores atípicos correctos, probablemente podremos\n",
            "obtener el valor p inferior a 0,05 (hemos hecho algo vagamente parecido en\n",
            "la sección “Correlación” del capítulo 5; ¿se había dado cuenta?).\n",
            "Esto a veces se denomina \n",
            "p-hacking\n",
            " o dragado de datos,\n",
            "2\n",
            " y en algunos\n",
            "aspectos es una consecuencia de la “infraestructura de inferencia de valores\n",
            "p\n",
            "”. Un buen artículo que critica este enfoque es “The Earth Is Round”\n",
            "3\n",
            " de\n",
            "Jacob Cohen.\n",
            "Si queremos hacer buena ciencia, deberemos determinar nuestras hipótesis\n",
            "antes de mirar los datos, limpiar los datos sin tener en mente las hipótesis yrecordar que los valores \n",
            "p\n",
            " no son sustitutos del sentido común (un método\n",
            "alternativo se trata en la sección “Inferencia bayesiana”, antes de finalizar\n",
            "este capítulo).\n",
            "Ejemplo: Realizar una prueba A/B\n",
            "Una de sus principales responsabilidades en DataSciencester es la\n",
            "optimización de la experiencia, un eufemismo para intentar que la gente haga\n",
            "clic en los anuncios. Uno de los anunciantes ha desarrollado una nueva\n",
            "bebida energética destinada a los científicos de datos, y el vicepresidente de\n",
            "Publicidad quiere que elija entre el anuncio A (“¡menudo sabor!) y el anuncio\n",
            "B (“¡menos prejuicios!”).\n",
            "Como somos científicos, decidimos realizar un experimento mostrando de\n",
            "forma aleatoria a los visitantes del sitio uno de los dos anuncios y haciendo\n",
            "un seguimiento de cuántos de ellos hacen clic sobre cada uno.\n",
            "Si 990 de 1.000 espectadores del anuncio A hacen clic en él, mientras que\n",
            "solamente 10 de 1.000 del anuncio B hacen clic en el B, podríamos estar\n",
            "bastante seguros de que A es el mejor anuncio. Pero ¿qué pasa si las\n",
            "diferencias no son tan abismales? Aquí es cuando entra en juego la inferencia\n",
            "estadística.\n",
            "Digamos que \n",
            "NA\n",
            " personas ven el anuncio A y que \n",
            "nA\n",
            " de ellas hacen clic\n",
            "en él. Podemos pensar en cada visión del anuncio como en un ensayo de\n",
            "Bernoulli, donde \n",
            "pA\n",
            " es la probabilidad de que alguien haga clic en el anuncio\n",
            "A. Entonces (si \n",
            "NA\n",
            " es grande, que lo es aquí) sabemos que \n",
            "nA\n",
            "/\n",
            "NA\n",
            " es\n",
            "aproximadamente una variable aleatoria normal, con una media de \n",
            "pA\n",
            " y una\n",
            "desviación estándar de \n",
            ".\n",
            "De forma similar, \n",
            "nB\n",
            "/\n",
            "NB\n",
            " es aproximadamente una variable aleatoria\n",
            "normal con una media de \n",
            "pB\n",
            " y una desviación estándar de \n",
            ".\n",
            "Podemos expresar esto en código del siguiente modo:\n",
            "def estimated_parameters(N: int, n: int) -> Tuple[float, float]:\n",
            "p = n / N\n",
            "sigma = math.sqrt(p * (1–p) / N)\n",
            "return p, sigmaSi suponemos que esas dos normales son independientes (lo que parece\n",
            "razonable, ya que los ensayos de Bernoulli individuales podrían serlo),\n",
            "entonces su diferencia también debería ser una normal con media \n",
            "PB\n",
            "–\n",
            "PA\n",
            " y\n",
            "desviación estándar \n",
            ".\n",
            "Nota:\n",
            " Esto es un poco trampa. Las mates solo cuadran exactamente así si\n",
            "conocemos las desviaciones estándar. Aquí estamos estimándolas desde los\n",
            "datos, lo que significa que en realidad deberíamos estar utilizando una\n",
            "distribución \n",
            "t\n",
            ". Pero, para conjuntos de datos bastante grandes, se aproxima lo\n",
            "suficiente como para no suponer una gran diferencia.\n",
            "Esto significa que podemos probar la hipótesis nula de que \n",
            "pA\n",
            " y \n",
            "pB\n",
            " son\n",
            "iguales (es decir, que \n",
            "pA\n",
            " - \n",
            "pB\n",
            " = 0) utilizando la estadística:\n",
            "def a_b_test_statistic(N_A: int, n_A: int, N_B: int, n_B: int) -> float:\n",
            "p_A, sigma_A = estimated_parameters(N_A, n_A)\n",
            "p_B, sigma_B = estimated_parameters(N_B, n_B)\n",
            "return (p_B–p_A) / math.sqrt(sigma_A ** 2 + sigma_B ** 2)\n",
            "Que debería ser aproximadamente una normal estándar.\n",
            "Por ejemplo, si “menudo sabor” obtiene 200 clics de 1.000 visitantes y\n",
            "“menos prejuicios” obtiene 180 clics de 1.000 espectadores, la estadística es\n",
            "igual a:\n",
            "z = a_b_test_statistic(1000, 200, 1000, 180)\n",
            "# -1,14\n",
            "La probabilidad de ver una diferencia tan grande si las medias fueran\n",
            "realmente iguales sería:\n",
            "two_sided_p_value(z)\n",
            "# 0,254\n",
            "Que es tan grande que no podemos concluir que haya mucha diferencia.\n",
            "Por otro lado, si “menos prejuicios” solo obtuviera 150 clics, tendríamos:\n",
            "z = a_b_test_statistic(1000, 200, 1000, 150)\n",
            "# -2,94\n",
            "two_sided_p_value(z)\n",
            "# 0,003Lo que significa que solamente hay una probabilidad de 0,003 de que\n",
            "veamos una diferencia tan grande si los anuncios fueran igualmente efectivos.\n",
            "Inferencia bayesiana\n",
            "Los procedimientos que hemos visto han supuesto realizar afirmaciones\n",
            "de probabilidad sobre nuestras pruebas: por ejemplo, “solo hay un 3 % de\n",
            "posibilidades de que observemos una estadística tan extrema si nuestras\n",
            "hipótesis nulas fueran verdaderas”.\n",
            "Un método distinto a la inferencia implica tratar los parámetros\n",
            "desconocidos como variables aleatorias. El analista (que es usted) empieza\n",
            "con una distribución previa para los parámetros y después utiliza los datos\n",
            "observados y el teorema de Bayes para obtener una distribución posterior\n",
            "actualizada para los parámetros. En lugar de hacer juicios de probabilidad\n",
            "sobre las pruebas, mejor hacer juicios de probabilidad sobre los parámetros.\n",
            "Por ejemplo, cuando el parámetro desconocido es una probabilidad (como\n",
            "en nuestro ejemplo del lanzamiento de la moneda), a menudo empleamos una\n",
            "previa de la distribución beta, que coloca toda su probabilidad entre 0 y 1:\n",
            "def B(alpha: float, beta: float) -> float:\n",
            "\"\"\"A normalizing constant so that the total probability is 1\"\"\"\n",
            "return math.gamma(alpha) * math.gamma(beta) / math.gamma(alpha + beta)\n",
            "def beta_pdf(x: float, alpha: float, beta: float) -> float:\n",
            "if x <= 0 or x >= 1:\n",
            "# no hay peso fuera de [0, 1]\n",
            "return 0\n",
            "return x ** (alpha–1) * (1–x) ** (beta–1) / B(alpha, beta)\n",
            "Por lo general, esta distribución centra su peso en:\n",
            "alpha / (alpha + beta)\n",
            "Y, cuanto más grandes sean \n",
            "alpha\n",
            " y \n",
            "beta\n",
            ", más “ajustada” es la\n",
            "distribución.\n",
            "Por ejemplo, si \n",
            "alpha\n",
            " y \n",
            "beta\n",
            " son ambas 1, es la distribución uniforme\n",
            "como tal (centrada en 0,5, muy dispersa). Si \n",
            "alpha\n",
            " es mucho mayor quebeta\n",
            ", la mayor parte del peso está cerca de 1. Y si \n",
            "alpha\n",
            " es mucho menor que\n",
            "beta\n",
            ", la mayor parte del peso está cerca de 0. La figura 7.1 muestra varias\n",
            "distribuciones beta diferentes.\n",
            "Figura 7.1. \n",
            "Distribuciones beta de ejemplo.\n",
            "Digamos que suponemos una distribución anterior en \n",
            "p\n",
            ". Quizá no\n",
            "queramos tomar partido sobre si la moneda es justa, así que elegimos que\n",
            "alpha\n",
            " y \n",
            "beta\n",
            " sean ambas 1. O quizá tenemos clarísimo que la moneda saca\n",
            "cara el 55 % de las veces, por lo que elegimos que \n",
            "alpha\n",
            " sea igual a 55 y\n",
            "beta\n",
            " sea igual a 45.\n",
            "Entonces lanzamos nuestra moneda un montón de veces y vemos \n",
            "h\n",
            " caras y\n",
            "t\n",
            " cruces. El teorema de Bayes (y otros cálculos matemáticos demasiado\n",
            "aburridos como para explicarlos aquí) nos dice que la distribución posterior\n",
            "para \n",
            "p\n",
            " es de nuevo una distribución beta, pero con los parámetros \n",
            "alpha + h\n",
            "y \n",
            "beta + t\n",
            ".\n",
            "Nota:\n",
            " No es una coincidencia que la distribución posterior sea de nuevo una\n",
            "distribución beta. El número de caras viene dado por una distribución binomial,y la beta es la previa conjugada\n",
            "4\n",
            " a la distribución binomial. Esto significa que,\n",
            "siempre que actualicemos una beta previa utilizando observaciones de la\n",
            "correspondiente binomial, obtendremos una posterior beta.\n",
            "Digamos que lanzamos la moneda 10 veces y solo vemos 3 caras. Si\n",
            "empezáramos con la anterior uniforme (negándonos en cierto sentido a tomar\n",
            "partido sobre que la moneda sea justa o no), nuestra distribución posterior\n",
            "sería una Beta(4, 8), centrada en torno a 0,33. Como consideramos todas las\n",
            "probabilidades igualmente probables, nuestro mejor intento es próximo a la\n",
            "probabilidad observada.\n",
            "Si empezáramos con una Beta(20, 20) (expresando la creencia de que la\n",
            "moneda era más o menos justa), nuestra distribución posterior sería una\n",
            "Beta(23, 27), centrada en torno a 0,46, indicando una creencia revisada de\n",
            "que quizá la moneda tiene una ligera tendencia hacia cruz.\n",
            "Pero, si empezáramos con una Beta(30, 10) (expresando la creencia de\n",
            "que la moneda tiende a sacar cara un 75 % de las veces), nuestra distribución\n",
            "posterior sería una Beta(33, 17), centrada en torno a 0,66. En ese caso,\n",
            "seguiríamos creyendo en un desequilibrio hacia cara, pero con menos\n",
            "vehemencia que al principio. Estas tres diferentes posteriores se trazan en la\n",
            "figura 7.2.Figura 7.2. \n",
            "Posteriores surgiendo de distintas previas.\n",
            "Si tirásemos la moneda más y más veces, la previa importaría cada vez\n",
            "menos hasta que al final tendríamos (casi) la misma distribución posterior sin\n",
            "importar la anterior con la que hubiéramos empezado.\n",
            "Por ejemplo, sin importar la tendencia que nos parecía que pudiera tener la\n",
            "moneda en un principio, sería difícil mantener esa creencia tras ver 1.000\n",
            "caras después de 2.000 lanzamientos, a menos que fuéramos unos lunáticos\n",
            "que eligiéramos algo parecido a una previa Beta(1000000,1).\n",
            "Lo interesante es que esto nos permite realizar afirmaciones de\n",
            "probabilidad sobre las hipótesis: “Basándonos en la previa y en los datos\n",
            "observados, solo hay un 5 % de posibilidades de que la probabilidad de que la\n",
            "moneda saque cara esté entre el 49 % y el 51 %”. Esto es filosóficamente\n",
            "muy distinto a una aseveración como “si la moneda fuera justa, esperaríamos\n",
            "observar datos tan extremos solo el 5 % de las veces”.\n",
            "Utilizar la inferencia bayesiana para probar hipótesis se considera un poco\n",
            "controvertido (en parte porque las matemáticas pueden llegar a ser bastante\n",
            "complicadas, y en parte debido a la naturaleza subjetiva de elegir una previa).\n",
            "No la utilizaremos más en este libro, pero es bueno conocerla.Para saber más\n",
            "■\n",
            "Apenas hemos arañado la superficie de lo que debería saber sobre\n",
            "inferencia estadística. Los libros recomendados al final del capítulo 5\n",
            "entran mucho más en detalle al respecto.\n",
            "■\n",
            "Coursera ofrece un curso de análisis de datos e inferencia estadística,\n",
            "en \n",
            "https://www.coursera.org/specializations/statistics\n",
            ", que\n",
            "trata muchos de estos temas.\n",
            "1\n",
            " \n",
            "https://es.wikipedia.org/wiki/Correcci%C3%B3n_por_continuidad\n",
            ".\n",
            "2\n",
            " \n",
            "https://www.nature.com/news/scientific-method-statistical-errors-1.14700\n",
            ".\n",
            "3\n",
            "https://www.iro.umontreal.ca/~dift3913/cours/papers/cohen1994_The_earth_is_round.pdf\n",
            "4\n",
            " \n",
            "https://www.johndcook.com/blog/conjugate_prior_diagram/\n",
            ".8\n",
            " Descenso de gradiente\n",
            "Los que presumen de su ascendencia se jactan de lo que deben a los demás.\n",
            "—Séneca\n",
            "Cuando estemos haciendo ciencia de datos, muchas veces intentaremos\n",
            "encontrar el mejor modelo para una determinada situación. Generalmente\n",
            "“mejor” quiere decir algo así como “minimiza el error de sus predicciones” o\n",
            "“maximiza la probabilidad de los datos”. En otras palabras, representará la\n",
            "solución a algún tipo de problema de optimización.\n",
            "Esto significa que tendremos que resolver unos cuantos problemas de\n",
            "optimización; en particular, tendremos que hacerlo desde el principio.\n",
            "Nuestro enfoque para ello será una técnica denominada descenso de\n",
            "gradiente, que se presta a la perfección a un tratamiento iniciado desde cero.\n",
            "Quizá no resulte superinteresante en sí mismo, pero sí nos permitirá hacer\n",
            "cosas apasionantes a lo largo del libro, así que les pido un poco de paciencia.\n",
            "La idea tras el descenso de gradiente\n",
            "Supongamos que tenemos una función \n",
            "f\n",
            " cuya entrada es un vector de\n",
            "números reales y cuya salida es un solo número real. Una función como esta\n",
            "sencilla es algo así:\n",
            "from scratch.linear_algebra import Vector, dot\n",
            "def sum_of_squares(v: Vector) -> float:\n",
            "\"\"\"Computes the sum of squared elements in v\"\"\"\n",
            "return dot(v, v)\n",
            "En muchas ocasiones, tendremos que maximizar o minimizar este tipo de\n",
            "funciones. Es decir, tendremos que encontrar la entrada \n",
            "v\n",
            " que produzca el\n",
            "mayor (o menor) valor posible.Para funciones como la nuestra, el gradiente (si se acuerda del cálculo que\n",
            "estudió en su día, es el vector de las derivadas parciales) proporciona la\n",
            "dirección de entrada en la que la función aumenta a mayor velocidad (si no se\n",
            "acuerda, créase lo que le digo, o busque en Internet).\n",
            "Según esto, un método para maximizar una función es elegir un punto de\n",
            "inicio aleatorio, calcular el gradiente, dar un pequeño paso en la dirección del\n",
            "gradiente (es decir, la dirección que hace que la función aumente al máximo)\n",
            "y repetir con el nuevo punto de inicio. De forma similar, se puede minimizar\n",
            "una función dando pequeños pasos en la dirección opuesta, como muestra la\n",
            "figura 8.1.\n",
            "Figura 8.1. \n",
            "Hallar un mínimo utilizando el descenso de gradiente.\n",
            "Nota:\n",
            " Si una función tiene un mínimo global único, es probable que este\n",
            "procedimiento lo encuentre. Si tiene varios mínimos (locales), quizá lo que el\n",
            "procedimiento “encuentre” sea el mínimo erróneo de todos ellos, en cuyo caso\n",
            "se podría volver a ejecutar desde distintos puntos de inicio. Si una función no\n",
            "tiene mínimo, entonces es posible que el procedimiento siga ejecutándose para\n",
            "siempre.Estimar el gradiente\n",
            "Si \n",
            "f\n",
            " es una función de una sola variable, su derivada en un punto \n",
            "x\n",
            " mide\n",
            "cómo cambia \n",
            "f(x)\n",
            " cuando le aplicamos un pequeño cambio a \n",
            "x\n",
            ". La derivada\n",
            "se define como el límite de los cocientes de diferencias:\n",
            "from typing import Callable\n",
            "def difference_quotient(f: Callable[[float], float],\n",
            "x: float,\n",
            "h: float) -> float:\n",
            "return (f(x + h)–f(x)) / h\n",
            "Cuando \n",
            "h\n",
            " se aproxima a cero.\n",
            "(Muchos aspirantes a estudiantes de cálculo se han visto obstaculizados\n",
            "por la definición matemática de límite, que es preciosa, pero puede resultar\n",
            "ciertamente intimidatoria. Aquí haremos trampas y simplemente diremos que\n",
            "“límite” significa lo que todos piensan que significa).\n",
            "La derivada es la pendiente de la tangente en (\n",
            "x\n",
            ", \n",
            "f\n",
            "(\n",
            "x\n",
            ")), mientras que el\n",
            "cociente de diferencias es la pendiente de la línea no tan tangente que cruza (\n",
            "x\n",
            "+ \n",
            "h\n",
            ", \n",
            "f\n",
            "(\n",
            "x\n",
            " + \n",
            "h\n",
            ")). A medida que \n",
            "h\n",
            " es más pequeño, la línea no tan tangente se\n",
            "acerca cada vez más a la línea tangente (figura 8.2).Figura 8.2. \n",
            "Aproximar una derivada con un cociente de diferencias.\n",
            "Para muchas funciones es fácil calcular las derivadas con exactitud. Por\n",
            "ejemplo, la función \n",
            "square\n",
            ":\n",
            "def square(x: float) -> float:\n",
            "return x * x\n",
            "Tiene la derivada:\n",
            "def derivative(x: float) -> float:\n",
            "return 2 * x\n",
            "Que nos resulta sencillo comprobar calculando de manera explícita el\n",
            "cociente de diferencias y tomando el límite (lo que no requiere nada más que\n",
            "un poco de álgebra de instituto).\n",
            "¿Qué pasa si no podemos (o no queremos) encontrar el gradiente? Aunque\n",
            "no podemos tomar límites en Python, podemos estimar derivadas evaluando\n",
            "el cociente de diferencias para un valor \n",
            "e\n",
            " muy pequeño. La figura 8.3 muestra\n",
            "los resultados de una estimación así:xs = range(-10, 11)\n",
            "actuals = [derivative(x) for x in xs]\n",
            "estimates = [difference_quotient(square, x, h=0.001) for x in xs]\n",
            "# se traza para mostrar que son básicamente lo mismo\n",
            "import matplotlib.pyplot as plt\n",
            "plt.title(\"Actual Derivatives vs. Estimates\")\n",
            "plt.plot(xs, actuals, ‘rx’, label=’Actual’)\n",
            "# rojo x\n",
            "plt.plot(xs, estimates, ‘b+’, label=’Estimate’)\n",
            "# azul +\n",
            "plt.legend(loc=9)\n",
            "plt.show()\n",
            "Cuando \n",
            "f\n",
            " es una función de muchas variables, tiene varias derivadas\n",
            "parciales, cada una de las cuales indica cómo cambia \n",
            "f\n",
            " cuando realizamos\n",
            "pequeñas modificaciones en tan solo una de las variables de entrada.\n",
            "Calculamos su \n",
            "i\n",
            " derivada parcial tratándola como una función solo de su \n",
            "i\n",
            "variable, manteniendo fijas el resto de variables:\n",
            "def partial_difference_quotient(f: Callable[[Vector], float],\n",
            "v: Vector,\n",
            "i: int,\n",
            "h: float) -> float:\n",
            "\"\"\"Returns the i-th partial difference quotient of f at v\"\"\"\n",
            "w = [v_j + (h if j == i else 0)\n",
            "# suma h al i elemento de v\n",
            "for j, v_j in enumerate(v)]\n",
            "return (f(w)–f(v)) / h\n",
            "Tras lo cual podemos estimar el gradiente del mismo modo:\n",
            "def estimate_gradient(f: Callable[[Vector], float],\n",
            "v: Vector,\n",
            "h: float = 0.0001):\n",
            "return [partial_difference_quotient(f, v, i, h)\n",
            "for i in range(len(v))]Figura 8.3. \n",
            "La bondad de la aproximación del cociente de diferencias.\n",
            "Nota:\n",
            " Un inconveniente a tener en cuenta de este método de “estimación\n",
            "mediante cocientes de diferencias” es que resulta caro desde el punto de vista\n",
            "computacional. Si \n",
            "v\n",
            " tiene una longitud \n",
            "n\n",
            ", \n",
            "estimate_gradient\n",
            " tiene que evaluar \n",
            "f\n",
            "en 2\n",
            "n\n",
            " entradas distintas. Si estamos estimando gradientes repetidamente,\n",
            "estaremos trabajando demasiado. En todo lo que hagamos, emplearemos las\n",
            "matemáticas para calcular nuestras funciones de gradiente de manera\n",
            "explícita.\n",
            "Utilizar el gradiente\n",
            "Es fácil darse cuenta de que la función \n",
            "sum_of_squares\n",
            " es menor cuando\n",
            "su entrada \n",
            "v\n",
            " es un vector de ceros. Pero imaginemos que no sabíamos eso.\n",
            "Utilicemos los gradientes para hallar el mínimo entre todos los vectores\n",
            "tridimensionales. Elegiremos simplemente un punto de inicio aleatorio y\n",
            "después daremos pequeños pasos en la dirección opuesta al gradiente hasta\n",
            "alcanzar un punto en el que el gradiente sea muy pequeño:import random\n",
            "from scratch.linear_algebra import distance, add, scalar_multiply\n",
            "def gradient_step(v: Vector, gradient: Vector, step_size: float) -> Vector:\n",
            "\"\"\"Moves \n",
            "'\n",
            "step_size\n",
            "'\n",
            " in the \n",
            "'\n",
            "gradient\n",
            "'\n",
            " direction from \n",
            "'\n",
            "v\n",
            "'\n",
            "\"\"\"\n",
            "assert len(v) == len(gradient)\n",
            "step = scalar_multiply(step_size, gradient)\n",
            "return add(v, step)\n",
            "def sum_of_squares_gradient(v: Vector) -> Vector:\n",
            "return [2 * v_i for v_i in v]\n",
            "# elige un punto de inicio aleatorio\n",
            "v = [random.uniform(-10, 10) for i in range(3)]\n",
            "for epoch in range(1000):\n",
            "grad = sum_of_squares_gradient(v)\n",
            "# calcula el gradiente en v\n",
            "v = gradient_step(v, grad, -0.01)\n",
            "# da un paso de gradiente negativo\n",
            "print(epoch, v)\n",
            "assert distance(v, [0, 0, 0]) < 0.001\n",
            "# v debería estar cerca de 0\n",
            "Si ejecutamos esto, veremos que siempre termina con un valor \n",
            "v\n",
            " muy\n",
            "próximo a \n",
            "[0,0,0]\n",
            ". Cuántas más veces se ejecute, más se acercará.\n",
            "Elegir el tamaño de paso adecuado\n",
            "Aunque los motivos para alejarnos del gradiente están claros, lo que no\n",
            "queda claro es lo lejos que queremos llegar. Sin duda, elegir el tamaño de\n",
            "paso correcto es más un arte que una ciencia. Entre las opciones más\n",
            "conocidas están las siguientes:\n",
            "■\n",
            "Utilizar un tamaño de paso fijo.\n",
            "■\n",
            "Ir encogiendo el tamaño de paso gradualmente con el tiempo.\n",
            "■\n",
            "En cada paso, elegir el tamaño de paso que minimice el valor de la\n",
            "función objetivo.\n",
            "El último método suena muy bien, pero, en la práctica, es un cálculo muy\n",
            "costoso. Para simplificar las cosas, utilizaremos la mayoría de las veces un\n",
            "tamaño de paso fijo. El tamaño de paso que “funcione” depende del\n",
            "problema: demasiado pequeño, y el descenso de gradiente se mantendrá para\n",
            "siempre; demasiado grande, y tendremos que dar pasos enormes que podríanlograr que la función que nos ocupa sea cada vez más grande o incluso que se\n",
            "quede sin definir. Por lo tanto, hay que experimentar.\n",
            "Utilizar descenso de gradiente para ajustar\n",
            "modelos\n",
            "En este libro, utilizaremos el descenso de gradiente para ajustar modelos\n",
            "paramétricos a los datos. Lo más habitual es que tengamos un conjunto de\n",
            "datos y un modelo (hipotético) para los datos que depende (de una forma\n",
            "diferenciada) de uno o más parámetros. También tendremos una función de\n",
            "pérdida que mide lo bien que se ajusta el modelo a nuestros datos (menor es\n",
            "mejor). Si pensamos que nuestros datos son fijos, entonces nuestra función de\n",
            "pérdida nos indica lo buenos o malos que son los parámetros de un modelo\n",
            "cualquiera. Esto significa que podemos utilizar el descenso de gradiente para\n",
            "encontrar los parámetros del modelo que minimicen al máximo la pérdida.\n",
            "Veamos un sencillo ejemplo:\n",
            "# x va de -50 a 49, y es siempre 20 * x + 5\n",
            "inputs = [(x, 20 * x + 5) for x in range(-50, 50)]\n",
            "En este caso, conocemos los parámetros de la relación lineal entre \n",
            "x\n",
            " e \n",
            "y\n",
            ",\n",
            "pero imaginemos que queremos descubrirlos a partir de los datos.\n",
            "Utilizaremos el descenso de gradiente para hallar la pendiente y la\n",
            "intersección que minimizan el error cuadrático medio.\n",
            "Empezaremos con una función que determina el gradiente basándose en el\n",
            "error a partir de un solo punto de datos:\n",
            "def linear_gradient(x: float, y: float, theta: Vector) -> Vector:\n",
            "slope, intercept = theta\n",
            "predicted = slope * x + intercept\n",
            "# La predicción del modelo.\n",
            "error = (predicted–y)\n",
            "# el error es (previsto–real).\n",
            "squared_error = error ** 2\n",
            "# Minimizaremos el error cuadrático\n",
            "grad = [2 * error * x, 2 * error]\n",
            "# usando su gradiente.\n",
            "return grad\n",
            "Pensemos en lo que significa el gradiente. Imaginemos que para un ciertox\n",
            " nuestra predicción es demasiado grande. En ese caso, el \n",
            "error\n",
            " es positivo.\n",
            "El segundo término de gradiente, \n",
            "2\n",
            " \n",
            "*\n",
            " \n",
            "error\n",
            ", es positivo, lo que refleja el\n",
            "hecho de que pequeños incrementos harán que la predicción (ya demasiado\n",
            "grande) sea aún más grande, lo que provocará que el error cuadrático (para\n",
            "este \n",
            "x\n",
            ") sea aún mayor.\n",
            "El primer término de gradiente, \n",
            "2\n",
            " \n",
            "*\n",
            " \n",
            "error\n",
            " \n",
            "*\n",
            " \n",
            "x\n",
            ", tiene el mismo signo que \n",
            "x\n",
            ".\n",
            "Por supuesto que, si \n",
            "x\n",
            " es positivo, los pequeños incrementos en la pendiente\n",
            "harán de nuevo que la predicción (y de ahí el error) sea más grande. Si \n",
            "x\n",
            " es\n",
            "negativo, sin embargo, esos pequeños incrementos harán que la predicción (y\n",
            "por lo tanto el error) sea más pequeña.\n",
            "Pero ese cálculo está hecho para un solo punto de datos. Para el conjunto\n",
            "completo miraremos el error cuadrático medio; el gradiente del error\n",
            "cuadrático medio no es más que la media de los gradientes individuales.\n",
            "Así, esto es lo que vamos a hacer:\n",
            "1\n",
            ".\n",
            "Empezar con un valor aleatorio para \n",
            "theta\n",
            ".\n",
            "2\n",
            ".\n",
            "Calcular la media de los gradientes.\n",
            "3\n",
            ".\n",
            "Ajustar \n",
            "theta\n",
            " en esa dirección.\n",
            "4\n",
            ".\n",
            "Repetir.\n",
            "Tras muchos \n",
            "epochs\n",
            " (como llamamos a cada pasada por el conjunto de\n",
            "datos), descubriríamos algo parecido a los parámetros correctos:\n",
            "from scratch.linear_algebra import vector_mean\n",
            "# Empieza con valores aleatorios para pendiente e intersección\n",
            "theta = [random.uniform(-1, 1), random.uniform(-1, 1)]\n",
            "learning_rate = 0.001\n",
            "for epoch in range(5000):\n",
            "# Calcula la media de los gradientes\n",
            "grad = vector_mean([linear_gradient(x, y, theta) for x, y in inputs])\n",
            "# Da un paso en esa dirección\n",
            "theta = gradient_step(theta, grad, -learning_rate)\n",
            "print(epoch, theta)\n",
            "slope, intercept = theta\n",
            "assert 19.9 < slope < 20.1, \"slope should be about 20\"\n",
            "assert 4.9 < intercept < 5.1, \"intercept should be about 5\"Descenso de gradiente en minilotes y estocástico\n",
            "Un inconveniente del método anterior es que hemos tenido que evaluar los\n",
            "gradientes en el conjunto de datos entero antes de poder dar un paso de\n",
            "gradiente y actualizar nuestros parámetros. En este caso estaba bien, porque\n",
            "nuestro conjunto de datos contenía solamente 100 pares y el cálculo del\n",
            "gradiente resultó barato.\n",
            "Pero otros modelos tendrán con frecuencia grandes conjuntos de datos y\n",
            "caros cálculos de gradientes. En ese caso, nos interesará dar pasos de\n",
            "gradiente más a menudo.\n",
            "Podemos hacerlo utilizando una técnica denominada descenso de\n",
            "gradiente en minilotes (o \n",
            "minibatch\n",
            "), en la que calculamos el gradiente (y\n",
            "damos un paso de gradiente) basándonos en un “minilote” muestreado del\n",
            "conjunto de datos principal:\n",
            "from typing import TypeVar, List, Iterator\n",
            "T = TypeVar(‘T’)\n",
            "# nos permite escribir funciones\n",
            "\"genéricas\"\n",
            "def minibatches(dataset: List[T],\n",
            "batch_size: int,\n",
            "shuffle: bool = True) -> Iterator[List[T]]:\n",
            "\"\"\"Generates \n",
            "'\n",
            "batch_size\n",
            "'\n",
            "-sized minibatches from the dataset\"\"\"\n",
            "# inicia índices 0, batch_size, 2 * batch_size, ...\n",
            "batch_starts = [start for start in range(0, len(dataset), batch_size)]\n",
            "if shuffle:\n",
            "random.shuffle(batch_starts)\n",
            "# mezcla los lotes\n",
            "for start in batch_starts:\n",
            "end = start + batch_size\n",
            "yield dataset[start:end]\n",
            "Nota:\n",
            " \n",
            "TypeVar\n",
            " \n",
            "(T)\n",
            " nos permite crear una función “genérica”, que dice que\n",
            "nuestro conjunto de datos puede ser una lista de cualquier tipo sencillo (\n",
            "str\n",
            ",\n",
            "int\n",
            ", \n",
            "list\n",
            ", lo que sea), pero, sea cual sea el tipo, los resultados serán lotes de\n",
            "él.\n",
            "Podemos resolver nuestro problema de nuevo utilizando minilotes:\n",
            "theta = [random.uniform(-1, 1), random.uniform(-1, 1)]for epoch in range(1000):\n",
            "for batch in minibatches(inputs, batch_size=20):\n",
            "grad = vector_mean([linear_gradient(x, y, theta) for x, y in batch])\n",
            "theta = gradient_step(theta, grad, -learning_rate)\n",
            "print(epoch, theta)\n",
            "slope, intercept = theta\n",
            "assert 19.9 < slope < 20.1, \"slope should be about 20\"\n",
            "assert 4.9 < intercept < 5.1, \"intercept should be about 5\"\n",
            "Otra variante es el descenso de gradiente estocástico, en el que se dan\n",
            "pasos de gradiente basados en un ejemplo de entrenamiento cada vez:\n",
            "theta = [random.uniform(-1, 1), random.uniform(-1, 1)]\n",
            "for epoch in range(100):\n",
            "for x, y in inputs:\n",
            "grad = linear_gradient(x, y, theta)\n",
            "theta = gradient_step(theta, grad, -learning_rate)\n",
            "print(epoch, theta)\n",
            "slope, intercept = theta\n",
            "assert 19.9 < slope < 20.1, \"slope should be about 20\"\n",
            "assert 4.9 < intercept < 5.1, “intercept should be about 5”\n",
            "En este problema, el descenso de gradiente estocástico encuentra los\n",
            "parámetros óptimos en un número de \n",
            "epochs\n",
            " mucho menor. Pero siempre hay\n",
            "inconvenientes. Basar los pasos de gradiente en pequeños minilotes (o en\n",
            "puntos de datos sencillos) permite dar más pasos, pero el gradiente para un\n",
            "solo punto podría residir en una dirección muy distinta a la del gradiente para\n",
            "el conjunto completo de datos.\n",
            "Además, si no estuviéramos creando nuestra álgebra lineal desde cero, se\n",
            "producirían mejoras en el rendimiento por “vectorizar” nuestros cálculos a lo\n",
            "largo de lotes en lugar de calcular el gradiente un punto cada vez.\n",
            "A lo largo del libro, jugaremos a buscar y encontrar tamaños de lote y de\n",
            "paso óptimos.\n",
            "Nota:\n",
            " La terminología para los distintos tipos de descensos de gradiente no es\n",
            "uniforme. El método “calcular el gradiente para el conjunto de datos completo”\n",
            "se suele denominar descenso de gradiente en lotes, y algunas personas dicen\n",
            "descenso de gradiente estocástico cuando se quieren referir a la versión de\n",
            "minilotes (cuya versión “un punto cada vez” es un caso especial).Para saber más\n",
            "■\n",
            "¡Siga leyendo! Utilizaremos el descenso de gradiente para resolver\n",
            "problemas en el resto del libro.\n",
            "■\n",
            "A estas alturas, es casi seguro que ya se ha hartado de leerme\n",
            "recomendándole que lea libros de texto. Si le sirve de consuelo, \n",
            "Active\n",
            "Calculus 1.0\n",
            ", en \n",
            "https://scholarworks.gvsu.edu/books/10/\n",
            ", de\n",
            "Matthew Boelkins, David Austin y Steven Schlicker (Bibliotecas de la\n",
            "Universidad Estatal de Grand Valley), parece más interesante que los\n",
            "libros de texto con los que yo aprendí.\n",
            "■\n",
            "Sebastian Ruder tiene una entrada épica en su blog, en\n",
            "http://ruder.io/optimizing-gradient-descent/index.html\n",
            ",\n",
            "comparando el descenso de gradiente y sus distintas variantes.9\n",
            " Obtener datos\n",
            "Para escribirlo, necesité tres meses; para concebirlo, tres minutos; para recoger los\n",
            "datos contenidos en él, toda mi vida.\n",
            "—F. Scott Fitzgerald\n",
            "Para ser científico de datos se necesitan datos. De hecho, como científico\n",
            "de datos se pasará una fracción indecorosamente grande de su tiempo\n",
            "adquiriendo, limpiando y transformando datos. Si no hay más remedio, puede\n",
            "escribirlos usted mismo (o si tiene minions a su disposición, mejor que lo\n",
            "hagan ellos), pero este no es un buen uso de su tiempo. En este capítulo,\n",
            "veremos distintas formas de obtener datos en Python y en los formatos\n",
            "adecuados.\n",
            "stdin y stdout\n",
            "Si ejecutamos nuestros \n",
            "scripts\n",
            " de Python en la línea de comandos, se\n",
            "pueden canalizar los datos a través de ellos utilizando \n",
            "sys.stdin\n",
            " y\n",
            "sys.stdout\n",
            ". Por ejemplo, esta es una secuencia de comandos que lee líneas\n",
            "de texto y devuelve las que coinciden con una expresión regular:\n",
            "# egrep.py\n",
            "import sys, re\n",
            "# sys.argv es la lista de argumentos de línea de comandos\n",
            "# sys.argv[0] es el nombre del propio programa\n",
            "# sys.argv[1] será el regex especificado en la línea de comandos\n",
            "regex = sys.argv[1]\n",
            "# por cada línea pasada al script\n",
            "for line in sys.stdin:\n",
            "# si coincide con el regex, lo graba en stdout\n",
            "if re.search(regex, line):\n",
            "sys.stdout.write(line)Y aquí tenemos un fragmento de código que cuenta las líneas que recibe y\n",
            "devuelve el total:\n",
            "# line_count.py\n",
            "import sys\n",
            "count = 0\n",
            "for line in sys.stdin:\n",
            "count += 1\n",
            "# print va a sys.stdout\n",
            "print(count)\n",
            "Podríamos entonces utilizar estos \n",
            "scripts\n",
            " para contar cuántas líneas de un\n",
            "archivo contienen números. En Windows emplearíamos:\n",
            "type SomeFile.txt | python egrep.py “[0-9]” | python line_count.py\n",
            "Mientras que en un sistema Unix se transformaría en:\n",
            "cat SomeFile.txt | python egrep.py “[0-9]” | python line_count.py\n",
            "El carácter | (barra vertical) es el denominado \n",
            "pipe\n",
            ", que significa “utilizar\n",
            "la salida del comando izquierdo como entrada del comando derecho”. De este\n",
            "modo se pueden construir \n",
            "pipelines\n",
            " (o tuberías) de proceso de datos.\n",
            "Nota:\n",
            " Si utilizamos Windows, es probable que podamos omitir la parte de\n",
            "Python de este comando:\n",
            "type SomeFile.txt | egrep.py “[0-9]” | line_count.py\n",
            "Si trabajamos en un sistema Unix, hacer esto mismo requiere un par de pasos\n",
            "adicionales.\n",
            "1\n",
            " Primero, añadimos un “shebang” como primera línea del \n",
            "script\n",
            "#!/usr/bin/env\n",
            " \n",
            "python\n",
            ". Después, en la línea de comandos, utilizamos \n",
            "chmod\n",
            " x\n",
            "egrep.py++ para convertir el archivo en ejecutable.\n",
            "De forma similar, este es un \n",
            "script\n",
            " que cuenta las palabras de su entrada y\n",
            "devuelve las más comunes:\n",
            "# most_common_words.py\n",
            "import sys\n",
            "from collections import Counter\n",
            "# pasa el número de palabras como primer argumentotry:\n",
            "num_words = int(sys.argv[1])\n",
            "except:\n",
            "print(\"usage: most_common_words.py num_words\")\n",
            "sys.exit(1)\n",
            "# un código de salida no cero indica\n",
            "error\n",
            "counter = Counter(word.lower()\n",
            "# palabras en minúscula\n",
            "for line in sys.stdin\n",
            "for word in\n",
            "line.strip().split()\n",
            "# divide por espacios\n",
            "if word)\n",
            "# salta las ‘palabras’ vacías\n",
            "for word, count in counter.most_common(num_words):\n",
            "sys.stdout.write(str(count))\n",
            "sys.stdout.write(\"\\t\")\n",
            "sys.stdout.write(word)\n",
            "sys.stdout.write(\"\\n\")\n",
            "Después de esto, se podría hacer algo así:\n",
            "$ cat the_bible.txt | python most_common_words.py 10\n",
            "36397\n",
            "the\n",
            "30031\n",
            "and\n",
            "20163\n",
            "of\n",
            "7154\n",
            "to\n",
            "6484\n",
            "in\n",
            "5856\n",
            "that\n",
            "5421\n",
            "he\n",
            "5226\n",
            "his\n",
            "5060\n",
            "unto\n",
            "4297\n",
            "shall\n",
            "(Si utiliza Windows, emplee \n",
            "type\n",
            " en lugar de \n",
            "cat\n",
            ").\n",
            "Nota:\n",
            " Si es un experto programador de Unix, probablemente estará\n",
            "familiarizado con una gran variedad de herramientas de línea de comandos\n",
            "(por ejemplo, \n",
            "egrep\n",
            "), integradas en el sistema operativo, que es preferible crear\n",
            "desde cero. Aun así, es bueno saber que puede si lo necesita.\n",
            "Leer archivosTambién es posible leer archivos y escribir en ellos de forma explícita\n",
            "directamente en el código. Python simplifica bastante el trabajo con archivos.\n",
            "Conocimientos básicos de los archivos de texto\n",
            "El primer paso para trabajar con un archivo de texto es obtener un objeto\n",
            "archivo utilizando \n",
            "open\n",
            ":\n",
            "# ‘r’ significa solo lectura, se da por sentado si se omite\n",
            "file_for_reading = open(‘reading_file.txt’, ‘r’)\n",
            "file_for_reading2 = open(‘reading_file.txt’)\n",
            "# ‘w’ es escribir — ¡destruirá el archivo si ya existe!\n",
            "file_for_writing = open(‘writing_file.txt’, ‘w’)\n",
            "# ‘a’ es añadir – para añadir al final del archivo\n",
            "file_for_appending = open(‘appending_file.txt’, ‘a’)\n",
            "# no olvide cerrar sus archivos al terminar\n",
            "file_for_writing.close()\n",
            "Como es fácil olvidarse de cerrar los archivos, siempre se deben utilizar\n",
            "con un bloque \n",
            "with\n",
            ", al final del cual se cerrarán automáticamente:\n",
            "with open(filename) as f:\n",
            "data = function_that_gets_data_from(f)\n",
            "# en este momento f ya se ha cerrado, así que no trate de usarlo\n",
            "process(data)\n",
            "Si hace falta leer un archivo de texto completo, basta simplemente con\n",
            "pasar varias veces por las líneas del archivo utilizando \n",
            "for\n",
            ":\n",
            "starts_with_hash = 0\n",
            "with open(‘input.txt’) as f:\n",
            "for line in f:\n",
            "# mira cada línea del archivo\n",
            "if re.match(\"^#\",line):\n",
            "# usa un regex para ver si empieza por ‘#’\n",
            "starts_with_hash += 1\n",
            "# si es así, suma 1 al total\n",
            "Todas las líneas obtenidas así terminan en un carácter de línea nueva, así\n",
            "que con frecuencia nos interesará limpiarlas con un \n",
            "strip\n",
            " antes de hacer\n",
            "nada con ellas.Por ejemplo, imaginemos que tenemos un archivo lleno de direcciones de\n",
            "correo electrónico, una por línea, y necesitamos generar un histograma de los\n",
            "dominios. Las reglas para extraer dominios correctamente son algo sutiles\n",
            "(vea, por ejemplo, la lista de sufijos públicos \n",
            "https://publicsuffix.org\n",
            "),\n",
            "pero una buena primera aproximación es coger las partes de las direcciones\n",
            "de correo que vienen después del @ (lo que da la respuesta equivocada con\n",
            "direcciones como \n",
            "joel@mail.datasciencester.com\n",
            ", pero solo para este ejemplo\n",
            "estamos dispuestos a vivir con ello):\n",
            "def get_domain(email_address: str) -> str:\n",
            "\"\"\"Split on ‘@’ and return the last piece\"\"\"\n",
            "return email_address.lower().split(\"@\")[-1]\n",
            "# un par de pruebas\n",
            "assert \n",
            "get_domain(‘joelgrus@gmail.com\n",
            "’) == ‘\n",
            "gmail.com\n",
            "’\n",
            "assert get_domain(‘joel@m.datasciencester.com’) == ‘\n",
            "m.datasciencester.com\n",
            "’\n",
            "from collections import Counter\n",
            "with open(‘email_addresses.txt’, ‘r’) as f:\n",
            "domain_counts = Counter(get_domain(line.strip())\n",
            "for line in f\n",
            "if \"@\" in line)\n",
            "Archivos delimitados\n",
            "Las direcciones de correo electrónico hipotéticas que acabamos de\n",
            "procesar solo tenían una dirección por línea. Lo más habitual es que los\n",
            "archivos tengan muchos datos en cada línea. Estos archivos suelen estar\n",
            "separados (o delimitados) por comas o tabuladores: cada línea tiene varios\n",
            "campos, con una coma o un tabulador indicando el lugar en el que termina un\n",
            "campo y empieza el siguiente.\n",
            "Esto empieza a complicarse cuando se tienen campos que incluyen comas,\n",
            "tabuladores y líneas nuevas (algo que ocurrirá forzosamente). Por esta razón,\n",
            "no conviene nunca intentar analizarlos uno mismo. Es mejor utilizar el\n",
            "módulo \n",
            "csv\n",
            " de Python (o la librería pandas, o cualquier otra diseñada para\n",
            "leer archivos delimitados por comas o tabuladores).Advertencia:\n",
            " ¡Nunca analice usted solo un archivo delimitado por comas! ¡Se\n",
            "cargará los casos límite!\n",
            "Si el archivo no tiene encabezados (lo que significa que probablemente\n",
            "nos interese cada fila como una \n",
            "list\n",
            ", y lo que además nos obliga a saber lo\n",
            "que hay en cada columna), se puede utilizar \n",
            "csv.reader\n",
            " para pasar varias\n",
            "veces por las filas, cada una de las cuales será una lista adecuadamente\n",
            "dividida.\n",
            "Si tuviéramos por ejemplo un archivo delimitado por tabuladores de\n",
            "precios de acciones:\n",
            "6/20/2014\n",
            "AAPL\n",
            "90.91\n",
            "6/20/2014\n",
            "MSFT\n",
            "41.68\n",
            "6/20/2014\n",
            "FB\n",
            "64.5\n",
            "6/19/2014\n",
            "AAPL\n",
            "91.86\n",
            "6/19/2014\n",
            "MSFT\n",
            "41.51\n",
            "6/19/2014\n",
            "FB\n",
            "64.34\n",
            "Podríamos procesar las líneas con:\n",
            "import csv\n",
            "with open(‘tab_delimited_stock_prices.txt’) as f:\n",
            "tab_reader = csv.reader(f, delimiter=’\\t’)\n",
            "for row in tab_reader:\n",
            "date = row[0]\n",
            "symbol = row[1]\n",
            "closing_price = float(row[2])\n",
            "process(date, symbol, closing_price)\n",
            "Si el archivo tiene encabezados:\n",
            "date:symbol:closing_price\n",
            "6/20/2014:AAPL:90.91\n",
            "6/20/2014:MSFT:41.68\n",
            "6/20/2014:FB:64.5\n",
            "Se puede omitir la fila del encabezado con una llamada inicial a\n",
            "reader.next\n",
            ", o bien obtener cada fila como un \n",
            "dict\n",
            " (con los encabezados\n",
            "como claves) utilizando \n",
            "csv.DictReader\n",
            ":with open(‘colon_delimited_stock_prices.txt’) as f:\n",
            "colon_reader = csv.DictReader(f, delimiter=’:’)\n",
            "for dict_row in colon_reader:\n",
            "date = dict_row[\"date\"]\n",
            "symbol = dict_row[\"symbol\"]\n",
            "closing_price = float(dict_row[\"closing_price\"])\n",
            "process(date, symbol, closing_price)\n",
            "Aunque el archivo no tuviera encabezados, aún podríamos utilizar\n",
            "DictReader\n",
            " pasándole las claves como un parámetro \n",
            "fieldnames\n",
            ".\n",
            "También se pueden escribir datos delimitados utilizando \n",
            "csv.writer\n",
            ":\n",
            "todays_prices = {‘AAPL’: 90.91, ‘MSFT’: 41.68, ‘FB’: 64.5 }\n",
            "with open(‘comma_delimited_stock_prices.txt’, ‘w’) as f:\n",
            "csv_writer = csv.writer(f, delimiter=’,’)\n",
            "for stock, price in todays_prices.items():\n",
            "csv_writer.writerow([stock, price])\n",
            "csv.writer\n",
            " hará lo correcto si los campos contienen comas. Escribirlos a\n",
            "mano probablemente no servirá. Por ejemplo, si intentamos lo siguiente:\n",
            "results = [[\"test1\", \"success\", \"Monday\"],\n",
            "[\"test2\", \"success, kind of\", \"Tuesday\"],\n",
            "[\"test3\", \"failure, kind of\", \"Wednesday\"],\n",
            "[\"test4\", \"failure, utter\", \"Thursday\"]]\n",
            "# ¡no haga esto!\n",
            "with open(‘bad_csv.txt’, ‘w’) as f:\n",
            "for row in results:\n",
            "f.write(\",\".join(map(str,\n",
            "row)))\n",
            "# ¡podría contener demasiadas comas!\n",
            "f.write(\"\\n\")\n",
            "# ¡la fila podría tener líneas\n",
            "nuevas!\n",
            "Terminará con un archivo \n",
            ".csv\n",
            " parecido a esto:\n",
            "test1,success,Monday\n",
            "test2,success, kind of,Tuesday\n",
            "test3,failure, kind of,Wednesday\n",
            "test4,failure, utter,Thursday\n",
            "Al que nadie podrá dar sentido.Raspado web\n",
            "Otra forma de conseguir datos es extrayéndolos de páginas web mediante\n",
            "el método del raspado web (\n",
            "web scraping\n",
            "). Parece que conseguir páginas\n",
            "web es bastante fácil; otra cosa es obtener de ellas información estructurada\n",
            "con sentido.\n",
            "HTML y su análisis\n",
            "Las páginas de la web están escritas en HTML, donde el texto\n",
            "(preferiblemente) se marca con elementos y sus atributos:\n",
            "<html>\n",
            "<head>\n",
            "<title>Una página web</title>\n",
            "</head>\n",
            "<body>\n",
            "<p id=\"author\">Joel Grus</p>\n",
            "<p id=\"subject\">Ciencia de datos</p>\n",
            "</body>\n",
            "</html>\n",
            "En un mundo perfecto, en el que todas las páginas web estuvieran\n",
            "marcadas semánticamente para nuestro beneficio, podríamos extraer datos\n",
            "utilizando reglas como “encuentra el elemento \n",
            "<p>\n",
            " cuyo \n",
            "id\n",
            " es \n",
            "subject\n",
            " y\n",
            "devuelve el texto que contiene”. Pero, en la realidad, HTML no suele estar\n",
            "bien formado, y no digamos bien comentado. Esto significa que\n",
            "necesitaremos ayuda para darle sentido.\n",
            "Para extraer datos de HTML, utilizaremos la librería Beautiful Soup,\n",
            "2\n",
            " que\n",
            "construye un árbol con los distintos elementos de una página web y ofrece\n",
            "una sencilla interfaz para acceder a ellos. La última versión en el momento de\n",
            "escribir este libro es Beautiful Soup 4.6.0, que es la que utilizaremos.\n",
            "También vamos a emplear la librería Requests,\n",
            "3\n",
            " una forma mucho más\n",
            "interesante de hacer peticiones HTTP que nada que esté integrado en Python.\n",
            "El analizador de HTML integrado en Python no es tan tolerante, es decir,\n",
            "que no siempre se lleva bien con código HTML que no esté perfectamenteformado. Por esa razón, instalaremos además el analizador \n",
            "html5lib\n",
            ".\n",
            "Asegurándonos de estar en el entorno virtual correcto, instalamos las\n",
            "librerías:\n",
            "python -m pip install beautifulsoup4 requests html5lib\n",
            "Para utilizar Beautiful Soup, pasamos una cadena de texto que contiene\n",
            "HTML a la función \n",
            "BeautifulSoup\n",
            ". En nuestros ejemplos, este será el\n",
            "resultado de una llamada a \n",
            "requests.get\n",
            ":\n",
            "from bs4 import BeautifulSoup\n",
            "import requests\n",
            "# Pongo el archivo HTML en GitHub. Para encajar\n",
            "# la URL en el libro tuve que dividirla en dos líneas.\n",
            "# Recuerde que las cadenas de texto whitespace-separated se concatenan.\n",
            "url = (\"https://raw.githubusercontent.com/\"\n",
            "\"joelgrus/data/master/getting-data.html\")\n",
            "html = requests.get(url).text\n",
            "soup = BeautifulSoup(html, ‘html5lib’)\n",
            "Tras de lo cual podemos llegar bastante lejos utilizando unos cuantos\n",
            "métodos sencillos.\n",
            "Normalmente trabajaremos con objetos \n",
            "Tag\n",
            ", que corresponden a las\n",
            "etiquetas que representan la estructura de una página HTML.\n",
            "Por ejemplo, para encontrar la primera etiqueta \n",
            "<p>\n",
            " (y su contenido), se\n",
            "puede utilizar:\n",
            "first_paragraph = soup.find(‘p’)\n",
            "# o simplemente soup.p\n",
            "Se puede obtener el contenido de texto de una \n",
            "Tag\n",
            " utilizando su propiedad\n",
            "text\n",
            ":\n",
            "first_paragraph_text = soup.p.text\n",
            "first_paragraph_words = soup.p.text.split()\n",
            "Y se pueden extraer los atributos de una etiqueta tratándola como un \n",
            "dict\n",
            ":\n",
            "first_paragraph_id = soup.p[‘id’]\n",
            "# da un KeyError si no hay ‘id’\n",
            "first_paragraph_id2 = soup.p.get(‘id’)\n",
            "# devuelve None si no hay ‘id’Se pueden conseguir varias etiquetas al mismo tiempo del siguiente modo:\n",
            "all_paragraphs = soup.find_all(‘p’)\n",
            "# o simplemente soup(‘p’)\n",
            "paragraphs_with_ids = [p for p in soup(‘p’) if p.get(‘id’)]\n",
            "Con frecuencia nos vendrá bien encontrar etiquetas con una determinada\n",
            "class\n",
            ":\n",
            "important_paragraphs = soup(‘p’, {‘class’ : ‘important’})\n",
            "important_paragraphs2 = soup(‘p’, ‘important’)\n",
            "important_paragraphs3 = [p for p in soup(‘p’)\n",
            "if ‘important’ in p.get(‘class’, [])]\n",
            "Y también es posible combinar estos métodos para implementar una\n",
            "lógica más elaborada. Por ejemplo, si queremos encontrar todos los\n",
            "elementos \n",
            "<span>\n",
            " contenidos dentro de un elemento \n",
            "<div>\n",
            ", podríamos hacer\n",
            "lo siguiente:\n",
            "# Atención: devolverá el mismo <span> varias veces\n",
            "# si está dentro de varios <div>s.\n",
            "# Sea más listo si ocurre esto.\n",
            "spans_inside_divs = [span\n",
            "for div in soup(‘div’)\n",
            "# por cada <div> de la página\n",
            "for span in div(‘span’)]\n",
            "# halla los <span> contenidos\n",
            "Solo este montón de funciones ya nos permitirá hacer bastante. Si\n",
            "finalmente hay que hacer cosas más complicadas (o simplemente si tiene\n",
            "curiosidad), eche un vistazo a la documentación que encontrará en\n",
            "https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
            ".\n",
            "Sin duda alguna, los datos importantes no van a estar etiquetados, claro\n",
            "está, como \n",
            "class=”important”\n",
            ". Será necesario inspeccionar con detalle el\n",
            "código fuente HTML, razonar sobre la lógica de selección y preocuparse de\n",
            "los casos límite para estar seguros de que los datos son correctos. Veamos un\n",
            "ejemplo.\n",
            "Ejemplo: Controlar el congresoEl vicepresidente de Política de DataSciencester está preocupado por las\n",
            "posibles regulaciones del sector de la ciencia de datos y le pide que\n",
            "cuantifique lo que dice el Congreso de los Estados Unidos sobre el tema. En\n",
            "especial quiere que encuentre a todos los representantes que tengan notas de\n",
            "prensa sobre “datos”.\n",
            "En el momento de la publicación de este libro, existe la página\n",
            "https://www.house.gov/representatives\n",
            " con enlaces a los sitios web de\n",
            "todos los representantes.\n",
            "Si visualizamos el código, todos los enlaces tienen este aspecto:\n",
            "<td>\n",
            "<a href=\"https://jayapal.house.gov\">Jayapal, Pramila</a>\n",
            "</td>\n",
            "Empecemos recopilando todas las URL a las que se enlaza desde esa\n",
            "página:\n",
            "from bs4 import BeautifulSoup\n",
            "import requests\n",
            "url = \"https://www.house.gov/representatives\"\n",
            "text = requests.get(url).text\n",
            "soup = BeautifulSoup(text, \"html5lib\")\n",
            "all_urls = [a[‘href’]\n",
            "for a in soup(‘a’)\n",
            "if a.has_attr(‘href’)]\n",
            "print(len(all_urls))\n",
            "# 965 para mí, demasiadas\n",
            "Esto devuelve demasiadas URL. Si les echamos un vistazo, las que\n",
            "queremos empiezan con \n",
            "http://\n",
            " o \n",
            "https://\n",
            ", tienen después algún nombre y\n",
            "terminan con \n",
            ".house.gov\n",
            " o \n",
            ".house.gov/\n",
            ".\n",
            "Es un buen momento para utilizar una expresión regular:\n",
            "import re\n",
            "# Debe empezar con http:// o https://\n",
            "# Debe terminar con .house.gov o .house.gov/\n",
            "regex = r\"^https?://.*\\.house\\.gov/?$\"\n",
            "# ¡Escribamos algunas pruebas!\n",
            "assert re.match(regex, \"http://joel.house.gov\")\n",
            "assert re.match(regex, \"https://joel.house.gov\")assert re.match(regex, \"http://joel.house.gov/\")\n",
            "assert re.match(regex, \"https://joel.house.gov/\")\n",
            "assert not re.match(regex, \"joel.house.gov\")\n",
            "assert not re.match(regex, \"http://joel.house.com\")\n",
            "assert not re.match(regex, \"https://joel.house.gov/biography\")\n",
            "# Ahora aplicamos\n",
            "good_urls = [url for url in all_urls if re.match(regex, url)]\n",
            "print(len(good_urls))\n",
            "# aun 862 para mi\n",
            "Siguen siendo demasiados, ya que solamente hay 435 representantes. Si\n",
            "miramos la lista, hay muchos duplicados. Utilicemos \n",
            "set\n",
            " para deshacernos de\n",
            "ellos:\n",
            "good_urls = list(set(good_urls))\n",
            "print(len(good_urls))\n",
            "# solo 431 para mi\n",
            "Siempre hay un par de escaños libres en la cámara, o quizá haya algún\n",
            "representante sin sitio web. En cualquier caso, con esto es suficiente. Al\n",
            "revisar los sitios, vemos que la mayoría de ellos tienen un enlace a notas de\n",
            "prensa. Por ejemplo:\n",
            "html = requests.get(‘https://jayapal.house.gov’).text\n",
            "soup = BeautifulSoup(html, ‘html5lib’)\n",
            "# Usa un conjunto porque los enlaces podrían aparecer varias veces.\n",
            "links = {a[‘href’] for a in soup(‘a’) if ‘press releases’ in a.text.lower()}\n",
            "print(links)\n",
            "# {‘/media/press-releases’}\n",
            "Hay que tener en cuenta que es un enlace relativo, es decir, tenemos que\n",
            "recordar el sitio del que se originó. Hagamos un poco de raspado:\n",
            "from typing import Dict, Set\n",
            "press_releases: Dict[str, Set[str]] = {}\n",
            "for house_url in good_urls:\n",
            "html = requests.get(house_url).text\n",
            "soup = BeautifulSoup(html, ‘html5lib’)\n",
            "pr_links = {a[‘href’] for a in soup(‘a’) if ‘press releases’\n",
            "in a.text.lower()}\n",
            "print(f\"{house_url}: {pr_links}\")\n",
            "press_releases[house_url] = pr_linksNota:\n",
            " Normalmente, no es muy correcto raspar un sitio libremente de esta\n",
            "forma. La mayoría de los sitios web tienen un archivo \n",
            "robots.txt\n",
            " que indica la\n",
            "frecuencia con la que se pueden extraer datos del sitio (y las rutas en las que\n",
            "se supone que no se debe hacer), pero, como es el Congreso, no hace falta\n",
            "que seamos especialmente educados.\n",
            "Si los observamos según van apareciendo, veremos muchos\n",
            "/media/press-releases\n",
            " y \n",
            "media-center/press-releases\n",
            ", además de otras\n",
            "direcciones varias. Una de estas URL es\n",
            "https://jayapal.house.gov/media/press-releases\n",
            ".\n",
            "Conviene recordar que nuestro objetivo es averiguar qué congresistas\n",
            "tienen notas de prensa que contienen “datos” (\n",
            "data\n",
            " en inglés). Escribiremos\n",
            "una función algo más general que verifique si una página de notas de prensa\n",
            "menciona un determinado término.\n",
            "Visitando el sitio y revisando el código fuente, parece que haya un\n",
            "fragmento de cada nota de prensa dentro de una etiqueta \n",
            "<p>\n",
            ", de modo que\n",
            "utilizaremos esto como primer intento:\n",
            "def paragraph_mentions(text: str, keyword: str) -> bool:\n",
            "\"\"\"\n",
            "Returns True if a <p> inside the text mentions {keyword}\n",
            "\"\"\"\n",
            "soup = BeautifulSoup(text, ‘html5lib’)\n",
            "paragraphs = [p.get_text() for p in soup(‘p’)]\n",
            "return any(keyword.lower() in paragraph.lower()\n",
            "for paragraph in paragraphs)\n",
            "Preparemos una prueba rápida de esto:\n",
            "text = \"\"\"<body><h1>Facebook</h1><p>Twitter</p>\"\"\"\n",
            "assert paragraph_mentions(text, \"twitter\")\n",
            "# está dentro de una <p>\n",
            "assert not paragraph_mentions(text, \"facebook\")\n",
            "# no está dentro de una <p>\n",
            "Finalmente, estamos listos para encontrar a los congresistas que\n",
            "buscábamos y dar sus nombres al vicepresidente:\n",
            "for house_url, pr_links in press_releases.items():\n",
            "for pr_link in pr_links:url = f\"{house_url}/{pr_link}\"\n",
            "text = requests.get(url).text\n",
            "if paragraph_mentions(text, ‘data’):\n",
            "print(f\"{house_url}\")\n",
            "break\n",
            "# lista esta house_url\n",
            "Al ejecutar este fragmento de código obtenemos una lista de 20\n",
            "representantes. Probablemente otra persona obtenga un resultado distinto.\n",
            "Nota:\n",
            " Si revisamos las distintas páginas de “notas de prensa” (\n",
            "press releases\n",
            "en inglés), la mayoría están paginadas solo con 5 o 10 notas de prensa por\n",
            "página. Esto significa que solamente hemos recuperado las notas de prensa\n",
            "más recientes para cada congresista. Una solución más meticulosa habría\n",
            "pasado varias veces por las páginas y recuperado el texto completo de cada\n",
            "nota de prensa.\n",
            "Utilizar API\n",
            "Muchos sitios y servicios web ofrecen interfaces de programación de\n",
            "aplicaciones o API (\n",
            "Application Programming Interfaces\n",
            "), que permiten\n",
            "solicitar de manera explícita datos en un formato estructurado (¡lo que nos\n",
            "ahorra el problema de tener que rasparlos!).\n",
            "JSON y XML\n",
            "Como HTTP es un protocolo para transferir texto, los datos que se\n",
            "soliciten a través de una API web se tienen que serializar en un formato de\n",
            "cadena de texto. Con frecuencia esta serialización emplea la notación de\n",
            "objeto de JavaScript o JSON (\n",
            "JavaScript Object Notation\n",
            "). Los objetos de\n",
            "JavaScript son bastante parecidos a las clases \n",
            "dict\n",
            " de Python, lo que facilita\n",
            "la interpretación de sus representaciones de texto:\n",
            "{ \"title\" : \"Data Science Book\",\n",
            "\"author\" : \"Joel Grus\",\n",
            "\"publicationYear\" : 2019,\"topics\" : [ \"data\", \"science\", \"data science\"] }\n",
            "Podemos analizar JSON utilizando el módulo \n",
            "json\n",
            " de Python. En\n",
            "particular, utilizaremos su función \n",
            "loads\n",
            ", que deserializa una cadena de texto\n",
            "que representa un objeto JSON y la transforma en un objeto Python:\n",
            "import json\n",
            "serialized = \"\"\"{ \"title\" : \"Data Science Book\",\n",
            "\"author\" : \"Joel Grus\",\n",
            "\"publicationYear\" : 2019,\n",
            "\"topics\" : [ \"data\", \"science\", \"data science\"] }\"\"\"\n",
            "# analiza JSON para crear un dict de Python\n",
            "deserialized = json.loads(serialized)\n",
            "assert deserialized[\"publicationYear\"] == 2019\n",
            "assert \"data science\" in deserialized[\"topics\"]\n",
            "A veces, un proveedor de API te odia y solamente ofrece respuestas en\n",
            "XML:\n",
            "<Book>\n",
            "<Title>Data Science Book</Title>\n",
            "<Author>Joel Grus</Author>\n",
            "<PublicationYear>2014</PublicationYear>\n",
            "<Topics>\n",
            "<Topic>data</Topic>\n",
            "<Topic>science</Topic>\n",
            "<Topic>data science</Topic>\n",
            "</Topics>\n",
            "</Book>\n",
            "Puede utilizar Beautiful Soup para obtener datos de XML de forma\n",
            "parecida a como lo usamos para obtener datos de HTML; revise su\n",
            "documentación para más detalles.\n",
            "Utilizar una API no autenticada\n",
            "La mayoría de las API actuales exigen que primero se autentifique uno\n",
            "mismo antes de poder utilizarlas. Aunque no envidiamos esta política, crea\n",
            "una gran cantidad de información adicional que enturbia nuestra exposición.Según esto, empezaremos echando un vistazo a la API de GitHub,\n",
            "4\n",
            " con la\n",
            "que podemos hacer algunas cosas sencillas sin necesitar de autenticación:\n",
            "import requests, json\n",
            "github_user = \"joelgrus\"\n",
            "endpoint = f\"https://api.github.com/users/{github_user}/repos\"\n",
            "repos = json.loads(requests.get(endpoint).text)\n",
            "Debo decir que \n",
            "repos\n",
            " es una \n",
            "list\n",
            " de clases \n",
            "dict\n",
            " de Python, que\n",
            "representa cada una un repositorio público en mi cuenta de GitHub (coloque\n",
            "con toda libertad su nombre de usuario y obtenga su propio repositorio de\n",
            "GitHub; porque, tiene cuenta en GitHub, ¿verdad?).\n",
            "Podemos utilizar esto para averiguar en qué meses y días del año es más\n",
            "probable que yo cree un repositorio. El único inconveniente es que las fechas\n",
            "de la respuesta son cadenas de texto:\n",
            "“created_at”: “2013-07-05T02:02:28Z”\n",
            "Python no incluye un analizador de fechas demasiado bueno, así que\n",
            "tendremos que instalar uno:\n",
            "python -m pip install python-dateutil\n",
            "A partir del cual es probable que solo se necesite la función\n",
            "dateutil.parser.parse\n",
            ":\n",
            "from collections import Counter\n",
            "from dateutil.parser import parse\n",
            "dates = [parse(repo[\"created_at\"]) for repo in repos]\n",
            "month_counts = Counter(date.month for date in dates)\n",
            "weekday_counts = Counter(date.weekday() for date in dates)\n",
            "De forma similar, se pueden conseguir los lenguajes de mis cinco últimos\n",
            "repositorios:\n",
            "last_5_repositories = sorted(repos,\n",
            "key=lambda r: r[\"pushed_at\"],\n",
            "reverse=True)[:5]\n",
            "last_5_languages = [repo[\"language\"]\n",
            "for repo in last_5_repositories]Lo normal es que no trabajemos con API en este bajo nivel de “hacemos\n",
            "las solicitudes y analizamos las respuestas nosotros mismos”. Uno de los\n",
            "beneficios de utilizar Python es que alguien ya ha creado una librería para\n",
            "prácticamente cualquier API a la que estemos interesados en acceder. Cuando\n",
            "lo han hecho bien, estas librerías pueden ahorrar buena parte del problema de\n",
            "averiguar los detalles más peliagudos del acceso API (pero, cuando no lo han\n",
            "hecho tan bien o cuando resulta que están basados en versiones difuntas de\n",
            "las correspondientes API, pueden provocar enormes dolores de cabeza).\n",
            "No obstante, de vez en cuando habrá que desarrollar una librería de acceso\n",
            "API propia (o, lo más probable, depurar, porque la de otra persona no\n",
            "funcione), de modo que resulta positivo conocer parte de los detalles.\n",
            "Encontrar API\n",
            "Si nos hacen falta datos de un determinado sitio, hay que buscar en él una\n",
            "sección “desarrolladores”, “\n",
            "developers\n",
            "” o “API” para obtener más\n",
            "información, y tratar de buscar en la web “python <nombredelsitio> api” para\n",
            "encontrar una librería.\n",
            "Hay librerías para la API de Yelp, de Instagram, de Spotify, etc.\n",
            "Si lo que queremos es una lista de API que tengan \n",
            "wrappers\n",
            " de Python,\n",
            "una que está muy bien es la de Real Python de GitHub.\n",
            "5\n",
            "Y, si no se encuentra lo buscado, siempre quedará el raspado, el último\n",
            "refugio del científico de datos.\n",
            "Ejemplo: Utilizar las API de Twitter\n",
            "Twitter es una fuente fenomenal de datos para trabajar. Se puede utilizar\n",
            "para obtener noticias en tiempo real, para medir reacciones a acontecimientos\n",
            "actuales, para encontrar enlaces relacionados con determinados temas, etc. En\n",
            "definitiva, se puede utilizar prácticamente para cualquier cosa que se pueda\n",
            "imaginar, siempre y cuando se tenga acceso a sus datos, obviamente a través\n",
            "de sus API.\n",
            "Para interactuar con las API de Twitter, vamos a emplear la libreríaTwython\n",
            "6\n",
            " (\n",
            "python\n",
            " \n",
            "-m\n",
            " \n",
            "pipinstall\n",
            " \n",
            "twython\n",
            "). Existen bastantes librerías de\n",
            "Python para Twitter, pero con esta es con la que me ha ido mejor. ¡Le animo\n",
            "a que explore otras opciones!\n",
            "Obtener credenciales\n",
            "Para poder utilizar las API de Twitter, es necesario conseguir credenciales\n",
            "(para lo cual hay que tener una cuenta de Twitter, que probablemente tendrá\n",
            "si desea formar parte de la animada y amistosa comunidad #datascience de\n",
            "Twitter).\n",
            "Advertencia:\n",
            " Como todas las instrucciones relacionadas con sitios web que no\n",
            "controlo, estas pueden quedar obsoletas en algún momento, pero espero que\n",
            "funcionen durante el tiempo suficiente (aunque ya han cambiado varias veces\n",
            "desde que empecé a escribir este libro, así que ¡buena suerte!).\n",
            "Estos son los pasos a seguir:\n",
            "1\n",
            ".\n",
            "Vaya a \n",
            "https://developer.twitter.com/\n",
            ".\n",
            "2\n",
            ".\n",
            "Si no está ya dentro, haga clic en \n",
            "Sign\n",
            " \n",
            "in\n",
            " e introduzca su nombre de\n",
            "usuario de Twitter y su contraseña.\n",
            "3\n",
            ".\n",
            "Haga clic en \n",
            "Apply\n",
            " para solicitar una cuenta de desarrollador.\n",
            "4\n",
            ".\n",
            "Solicite acceso para uso personal.\n",
            "5\n",
            ".\n",
            "Rellene la solicitud. Dispondrá de 300 palabras para explicar (en serio)\n",
            "por qué necesita el acceso, de modo que para pasarse del límite puede\n",
            "hablarles de este libro y de lo mucho que está disfrutando con su\n",
            "lectura.\n",
            "6\n",
            ".\n",
            "Espere una cantidad de tiempo indefinida.\n",
            "7\n",
            ".\n",
            "Si conoce a alguien que trabaje en Twitter, envíele un correo\n",
            "electrónico preguntándole si puede acelerar su solicitud. Si no, siga\n",
            "esperando.\n",
            "8\n",
            ".\n",
            "En cuanto se la aprueben, vuelva a \n",
            "https://developer.twitter.com/\n",
            ",\n",
            "localice la sección \n",
            "Apps\n",
            " y haga clic en \n",
            "Create\n",
            " \n",
            "an\n",
            " \n",
            "app\n",
            ".\n",
            "9\n",
            ".\n",
            "Rellene todos los campos necesarios (aquí también, si necesita textoadicional para la descripción, puede hablar de este libro y de lo\n",
            "edificante que le está resultando).\n",
            "10. Haga clic en \n",
            "CREATE\n",
            ".\n",
            "Ahora su aplicación debería incluir una pestaña \n",
            "Keys\n",
            " \n",
            "and\n",
            " \n",
            "tokens\n",
            " con una\n",
            "sección \n",
            "Consumer\n",
            " \n",
            "API\n",
            " \n",
            "keys\n",
            ", donde se lista una “clave API” y una “clave\n",
            "secreta API”. Tome nota de estas claves, porque las necesitará (y guárdelas\n",
            "bien; son como contraseñas).\n",
            "Advertencia:\n",
            " No comparta las claves, no las publique en su libro, ni las\n",
            "compruebe en su repositorio público de GitHub. Una solución sencilla es\n",
            "almacenarlas en un archivo \n",
            "credenciales.json\n",
            " que no se compruebe, y hacer\n",
            "que su código utilice \n",
            "json.loads\n",
            " para recuperarlas. Otra solución es\n",
            "almacenarlas en variables de entorno y utilizar \n",
            "os.environ\n",
            " para recuperarlas.\n",
            "Utilizar Twython\n",
            "La parte más difícil de utilizar la API de Twitter es autentificarse a uno\n",
            "mismo (de hecho, esto es lo más difícil en la mayoría de las API). Los\n",
            "proveedores de API quieren asegurarse de que está autorizado para acceder a\n",
            "sus datos y que no va a exceder sus límites de uso. También quieren saber\n",
            "quién está accediendo a sus datos.\n",
            "La autentificación es un incordio. Tenemos dos métodos: uno fácil, OAuth\n",
            "2, que sirve perfectamente cuando solo se desean realizar búsquedas\n",
            "sencillas, y otro complejo, OAuth 1, que es necesario cuando se quieren\n",
            "realizar acciones (por ejemplo, tuitear) o (para nuestro caso en particular)\n",
            "conectar con el \n",
            "stream\n",
            " de Twitter.\n",
            "Así que nos quedamos con la forma más complicada, que trataremos de\n",
            "automatizar tanto como podamos.\n",
            "En primer lugar, necesitamos la clave API y la clave secreta API (a veces\n",
            "conocida como clave de consumidor y clave secreta de consumidor,\n",
            "respectivamente). Obtendré la mía a partir de variables de entorno (no dude\n",
            "en poner las suyas si lo desea):\n",
            "import os# Cambie sin dudarlo sus claves directamente\n",
            "CONSUMER_KEY = os.environ.get(\"TWITTER_CONSUMER_KEY\")\n",
            "CONSUMER_SECRET = os.environ.get(\"TWITTER_CONSUMER_SECRET\")\n",
            "Ahora podemos instanciar el cliente:\n",
            "import webbrowser\n",
            "from twython import Twython\n",
            "# Obtiene cliente temporal para recuperar URL de autenticación\n",
            "temp_client = Twython(CONSUMER_KEY, CONSUMER_SECRET)\n",
            "temp_creds = temp_client.get_authentication_tokens()\n",
            "url = temp_creds[‘auth_url’]\n",
            "# Ahora visita la URL para autorizar a la aplicación y obtener un PIN\n",
            "print(f\"go visit {url} and get the PIN code and paste it below\")\n",
            "webbrowser.open(url)\n",
            "PIN_CODE = input(\"please enter the PIN code: \")\n",
            "# Ahora usamos ese PIN_CODE para obtener los tokens reales\n",
            "auth_client = Twython(CONSUMER_KEY,\n",
            "CONSUMER_SECRET,\n",
            "temp_creds[‘oauth_token’],\n",
            "temp_creds[‘oauth_token_secret’])\n",
            "final_step = auth_client.get_authorized_tokens(PIN_CODE)\n",
            "ACCESS_TOKEN = final_step[‘oauth_token’]\n",
            "ACCESS_TOKEN_SECRET = final_step[‘oauth_token_secret’]\n",
            "# Y obtiene una nueva instancia Twython usándolos.\n",
            "twitter = Twython(CONSUMER_KEY,\n",
            "CONSUMER_SECRET,\n",
            "ACCESS_TOKEN,\n",
            "ACCESS_TOKEN_SECRET)\n",
            "Truco:\n",
            " Quizá en este momento le interese guardar \n",
            "ACCESS_TOKEN\n",
            " y\n",
            "ACCESS_TOKEN_SECRET\n",
            " en un sitio seguro, de modo que la próxima vez no tenga\n",
            "que pasar por todo este jaleo de nuevo.\n",
            "En cuanto tengamos una instancia Twython autenticada, podemos\n",
            "empezar a realizar búsquedas:\n",
            "# Busca tuits que contengan la frase \"datascience\"\n",
            "for status in twitter.search(q=’\"data science\"’)[\"statuses\"]:\n",
            "user = status[\"user\"][\"screen_name\"]\n",
            "text = status[\"text\"]\n",
            "print(f\"{user}: {text}\\n\")Si ejecutamos esto, obtendremos algunos tuits como estos:\n",
            "haithemnyc: Data scientists with the technical savvy &amp; analytical chops to\n",
            "derive meaning from big data are in demand. http://t.co/HsF9Q0dShP\n",
            "RPubsRecent: Data Science http://t.co/6hcHUz2PHM\n",
            "spleonard1: Using #dplyr in #R to work through a procrastinated assignment for\n",
            "@rdpeng in @coursera data science specialization. So easy and Awesome.\n",
            "Que no son muy interesantes, en parte porque la API Search de Twitter\n",
            "solo muestra el montón de resultados recientes que quiera. Cuando estamos\n",
            "haciendo ciencia de datos, solemos querer muchos tuits. Aquí es donde\n",
            "resulta de gran utilidad la API Streaming.\n",
            "7\n",
            " Permite conectarse al gran\n",
            "Firehose de Twitter (mejor dicho, a una pequeña parte). Para utilizarlo, será\n",
            "necesario autentificarse utilizando sus \n",
            "tokens\n",
            " de acceso.\n",
            "Para acceder a la API Streaming con Twython, tenemos que definir una\n",
            "clase que herede de \n",
            "TwythonStreamer\n",
            " y que anule su método \n",
            "on_success\n",
            ", y\n",
            "posiblemente también su método \n",
            "on_error\n",
            ":\n",
            "from twython import TwythonStreamer\n",
            "# Añadir datos a una variable global es bastante pobre\n",
            "# pero simplifica mucho el ejemplo\n",
            "tweets = []\n",
            "class MyStreamer(TwythonStreamer):\n",
            "def on_success(self, data):\n",
            "\"\"\"\n",
            "What do we do when Twitter sends us data?\n",
            "Here data will be a Python dict representing a tweet.\n",
            "\"\"\"\n",
            "# Solo queremos recopilar tuits en inglés\n",
            "if data.get(‘lang’) == ‘en’:\n",
            "tweets.append(data)\n",
            "print(f\"received tweet #{len(tweets)}\")\n",
            "# Para cuando hemos recopilado bastantes\n",
            "if len(tweets) >= 100:\n",
            "self.disconnect()\n",
            "def on_error(self, status_code, data):\n",
            "print(status_code, data)\n",
            "self.disconnect()\n",
            "MyStreamer\n",
            " conectará con el \n",
            "stream\n",
            " de Twitter y esperará a que Twitter lepase datos. Cada vez que reciba datos (aquí, un tuit representado como un\n",
            "objeto de Python), los pasa al método \n",
            "on_success\n",
            ", que los añade a nuestra\n",
            "lista \n",
            "tweets\n",
            " si su idioma es inglés, y, una vez que ha recogido 1.000 tuits, se\n",
            "desconecta del \n",
            "streamer\n",
            ".\n",
            "Todo lo que queda por hacer es inicializarlo y empezar a ejecutarlo:\n",
            "stream = MyStreamer(CONSUMER_KEY, CONSUMER_SECRET,\n",
            "ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
            "# empieza a consumir estados públicos que contienen ‘data’\n",
            "stream.statuses.filter(track=’data’)\n",
            "# pero si queremos empezar a consumir una muestra de *todos* los estados\n",
            "públicos\n",
            "# stream.statuses.sample()\n",
            "Esto se ejecutará hasta que recopile 100 tuits (o hasta que encuentre un\n",
            "error) y se detendrá, momento en el cual podremos empezar a analizar esos\n",
            "tuits. Por ejemplo, podríamos encontrar los \n",
            "hashtags\n",
            " más habituales con:\n",
            "top_hashtags = Counter(hashtag[‘text’].lower()\n",
            "for tweet in tweets\n",
            "for hashtag in tweet[\"entities\"][\"hashtags\"])\n",
            "print(top_hashtags.most_common(5))\n",
            "Cada tuit contiene muchos datos. Puede investigar por sí mismo o buscar\n",
            "en la documentación de las API de Twitter.\n",
            "8\n",
            "Nota:\n",
            " En un proyecto real, probablemente no quiera confiar en una \n",
            "list\n",
            " en\n",
            "memoria para almacenar los tuits. Lo mejor que podría hacer sería guardarlos en\n",
            "un archivo o en una base de datos, de modo que así dispondría de ellos\n",
            "permanentemente.\n",
            "Para saber más\n",
            "■\n",
            "pandas, en \n",
            "http://pandas.pydata.org/\n",
            ", es la librería que utilizan\n",
            "normalmente los científicos de datos para trabajar con datos\n",
            "(específicamente, para importarlos).\n",
            "■\n",
            "Scrapy, en \n",
            "http://scrapy.org/\n",
            ", es una librería repleta de funcionespara crear complicados raspadores web, que hagan cosas como seguir\n",
            "enlaces desconocidos.\n",
            "■\n",
            "Kaggle, en \n",
            "https://www.kaggle.com/datasets\n",
            ", alberga una gran\n",
            "colección de conjuntos de datos.\n",
            "1\n",
            " \n",
            "https://stackoverflow.com/questions/15587877/run-a-python-script-in-terminal-\n",
            "without-the-python-command\n",
            ".\n",
            "2\n",
            " \n",
            "https://www.crummy.com/software/BeautifulSoup/\n",
            ".\n",
            "3\n",
            " \n",
            "https://docs.python-requests.org/en/latest/\n",
            ".\n",
            "4\n",
            " \n",
            "https://docs.github.com/es/rest\n",
            ".\n",
            "5\n",
            " \n",
            "https://github.com/realpython/list-of-python-api-wrappers\n",
            ".\n",
            "6\n",
            " \n",
            "https://github.com/ryanmcgrath/twython\n",
            ".\n",
            "7\n",
            " \n",
            "https://developer.twitter.com/en/docs/tutorials/consuming-streaming-data\n",
            ".\n",
            "8\n",
            " \n",
            "https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-\n",
            "object\n",
            ".10\n",
            " Trabajar con datos\n",
            "Los expertos suelen poseer más datos que criterio.\n",
            "—Colin Powell\n",
            "Trabajar con datos es un arte, así como una ciencia. En general, hemos\n",
            "estado hablando de la parte científica, pero en este capítulo nos centraremos\n",
            "en el arte.\n",
            "Explorar los datos\n",
            "Una vez identificadas las preguntas que intentamos responder y después\n",
            "de haber obtenido datos, quizá se sienta tentado a meterse de lleno y empezar\n",
            "inmediatamente a crear modelos y obtener respuestas. Pero es necesario\n",
            "resistirse a este impulso. El primer paso debe ser explorar los datos.\n",
            "Explorar datos unidimensionales\n",
            "El caso más sencillo es tener un conjunto de datos unidimensional, que no\n",
            "es más que una colección de números. Por ejemplo, podría ser el número de\n",
            "minutos promedio al día que cada usuario se pasa en un sitio web, el número\n",
            "de veces que cada uno de los vídeos de tutoriales de ciencia de datos de una\n",
            "colección es visionado, o el número de páginas de cada uno de los libros de\n",
            "ciencia de datos que hay en una biblioteca.\n",
            "Un primer paso obvio es calcular algunas estadísticas de resumen. Nos\n",
            "interesa saber cuántos puntos de datos tenemos, el menor, el mayor, la media\n",
            "y la desviación estándar.\n",
            "Pero incluso estos datos no tienen por qué ofrecer un elevado nivel de\n",
            "comprensión. El siguiente paso correcto sería crear un histograma, en el que\n",
            "se agrupan los datos en \n",
            "buckets\n",
            " discretos y se cuenta cuántos puntos caen encada \n",
            "bucket\n",
            ":\n",
            "from typing import List, Dict\n",
            "from collections import Counter\n",
            "import math\n",
            "import matplotlib.pyplot as plt\n",
            "def bucketize(point: float, bucket_size: float) -> float:\n",
            "\"\"\"Floor the point to the next lower multiple of bucket_size\"\"\"\n",
            "return bucket_size * math.floor(point / bucket_size)\n",
            "def make_histogram(points: List[float], bucket_size: float) -> Dict[float,\n",
            "int]:\n",
            "\"\"\"Buckets the points and counts how many in each bucket\"\"\"\n",
            "return Counter(bucketize(point, bucket_size) for point in points)\n",
            "def plot_histogram(points: List[float], bucket_size: float, title: str = \"\"):\n",
            "histogram = make_histogram(points, bucket_size)\n",
            "plt.bar(histogram.keys(), histogram.values(), width=bucket_size)\n",
            "plt.title(title)\n",
            "Por ejemplo, tengamos en cuenta los dos siguientes conjuntos de datos:\n",
            "import random\n",
            "from scratch.probability import inverse_normal_cdf\n",
            "random.seed(0)\n",
            "# uniforme entre -100 y 100\n",
            "uniform = [200 * random.random()–100 for _ in range(10000)]\n",
            "# distribución normal con media 0, desviación estándar 57\n",
            "normal = [57 * inverse_normal_cdf(random.random())\n",
            "for _ in range(10000)]\n",
            "Ambos tienen medias próximas a 0 y desviaciones estándares cercanas a\n",
            "58. Sin embargo, tienen distribuciones muy distintas. La figura 10.1 muestra\n",
            "la distribución de \n",
            "uniform\n",
            ":\n",
            "plot_histogram(uniform, 10, “Uniform Histogram”)\n",
            "Mientras que la figura 10.2 muestra la distribución de \n",
            "normal\n",
            ":\n",
            "plot_histogram(normal, 10, “Normal Histogram”)\n",
            "En este caso, las dos distribuciones tienen \n",
            "max\n",
            " y \n",
            "min\n",
            " bastante diferentes,\n",
            "pero ni siquiera saber esto habría sido suficiente para entender cómo difieren.Figura 10.1. \n",
            "Histograma de \n",
            "uniform\n",
            ".\n",
            "Figura 10.2. \n",
            "Histograma de \n",
            "normal\n",
            ".\n",
            "Dos dimensiones\n",
            "Ahora imaginemos que tenemos un conjunto de datos con dosdimensiones. Quizá, además de los minutos diarios, tenemos años de\n",
            "experiencia en ciencia de datos. Por supuesto que queremos entender cada\n",
            "dimensión de manera individual, pero probablemente también nos interese\n",
            "dispersar los datos.\n",
            "Por ejemplo, veamos otro conjunto de datos imaginario:\n",
            "def random_normal() -> float:\n",
            "\"\"\"Returns a random draw from a standard normal distribution\"\"\"\n",
            "return inverse_normal_cdf(random.random())\n",
            "xs = [random_normal() for _ in range(1000)]\n",
            "ys1 = [ x + random_normal() / 2 for x in xs]\n",
            "ys2 = [-x + random_normal() / 2 for x in xs]\n",
            "Si ejecutáramos \n",
            "plot_histogram\n",
            " en \n",
            "ys1\n",
            " e \n",
            "ys2\n",
            ", obtendríamos trazados de\n",
            "aspecto similar (de hecho, ambos están distribuidos normalmente con la\n",
            "misma media y desviación estándar).\n",
            "Pero cada uno tiene una distribución conjunta diferente con \n",
            "xs\n",
            ", como\n",
            "puede verse en la figura 10.3:\n",
            "plt.scatter(xs, ys1, marker=’.’, color=’black’, label=’ys1’)\n",
            "plt.scatter(xs, ys2, marker=’.’, color=’gray’, label=’ys2’)\n",
            "plt.xlabel(‘xs’)\n",
            "plt.ylabel(‘ys’)\n",
            "plt.legend(loc=9)\n",
            "plt.title(\"Very Different Joint Distributions\")\n",
            "plt.show()Figura 10.3. \n",
            "Dispersando dos \n",
            "ys\n",
            " distintos.\n",
            "Esta diferencia también se haría patente si mirásemos las correlaciones:\n",
            "from scratch.statistics import correlation\n",
            "print(correlation(xs, ys1))\n",
            "# más o menos 0.9\n",
            "print(correlation(xs, ys2))\n",
            "# más o menos -0.9\n",
            "Muchas dimensiones\n",
            "Si tenemos muchas dimensiones, nos interesará saber cómo se relacionan\n",
            "todas ellas entre sí. Una forma sencilla de averiguarlo es mirar la matriz de\n",
            "correlación, en la que la entrada de la fila \n",
            "i\n",
            " y la columna \n",
            "j\n",
            " es la correlación\n",
            "entre la dimensión \n",
            "i\n",
            " y la dimensión \n",
            "j\n",
            " de los datos:\n",
            "from scratch.linear_algebra import Matrix, Vector, make_matrix\n",
            "def correlation_matrix(data: List[Vector]) -> Matrix:\n",
            "\"\"\"\n",
            "Returns the len(data) x len(data) matrix whose (i, j)-th entry\n",
            "is the correlation between data[i] and data[j]\n",
            "\"\"\"\n",
            "def correlation_ij(i: int, j: int) -> float:\n",
            "return correlation(data[i], data[j])\n",
            "return make_matrix(len(data), len(data), correlation_ij)Un método más visual (si no tenemos demasiadas dimensiones) es hacer\n",
            "una matriz de \n",
            "scatterplot\n",
            " o de diagrama de dispersión (figura 10.4), que\n",
            "muestre todos los gráficos de dispersión por pares. Para ello, utilizaremos\n",
            "plt.subplots\n",
            ", que nos permite crear \n",
            "subplots\n",
            " de nuestro gráfico. Le damos\n",
            "el número de filas y columnas y devuelve un objeto \n",
            "figure\n",
            " (que no\n",
            "usaremos) y un \n",
            "array\n",
            " bidimensional de objetos \n",
            "axes\n",
            " (que mostraremos en\n",
            "pantalla):\n",
            "# corr_data es una lista de vectores de 100 dimensiones\n",
            "num_vectors = len(corr_data)\n",
            "fig, ax = plt.subplots(num_vectors, num_vectors)\n",
            "for i in range(num_vectors):\n",
            "for j in range(num_vectors):\n",
            "# Dispersa column_j en el eje x frente a column_i en el eje y\n",
            "if i != j: ax[i][j].scatter(corr_data[j], corr_data[i])\n",
            "# a menos que i == j, en ese caso muestra el nombre de la serie\n",
            "else: ax[i][j].annotate(\"series \" + str(i), (0.5, 0.5),\n",
            "xycoords=’axes fraction’,\n",
            "ha=\"center\", va=\"center\")\n",
            "# Luego oculta etiquetas de eje, salvo los diagramas izquierdo e inferior\n",
            "if i < num_vectors–1: ax[i][j].xaxis.set_visible(False)\n",
            "if j > 0: ax[i][j].yaxis.set_visible(False)\n",
            "# Fija las etiquetas de ejes de abajo derecha y arriba izquierda, que están mal\n",
            "# porque sus diagramas solo contienen texto\n",
            "ax[-1][-1].set_xlim(ax[0][-1].get_xlim())\n",
            "ax[0][0].set_ylim(ax[0][1].get_ylim())\n",
            "plt.show()Figura 10.4. \n",
            "Matriz de diagrama de dispersión.\n",
            "Mirando los diagramas de dispersión, podemos ver que la serie 1 está\n",
            "correlacionada muy negativamente con la serie 0, la serie 2 lo está\n",
            "positivamente con la serie 1 y la serie 3 solo toma los valores 0 y 6,\n",
            "correspondiendo el 0 a los valores pequeños de la serie 2 y el 6 a los valores\n",
            "grandes.\n",
            "Esta es una forma rápida de hacerse una idea general de cuál de las\n",
            "variables está correlacionada (a menos que se pase horas retocando matplotlib\n",
            "para mostrar las cosas exactamente como las quiere, en cuyo caso no es un\n",
            "método rápido).\n",
            "Utilizar NamedTuples\n",
            "Una forma habitual de representar datos es utilizando \n",
            "dict\n",
            ":\n",
            "import datetime\n",
            "stock_price = {‘closing_price’: 102.06,\n",
            "‘date’: datetime.date(2014, 8, 29),\n",
            "‘symbol’: ‘AAPL’}Hay varias razones por las que esto, sin embargo, no es lo ideal. Es una\n",
            "representación ligeramente ineficaz (un \n",
            "dict\n",
            " implica gastos extra), de modo\n",
            "que, si tenemos muchos precios de acciones, ocuparán más memoria de la\n",
            "necesaria. En general, esto es una consideración de menor importancia.\n",
            "Un problema mayor es que acceder a las cosas mediante una clave \n",
            "dict\n",
            "tiene tendencia a producir errores. El siguiente código funcionará sin errores\n",
            "y solo hará lo incorrecto:\n",
            "# huy, error\n",
            "stock_price[‘cosing_price’] = 103.06\n",
            "Finalmente, aunque podemos anotar los tipos de diccionarios uniformes:\n",
            "prices: Dict[datetime.date, float] = {}\n",
            "No hay un modo útil de anotar diccionarios como datos que tengan\n",
            "muchos tipos de valores distintos, de forma que también perdemos el poder\n",
            "de las comprobaciones de tipos.\n",
            "Como alternativa, Python incluye una clase \n",
            "namedtuple\n",
            ", que es como una\n",
            "tuple\n",
            " pero con nombres:\n",
            "from collections import namedtuple\n",
            "StockPrice = namedtuple(‘StockPrice’, [‘symbol’, ‘date’, ‘closing_price’])\n",
            "price = StockPrice(‘MSFT’, datetime.date(2018, 12, 14), 106.03)\n",
            "assert price.symbol == ‘MSFT’\n",
            "assert price.closing_price == 106.03\n",
            "Como las \n",
            "tuple\n",
            " normales, las \n",
            "namedtuple\n",
            " son inmutables, lo que\n",
            "significa que no se pueden modificar sus valores una vez que se crean. De\n",
            "vez en cuando, esto se interpondrá en nuestro camino, pero en general es algo\n",
            "bueno.\n",
            "Vemos que no hemos resuelto aún el tema de la anotación de tipo. Lo\n",
            "hacemos utilizando la variante con nombre, \n",
            "NamedTuple\n",
            ":\n",
            "from typing import NamedTuple\n",
            "class StockPrice(NamedTuple):\n",
            "symbol: str\n",
            "date: datetime.dateclosing_price: float\n",
            "def is_high_tech(self) -> bool:\n",
            "\"\"\"It’s a class, so we can add methods too\"\"\"\n",
            "return self.symbol in [‘MSFT’, ‘GOOG’, ‘FB’, ‘AMZN’, ‘AAPL’]\n",
            "price = StockPrice(‘MSFT’, datetime.date(2018, 12, 14), 106.03)\n",
            "assert price.symbol == ‘MSFT’\n",
            "assert price.closing_price == 106.03\n",
            "assert price.is_high_tech()\n",
            "Ahora el editor nos puede ayudar, como muestra la figura 10.5.\n",
            "Figura 10.5. \n",
            "Útil editor.\n",
            "Nota:\n",
            " Muy poca gente utiliza así \n",
            "NamedTuple\n",
            ". ¡Pero deberían!\n",
            "Clases de datos\n",
            "Las clases de datos son (más o menos) una versión mutable de\n",
            "NamedTuple\n",
            " (digo “más o menos” porque las \n",
            "NamedTuple\n",
            " representan sus\n",
            "datos de manera compacta como tuples, mientras que las \n",
            "dataclasses\n",
            " son\n",
            "clases de Python normales que simplemente se encargan de generar\n",
            "automáticamente ciertos métodos).\n",
            "Nota: \n",
            "Las clases de datos son nuevas en Python 3.7. Si está utilizando una\n",
            "versión más antigua, esta sección no le servirá.\n",
            "La sintaxis es muy parecida a la de \n",
            "NamedTuple\n",
            ". Pero, en lugar de heredar\n",
            "de una clase base, utilizamos un decorador:\n",
            "from dataclasses import dataclass\n",
            "@dataclassclass StockPrice2:\n",
            "symbol: str\n",
            "date: datetime.date\n",
            "closing_price: float\n",
            "def is_high_tech(self) -> bool:\n",
            "\"\"\"It’s a class, so we can add methods too\"\"\"\n",
            "return self.symbol in [‘MSFT’, ‘GOOG’, ‘FB’, ‘AMZN’, ‘AAPL’]\n",
            "price2 = StockPrice2(‘MSFT’, datetime.date(2018, 12, 14), 106.03)\n",
            "assert price2.symbol == ‘MSFT’\n",
            "assert price2.closing_price == 106.03\n",
            "assert price2.is_high_tech()\n",
            "Como ya hemos dicho antes, la gran diferencia es que podemos modificar\n",
            "los valores de la instancia de una clase de datos:\n",
            "# división de acciones\n",
            "price2.closing_price /= 2\n",
            "assert price2.closing_price == 51.03\n",
            "Si intentáramos modificar un campo de la versión \n",
            "NamedTuple\n",
            ",\n",
            "obtendríamos un \n",
            "AttributeError\n",
            ".\n",
            "Esto nos deja también susceptibles al tipo de errores que esperamos evitar\n",
            "no utilizando \n",
            "dict\n",
            ":\n",
            "# Es una clase regular, así que añada campos siempre que quiera.\n",
            "price2.cosing_price = 75\n",
            "# huy\n",
            "No utilizaremos clases de datos, pero es fácil que se las encuentre por ahí\n",
            "fuera.\n",
            "Limpiar y preparar datos\n",
            "Los datos del mundo real están “sucios”. Muchas veces tendremos que\n",
            "trabajar con ellos antes de poder utilizarlos. Hemos visto ejemplos en el\n",
            "capítulo 9. Hay que convertir cadenas de texto en \n",
            "float\n",
            " o \n",
            "int\n",
            " antes de poder\n",
            "usarlos, o revisar en busca de valores perdidos, valores atípicos (\n",
            "outliers\n",
            ") y\n",
            "datos erróneos.\n",
            "Anteriormente, hicimos esto justo antes de usar los datos:closing_price = float(row[2])\n",
            "Pero probablemente induce menos errores analizar una función que\n",
            "podemos probar:\n",
            "from dateutil.parser import parse\n",
            "def parse_row(row: List[str]) -> StockPrice:\n",
            "symbol, date, closing_price = row\n",
            "return StockPrice(symbol=symbol,\n",
            "date=parse(date).date(),\n",
            "closing_price=float(closing_price))\n",
            "# A probar la función\n",
            "stock = parse_row([\"MSFT\", \"2018-12-14\", \"106.03\"])\n",
            "assert stock.symbol == \"MSFT\"\n",
            "assert stock.date == datetime.date(2018, 12, 14)\n",
            "assert stock.closing_price == 106.03\n",
            "¿Qué pasa si hay datos erróneos? ¿O un valor “float” que en realidad no\n",
            "representa un número? ¿Quizá es mejor obtener un \n",
            "None\n",
            " que el programa se\n",
            "cuelgue?\n",
            "from typing import Optional\n",
            "import re\n",
            "def try_parse_row(row: List[str]) -> Optional[StockPrice]:\n",
            "symbol, date_, closing_price_ = row\n",
            "# El símbolo de acción debe estar en mayúscula\n",
            "if not re.match(r\"^[A-Z]+$\", symbol):\n",
            "return None\n",
            "try:\n",
            "date = parse(date_).date()\n",
            "except ValueError:\n",
            "return None\n",
            "try:\n",
            "closing_price = float(closing_price_)\n",
            "except ValueError:\n",
            "return None\n",
            "return StockPrice(symbol, date, closing_price)\n",
            "# Debería devolver None por errores\n",
            "assert try_parse_row([\"MSFT0\", \"2018-12-14\", \"106.03\"]) is None\n",
            "assert try_parse_row([\"MSFT\", \"2018-12—14\", \"106.03\"]) is None\n",
            "assert try_parse_row([\"MSFT\", \"2018-12-14\", \"x\"]) is None\n",
            "# Pero debería devolver lo mismo que antes si los datos son correctos\n",
            "assert try_parse_row([\"MSFT\", \"2018-12-14\", \"106.03\"]) == stockPor ejemplo, si tenemos precios de acciones delimitados por comas con\n",
            "datos sobrantes:\n",
            "AAPL,6/20/2014,90.91\n",
            "MSFT,6/20/2014,41.68\n",
            "FB,6/20/3014,64.5\n",
            "AAPL,6/19/2014,91.86\n",
            "MSFT,6/19/2014,n/a\n",
            "FB,6/19/2014,64.34\n",
            "Ahora podemos leer y devolver solo las filas válidas:\n",
            "import csv\n",
            "data: List[StockPrice] = []\n",
            "with open(\"comma_delimited_stock_prices.csv\") as f:\n",
            "reader = csv.reader(f)\n",
            "for row in reader:\n",
            "maybe_stock = try_parse_row(row)\n",
            "if maybe_stock is None:\n",
            "print(f\"skipping invalid row: {row}\")\n",
            "else:\n",
            "data.append(maybe_stock)\n",
            "Y decidir lo que queremos hacer con las no válidas. En general, las tres\n",
            "opciones son deshacerse de ellas, volver al origen y tratar de arreglar los\n",
            "datos sobrantes/faltantes, o no hacer nada y cruzar los dedos. Si hay una sola\n",
            "fila errónea de millones, probablemente no pasa nada por ignorarla. Pero, si\n",
            "la mitad de las filas tienen datos sobrantes, es algo que conviene arreglar.\n",
            "Algo correcto que podemos hacer a continuación es buscar valores\n",
            "atípicos (\n",
            "outliers\n",
            "), utilizando las técnicas vistas en el apartado “Explorar\n",
            "datos” del comienzo de este capítulo o investigando como corresponde. Por\n",
            "ejemplo, ¿se dio cuenta de que una de las fechas del archivo de acciones tenía\n",
            "el año 3014? No tendría por qué dar error, pero es claramente incorrecto, y se\n",
            "obtendrían resultados caóticos si no se detectara. A los conjuntos de datos\n",
            "reales les faltan puntos decimales, tienen ceros de más, errores tipográficos y\n",
            "otros incontables problemas que nosotros tenemos que localizar (quizá este\n",
            "no sea oficialmente su trabajo, pero ¿quién más lo va a hacer?).\n",
            "Manipular datosUna de las habilidades más importantes de un científico de datos es la\n",
            "manipulación de los mismos. Se trata de un acercamiento general más que de\n",
            "una técnica específica, así que simplemente veremos unos cuantos ejemplos\n",
            "para que se haga una idea.\n",
            "Imaginemos que tenemos un montón de datos de precios de acciones con\n",
            "este aspecto:\n",
            "data = [\n",
            "StockPrice(symbol=’MSFT’,\n",
            "date=datetime.date(2018, 12, 24),\n",
            "closing_price=106.03),\n",
            "# ...\n",
            "]\n",
            "Empecemos por plantear preguntas sobre estos datos. Por el camino\n",
            "intentaremos observar patrones en lo que estamos haciendo y abstraer\n",
            "algunas herramientas para facilitar la manipulación.\n",
            "Por ejemplo, supongamos que queremos conocer el precio de cierre\n",
            "máximo posible para AAPL. Dividamos esto en pasos:\n",
            "1\n",
            ".\n",
            "Limitarnos a las filas AAPL.\n",
            "2\n",
            ".\n",
            "Coger el \n",
            "closing_price\n",
            " de cada fila.\n",
            "3\n",
            ".\n",
            "Tomar el \n",
            "max\n",
            " de esos precios.\n",
            "Podemos hacer las tres cosas a la vez utilizando una lista de comprensión:\n",
            "max_aapl_price = max(stock_price.closing_price\n",
            "for stock_price in data\n",
            "if stock_price.symbol == \"AAPL\")\n",
            "De forma más general, nos podría interesar conocer el precio de cierre\n",
            "máximo posible para cada acción de nuestro conjunto de datos. Una forma de\n",
            "hacer esto es:\n",
            "1\n",
            ".\n",
            "Crear un \n",
            "dict\n",
            " para mantener controlados los precios máximos\n",
            "(utilizaremos un \n",
            "defaultdict\n",
            " que devuelve menos infinito para\n",
            "valores que faltan, ya que cualquier precio será mayor).2\n",
            ".\n",
            "Iterar nuestros datos, actualizándolos.\n",
            "Este es el código:\n",
            "from collections import defaultdict\n",
            "max_prices: Dict[str, float] = defaultdict(lambda: float(‘-inf’))\n",
            "for sp in data:\n",
            "symbol, closing_price = sp.symbol, sp.closing_price\n",
            "if closing_price > max_prices[symbol]:\n",
            "max_prices[symbol] = closing_price\n",
            "Ahora podemos empezar a pedir cosas más complicadas, como averiguar\n",
            "cuáles son los cambios porcentuales de un día mayor y menor de nuestro\n",
            "conjunto de datos. El cambio porcentual es \n",
            "price_today\n",
            " \n",
            "/\n",
            " \n",
            "price_yesterday\n",
            "-1\n",
            ", lo que significa que necesitamos un modo de asociar el precio de hoy y el\n",
            "de ayer. Una forma es agrupando los precios por símbolo, y después, dentro\n",
            "de cada grupo:\n",
            "1\n",
            ".\n",
            "Ordenar los precios por fecha.\n",
            "2\n",
            ".\n",
            "Utilizar \n",
            "zip\n",
            " para obtener pares (anterior, actual).\n",
            "3\n",
            ".\n",
            "Convertir los pares en nuevas filas de “cambio porcentual”.\n",
            "Empecemos agrupando los precios por símbolo:\n",
            "from typing import List\n",
            "from collections import defaultdict\n",
            "# Recopila los precios por símbolo\n",
            "prices: Dict[str, List[StockPrice]] = defaultdict(list)\n",
            "for sp in data:\n",
            "prices[sp.symbol].append(sp)\n",
            "Como los precios son tuplas, se clasifican por sus campos en orden:\n",
            "primero por símbolo, después por fecha y por último por precio. Esto\n",
            "significa que, si tenemos varios precios, todos con el mismo símbolo, \n",
            "sort\n",
            "los ordenará por fecha (y después por precio, lo que no hace nada, ya que\n",
            "tenemos solo uno por fecha), que es lo que queremos:\n",
            "# Ordena los precios por fechaprices = {symbol: sorted(symbol_prices)\n",
            "for symbol, symbol_prices in prices.items()}\n",
            "Y que podemos utilizar para calcular una secuencia de cambios por día:\n",
            "def pct_change(yesterday: StockPrice, today: StockPrice) -> float:\n",
            "return today.closing_price / yesterday.closing_price–1\n",
            "class DailyChange(NamedTuple):\n",
            "symbol: str\n",
            "date: datetime.date\n",
            "pct_change: float\n",
            "def day_over_day_changes(prices: List[StockPrice]) -> List[DailyChange]:\n",
            "\"\"\"\n",
            "Assumes prices are for one stock and are in order\n",
            "\"\"\"\n",
            "return [DailyChange(symbol=today.symbol,\n",
            "date=today.date,\n",
            "pct_change=pct_change(yesterday, today))\n",
            "for yesterday, today in zip(prices, prices[1:])]\n",
            "Y recopilarlos después todos:\n",
            "all_changes = [change\n",
            "for symbol_prices in prices.values()\n",
            "for change in day_over_day_changes(symbol_prices)]\n",
            "Momento en el cual es fácil encontrar el mayor y el menor:\n",
            "max_change = max(all_changes, key=lambda change: change.pct_change)\n",
            "# ver p. ej. http://news.cnet.com/2100-1001-202143.html\n",
            "assert max_change.symbol == ‘AAPL’\n",
            "assert max_change.date == datetime.date(1997, 8, 6)\n",
            "assert 0.33 < max_change.pct_change < 0.34\n",
            "min_change = min(all_changes, key=lambda change: change.pct_change)\n",
            "# ver p.ej. http://money.cnn.com/2000/09/29/markets/techwrap/\n",
            "assert min_change.symbol == ‚AAPL’\n",
            "assert min_change.date == datetime.date(2000, 9, 29)\n",
            "assert -0.52 < min_change.pct_change < -0.51\n",
            "Ahora se puede utilizar este nuevo conjunto de datos \n",
            "all_changes\n",
            " para\n",
            "averiguar qué mes es el mejor para invertir en acciones tecnológicas.\n",
            "Veremos el cambio diario medio por mes:changes_by_month: List[DailyChange] = {month: [] for month in range(1, 13)}\n",
            "for change in all_changes:\n",
            "changes_by_month[change.date.month].append(change)\n",
            "avg_daily_change = {\n",
            "month: sum(change.pct_change for change in changes) / len(changes)\n",
            "for month, changes in changes_by_month.items()\n",
            "}\n",
            "# Octubre es el mejor mes\n",
            "assert avg_daily_change[10] == max(avg_daily_change.values())\n",
            "Estaremos haciendo este tipo de manipulaciones a lo largo del libro,\n",
            "normalmente sin llamar de una forma demasiado explícita la atención sobre\n",
            "ellas.\n",
            "Redimensionar\n",
            "Muchas técnicas son sensibles a la dimensión de los datos. Por ejemplo,\n",
            "imaginemos que tenemos un conjunto de datos que consiste en las alturas y\n",
            "pesos de cientos de científicos de datos, y que estamos tratando de identificar\n",
            "clusters\n",
            " de tamaños de cuerpos. De forma intuitiva, nos gustaría que los\n",
            "agrupamientos representaran puntos uno al lado del otro, lo que significa que\n",
            "necesitamos una cierta noción de distancia entre puntos. Ya tenemos la\n",
            "función euclidiana \n",
            "distance\n",
            ", de modo que la forma natural de hacer esto\n",
            "podría ser tratar pares (altura, peso) como puntos en un espacio\n",
            "bidimensional. Veamos las personas que aparecen en la tabla 10.1.\n",
            "Tabla 10.1. \n",
            "Alturas y pesos.\n",
            "Persona\n",
            "Altura(pulgadas)\n",
            "Altura (centímetros)\n",
            "Peso (libras)\n",
            "A\n",
            "63\n",
            "160\n",
            "150\n",
            "B\n",
            "67\n",
            "170,2\n",
            "160\n",
            "C\n",
            "70\n",
            "177,8\n",
            "171Si medimos la altura en pulgadas, entonces el vecino más próximo a B es\n",
            "A:\n",
            "from scratch.linear_algebra import distance\n",
            "a_to_b = distance([63, 150], [67, 160])\n",
            "# 10.77\n",
            "a_to_c = distance([63, 150], [70, 171])\n",
            "# 22.14\n",
            "b_to_c = distance([67, 160], [70, 171])\n",
            "# 11.40\n",
            "Pero, si medimos la altura en centímetros, sin embargo el vecino más\n",
            "próximo a B es C:\n",
            "a_to_b = distance([160, 150], [170.2, 160])\n",
            "# 14.28\n",
            "a_to_c = distance([160, 150], [177.8, 171])\n",
            "# 27.53\n",
            "b_to_c = distance([170.2, 160], [177.8, 171])\n",
            "# 13.37\n",
            "Obviamente es un problema el hecho de que cambiar las unidades pueda\n",
            "cambiar así los resultados. Por esta razón, cuando las dimensiones no sean\n",
            "comparables una con otra, redimensionaremos en ocasiones nuestros datos de\n",
            "forma que cada dimensión tenga media 0 y desviación estándar 1. Así nos\n",
            "deshacemos efectivamente de las unidades, convirtiendo cada dimensión en\n",
            "“desviaciones estándares de la media”.\n",
            "Para empezar, tendremos que calcular \n",
            "mean\n",
            " y \n",
            "standard_deviation\n",
            " para\n",
            "cada posición:\n",
            "from typing import Tuple\n",
            "from scratch.linear_algebra import vector_mean\n",
            "from scratch.statistics import standard_deviation\n",
            "def scale(data: List[Vector]) -> Tuple[Vector, Vector]:\n",
            "\"\"\"returns the mean and standard deviation for each position\"\"\"\n",
            "dim = len(data[0])\n",
            "means = vector_mean(data)\n",
            "stdevs = [standard_deviation([vector[i] for vector in data])\n",
            "for i in range(dim)]\n",
            "return means, stdevs\n",
            "vectors = [[-3, -1, 1], [-1, 0, 1], [1, 1, 1]]\n",
            "means, stdevs = scale(vectors)\n",
            "assert means == [-1, 0, 1]\n",
            "assert stdevs == [2, 1, 0]Después podemos emplearlas para crear un nuevo conjunto de datos:\n",
            "def rescale(data: List[Vector]) -> List[Vector]:\n",
            "\"\"\"\n",
            "Rescales the input data so that each position has\n",
            "mean 0 and standard deviation 1. (Leaves a position\n",
            "as is if its standard deviation is 0.)\n",
            "\"\"\"\n",
            "dim = len(data[0])\n",
            "means, stdevs = scale(data)\n",
            "# Hace una copia de cada vector\n",
            "rescaled = [v[:] for v in data]\n",
            "for v in rescaled:\n",
            "for i in range(dim):\n",
            "if stdevs[i] > 0:\n",
            "v[i] = (v[i]–means[i]) / stdevs[i]\n",
            "return rescaled\n",
            "Por supuesto, escribimos una prueba para comprobar que \n",
            "rescale\n",
            " hace lo\n",
            "que pensamos que hace:\n",
            "means, stdevs = scale(rescale(vectors))\n",
            "assert means == [0, 0, 1]\n",
            "assert stdevs == [1, 1, 0]\n",
            "Como siempre, necesitamos aplicar nuestro criterio. Si tomáramos un\n",
            "enorme conjunto de datos de alturas y pesos y lo filtráramos para quedarnos\n",
            "solo con las personas con alturas de entre 69,5 pulgadas y 70,5 pulgadas, es\n",
            "bastante probable (dependiendo de la pregunta que estemos tratando de\n",
            "responder) que la variación restante sea simplemente ruido, y quizá no\n",
            "queramos poner su desviación estándar al mismo nivel que las desviaciones\n",
            "de otras dimensiones.\n",
            "Un inciso: tqdm\n",
            "Con frecuencia, acabaremos haciendo cálculos que requieren mucho\n",
            "tiempo. Cuando estemos haciendo esto, nos gustará saber que estamos\n",
            "haciendo progresos y calcular el tiempo que se supone que tendremos que\n",
            "esperar.Una forma de hacerlo es con la librería \n",
            "tqdm\n",
            ", que genera barras de\n",
            "progreso personalizadas. Lo utilizaremos un poco a lo largo del libro, de\n",
            "modo que aprovechemos la oportunidad que se nos brinda de aprender cómo\n",
            "funciona.\n",
            "Lo primero es instalarlo:\n",
            "python -m pip install tqdm\n",
            "Solo hace falta conocer unas cuantas funciones. La primera es que un\n",
            "iterable envuelto en \n",
            "tqdm.tqdm\n",
            " producirá una barra de progreso:\n",
            "import tqdm\n",
            "for i in tqdm.tqdm(range(100)):\n",
            "# funciona algo lento\n",
            "_ = [random.random() for _ in range(1000000)]\n",
            "Que produce un resultado parecido a este:\n",
            "56%| \n",
            "| 56/100 [00:08<00:06, 6.49it/s]\n",
            "En particular, muestra qué fracción del bucle está terminada (aunque no se\n",
            "puede hacer esto si se utiliza un generador), cuánto tiempo se ha estado\n",
            "ejecutando y cuánto tiempo más espera hacerlo.\n",
            "En este caso (donde simplemente estamos envolviendo una llamada a\n",
            "range\n",
            "), basta con utilizar \n",
            "tqdm.range\n",
            ".\n",
            "También se puede configurar la descripción de la barra de progreso\n",
            "mientras está funcionando. Para ello, hay que capturar el iterador \n",
            "tqdm\n",
            " en una\n",
            "sentencia \n",
            "with\n",
            ":\n",
            "from typing import List\n",
            "def primes_up_to(n: int) -> List[int]:\n",
            "primes = [2]\n",
            "with tqdm.trange(3, n) as t:\n",
            "for i in t:\n",
            "# i es primo si ningún primo menor lo divide\n",
            "i_is_prime = not any(i % p == 0 for p in primes)\n",
            "if i_is_prime:primes.append(i)\n",
            "t.set_description(f\"{len(primes)} primes\")\n",
            "return primes\n",
            "my_primes = primes_up_to(100_000)\n",
            "Esto añade una descripción como la siguiente, con un contador que se\n",
            "actualiza cuando se descubren nuevos primos:\n",
            "5116 primes: 50%| \n",
            "| 49529/99997 [00:03<00:03, 15905.90it/s]\n",
            "Utilizar \n",
            "tqdm\n",
            " puede hacer que el código inspire desconfianza (ya que, a\n",
            "veces, la pantalla se redibuja pésimamente, y otras veces el bucle\n",
            "directamente se colgará). Si envolvemos accidentalmente un bucle \n",
            "tqdm\n",
            "dentro de otro, podrían ocurrir cosas raras. Lo normal es que sus beneficios\n",
            "superen ampliamente estos inconvenientes, así que trataremos de utilizarlo\n",
            "siempre que tengamos entre manos cálculos de ejecución lenta.\n",
            "Reducción de dimensionalidad\n",
            "En ocasiones, las dimensiones “reales” (o útiles) de los datos podrían no\n",
            "corresponder con las dimensiones que tenemos. Por ejemplo, veamos el\n",
            "conjunto de datos representado en la figura 10.6.Figura 10.6. \n",
            "Datos con los ejes “erróneos”.\n",
            "La mayor parte de la variación de los datos parece producirse en una única\n",
            "dimensión, que no corresponde con el eje x o y.\n",
            "Cuando ocurre esto, podemos utilizar una técnica denominada análisis de\n",
            "componentes principales o PCA (\n",
            "Principal Component Analysis\n",
            ") para extraer\n",
            "una o más dimensiones que capturen tanto de la variación de datos como sea\n",
            "posible.\n",
            "Nota:\n",
            " En la práctica, no utilizaríamos esta técnica en un conjunto de datos de\n",
            "tan baja dimensión. Principalmente, la reducción de dimensionalidad es útil\n",
            "cuando el conjunto de datos tiene un gran número de dimensiones y deseamos\n",
            "encontrar un pequeño subconjunto que capture la mayor parte de la variación.\n",
            "Lamentablemente, esta situación es difícil de ilustrar en un libro en formato de\n",
            "dos dimensiones.\n",
            "Como primer paso a dar, tendremos que traducir los datos de modo que\n",
            "cada dimensión tenga media 0:\n",
            "from scratch.linear_algebra import subtract\n",
            "def de_mean(data: List[Vector]) -> List[Vector]:\n",
            "\"\"\"Recenters the data to have mean 0 in every dimension\"\"\"mean = vector_mean(data)\n",
            "return [subtract(vector, mean) for vector in data]\n",
            "(Si no hacemos esto, es probable que nuestras técnicas identifiquen la\n",
            "propia media en lugar de la variación en los datos).\n",
            "La figura 10.7 muestra los datos de ejemplo tras aplicar media 0.\n",
            "Figura 10.7. \n",
            "Datos tras aplicar media 0.\n",
            "Ahora, dada una matriz \n",
            "X\n",
            " con media 0, podemos preguntar cuál es la\n",
            "dirección que captura la mayor varianza en los datos.\n",
            "Específicamente, dada una dirección \n",
            "d\n",
            " (un vector de magnitud 1), cada fila\n",
            "x\n",
            " de la matriz extiende \n",
            "dot(x,\n",
            " \n",
            "d)\n",
            " en la dirección \n",
            "d\n",
            ". Y cada vector no cero \n",
            "w\n",
            "determina una dirección si lo redimensionamos para que tenga una magnitud\n",
            "1:\n",
            "from scratch.linear_algebra import magnitude\n",
            "def direction(w: Vector) -> Vector:\n",
            "mag = magnitude(w)\n",
            "return [w_i / mag for w_i in w]\n",
            "De esta forma, dado un vector no cero \n",
            "w\n",
            ", podemos calcular la varianza denuestro conjunto de datos en la dirección determinada por \n",
            "w\n",
            ":\n",
            "from scratch.linear_algebra import dot\n",
            "def directional_variance(data: List[Vector], w: Vector) -> float:\n",
            "\"\"\"\n",
            "Returns the variance of x in the direction of w\n",
            "\"\"\"\n",
            "w_dir = direction(w)\n",
            "return sum(dot(v, w_dir) ** 2 for v in data)\n",
            "Nos gustaría encontrar la dirección que maximice esta varianza. Podemos\n",
            "hacerlo utilizando el descenso de gradiente, tan pronto como tengamos la\n",
            "función gradiente:\n",
            "def directional_variance_gradient(data: List[Vector], w: Vector) -> Vector:\n",
            "\"\"\"\n",
            "The gradient of directional variance with respect to w\n",
            "\"\"\"\n",
            "w_dir = direction(w)\n",
            "return [sum(2 * dot(v, w_dir) * v[i] for v in data)\n",
            "for i in range(len(w))]\n",
            "Y ahora el principal componente que tenemos es simplemente la dirección\n",
            "que maximiza la función \n",
            "directional_variance\n",
            ":\n",
            "from scratch.gradient_descent import gradient_step\n",
            "def first_principal_component(data: List[Vector],\n",
            "n: int = 100,\n",
            "step_size: float = 0.1) -> Vector:\n",
            "# Inicia con una suposición al azar\n",
            "guess = [1.0 for _ in data[0]]\n",
            "with tqdm.trange(n) as t:\n",
            "for _ in t:\n",
            "dv = directional_variance(data, guess)\n",
            "gradient = directional_variance_gradient(data, guess)\n",
            "guess = gradient_step(guess, gradient, step_size)\n",
            "t.set_description(f\"dv: {dv:.3f}\")\n",
            "return direction(guess)\n",
            "En el conjunto de datos con media 0, esto devuelve la dirección \n",
            "[0.924,\n",
            "0.383]\n",
            ", que parece capturar el eje principal a lo largo del cual varían nuestrosdatos (figura 10.8).\n",
            "Una vez localizada la dirección que es el primer componente principal,\n",
            "podemos proyectar en ella nuestros datos para hallar los valores de dicho\n",
            "componente:\n",
            "from scratch.linear_algebra import scalar_multiply\n",
            "def project(v: Vector, w: Vector) -> Vector:\n",
            "\"\"\"return the projection of v onto the direction w\"\"\"\n",
            "projection_length = dot(v, w)\n",
            "return scalar_multiply(projection_length, w)\n",
            "Figura 10.8. \n",
            "Primer componente principal.\n",
            "Si queremos hallar más componentes, primero eliminamos las\n",
            "proyecciones de los datos:\n",
            "from scratch.linear_algebra import subtract\n",
            "def remove_projection_from_vector(v: Vector, w: Vector) -> Vector:\n",
            "\"\"\"projects v onto w and subtracts the result from v\"\"\"\n",
            "return subtract(v, project(v, w))\n",
            "def remove_projection(data: List[Vector], w: Vector) -> List[Vector]:\n",
            "return [remove_projection_from_vector(v, w) for v in data]\n",
            "Como este conjunto de datos de ejemplo es solo bidimensional, traseliminar el primer componente, lo que queda será, efectivamente,\n",
            "unidimensional (figura 10.9).\n",
            "En este momento, podemos hallar el siguiente componente principal\n",
            "repitiendo el proceso con el resultado de \n",
            "remove_projection\n",
            " (figura 10.10).\n",
            "En un conjunto de datos de muchas dimensiones, podemos encontrar de\n",
            "forma iterativa tantos componentes como queramos:\n",
            "def pca(data: List[Vector], num_components: int) -> List[Vector]:\n",
            "components: List[Vector] = []\n",
            "for _ in range(num_components):\n",
            "component = first_principal_component(data)\n",
            "components.append(component)\n",
            "data = remove_projection(data, component)\n",
            "return components\n",
            "Figura 10.9.\n",
            " Datos tras eliminar el primer componente principal.Figura 10.10.\n",
            " Primeros dos componentes principales.\n",
            "Podemos después transformar nuestros datos en el espacio de menos\n",
            "dimensiones atravesado por los componentes:\n",
            "def transform_vector(v: Vector, components: List[Vector]) -> Vector:\n",
            "return [dot(v, w) for w in components]\n",
            "def transform(data: List[Vector], components: List[Vector]) -> List[Vector]:\n",
            "return [transform_vector(v, components) for v in data]\n",
            "Esta técnica es válida por varias razones. Primero, puede permitirnos\n",
            "limpiar nuestros datos eliminando las dimensiones de ruido y consolidando\n",
            "las dimensiones altamente correlacionadas.\n",
            "Segundo, tras extraer una representación de baja dimensión de nuestros\n",
            "datos, podemos utilizar diversas técnicas que no funcionen tan bien en datos\n",
            "de alta dimensión. Veremos ejemplos de dichas técnicas a lo largo del libro.\n",
            "Al mismo tiempo, mientras esta técnica puede ayudarnos a crear modelos\n",
            "mejores, también puede hacer que esos modelos sean más difíciles de\n",
            "interpretar. Es fácil entender conclusiones como “cada año adicional de\n",
            "experiencia suma una media de 10.000 euros al salario”, pero es mucho más\n",
            "difícil dar sentido a “cada incremento de 0,1 en el tercer componenteprincipal suma una media de 10.000 euros al salario”.\n",
            "Para saber más\n",
            "■\n",
            "Como mencionamos al final del capítulo 9, pandas, en\n",
            "http://pandas.pydata.org/\n",
            ", es probablemente la herramienta\n",
            "principal de Python para limpiar, preparar, manipular y trabajar con\n",
            "datos. Todos los ejemplos que hicimos a mano en este capítulo podrían\n",
            "haberse hecho de un modo mucho más sencillo utilizando pandas.\n",
            "Python for Data Analysis\n",
            " (O’Reilly), de Wes McKinney, es\n",
            "probablemente la mejor manera de aprender pandas.\n",
            "■\n",
            "scikit-learn tiene una amplia variedad de funciones de descomposición\n",
            "de matrices, en \n",
            "https://scikit-\n",
            "learn.org/stable/modules/classes.html#module-\n",
            "sklearn.decomposition\n",
            ", incluyendo PCA.11\n",
            " \n",
            "Machine learning\n",
            "(aprendizaje automático)\n",
            "Siempre estoy dispuesto a aprender, aunque no siempre me gusta que me den lecciones.\n",
            "—Winston Churchill\n",
            "Mucha gente piensa que la ciencia de datos es más que nada aprendizaje\n",
            "automático o \n",
            "machine learning\n",
            ", y que los científicos de datos se pasan el día\n",
            "creando, entrenando y modificando modelos de \n",
            "machine learning\n",
            " (aunque,\n",
            "pensándolo bien, muchas de esas personas no saben ni siquiera lo que es esto\n",
            "realmente). En realidad, lo que hace la ciencia de datos es convertir\n",
            "problemas de empresa en problemas de datos, y recoger, comprender, limpiar\n",
            "y formatear datos, tras de lo cual el aprendizaje automático es casi una\n",
            "anécdota. Puede que lo sea, pero es interesante y esencial, y merece mucho la\n",
            "pena conocerlo para poder hacer ciencia de datos.\n",
            "Modelos\n",
            "Antes de poder hablar de \n",
            "machine learning\n",
            ", tenemos que hablar primero\n",
            "de los modelos.\n",
            "¿Qué es un modelo? No es más que la especificación de una relación\n",
            "matemática (o probabilística) existente entre distintas variables.\n",
            "Por ejemplo, si la idea es recaudar dinero para una red social, sería\n",
            "interesante crear un modelo de negocio (probablemente en una hoja de\n",
            "cálculo) que admitiera entradas como “número de usuarios”, “ingresos de\n",
            "publicidad por usuario” y “número de empleados” y obtuviera el beneficio\n",
            "anual para los siguientes años. Una receta de un libro de cocina conlleva un\n",
            "modelo que relaciona entradas como “número de comensales” y “hambre”\n",
            "con las cantidades de ingredientes necesarias. En las partidas de póker quepueden verse en televisión, la “probabilidad de victoria” de cada jugador se\n",
            "estima en tiempo real basándose en un modelo que tiene en cuenta las cartas\n",
            "que se han levantado hasta el momento y la distribución de cartas de la\n",
            "baraja.\n",
            "Probablemente, el modelo de negocio está basado en sencillas relaciones\n",
            "matemáticas: el beneficio es el ingreso menos el gasto, el ingreso es igual a\n",
            "las unidades vendidas multiplicadas por el precio medio, etc.\n",
            "El modelo de receta se basa casi seguro en el método de prueba y error\n",
            "(alguien fue a una cocina y probó distintas combinaciones de ingredientes\n",
            "hasta que encontró una que le gustó), mientras que el modelo de póker tiene\n",
            "como base la teoría de la probabilidad, las reglas del póker y ciertas\n",
            "suposiciones razonablemente inocuas sobre el proceso aleatorio mediante el\n",
            "cual se reparten las cartas.\n",
            "¿Qué es el \n",
            "machine learning\n",
            "?\n",
            "Cada uno tiene su propia definición exacta, pero utilizaremos \n",
            "machine\n",
            "learning\n",
            " para referirnos a la creación y utilización de modelos que se\n",
            "aprenden a partir de los datos. En otros contextos se podría denominar\n",
            "modelado predictivo o minería de datos, pero nos quedaremos con\n",
            "aprendizaje automático o \n",
            "machine learning\n",
            ". Habitualmente, nuestro objetivo\n",
            "será utilizar datos ya existentes para desarrollar modelos que podamos\n",
            "emplear para predecir resultados diversos con datos nuevos, como por\n",
            "ejemplo:\n",
            "■\n",
            "Si un email es \n",
            "spam\n",
            " o no.\n",
            "■\n",
            "Si una transacción con tarjeta de crédito es fraudulenta.\n",
            "■\n",
            "En qué anuncio es más probable que un comprador haga clic.\n",
            "■\n",
            "Qué equipo de fútbol va a ganar la Champions.\n",
            "Veremos modelos supervisados (en los que hay un conjunto de datos\n",
            "etiquetado con las respuestas correctas de las que aprender) y modelos no\n",
            "supervisados (que no tienen tales etiquetas). Hay otros tipos, comosemisupervisados (en los que solo parte de los datos están etiquetados),\n",
            "modelos \n",
            "online\n",
            " (en los que el modelo necesita ser continuamente ajustado\n",
            "con los datos más recientes) y modelos por refuerzo (en los que, tras realizar\n",
            "una serie de predicciones, el modelo obtiene una señal indicando lo bien que\n",
            "lo hizo), que no trataremos en este libro. Pero, hasta en la situación más\n",
            "simple, hay universos enteros de modelos que podrían describir la relación en\n",
            "la que estamos interesados. En la mayoría de los casos, nosotros mismos\n",
            "elegiremos una familia parametrizada de modelos, y después utilizaremos los\n",
            "datos para aprender parámetros que de algún modo son óptimos.\n",
            "Por ejemplo, podríamos suponer que la altura de una persona es (más o\n",
            "menos) una función lineal de su peso, y utilizar después los datos para saber\n",
            "cuál es esa función lineal. O también podríamos creer que un árbol de\n",
            "decisión es una buena forma de diagnosticar cuáles son las enfermedades que\n",
            "tienen nuestros pacientes y utilizarlo luego para descubrir cuál sería un árbol\n",
            "así “óptimo”. A lo largo del resto del libro, investigaremos distintas familias\n",
            "de modelos que podemos aprender.\n",
            "Pero, antes de poder hacer esto, tenemos que comprender mejor los\n",
            "fundamentos del \n",
            "machine learning\n",
            ". En el resto de este capítulo hablaremos\n",
            "de algunos de estos conceptos básicos, antes de pasar a los modelos\n",
            "propiamente dichos.\n",
            "Sobreajuste y subajuste\n",
            "Un peligro habitual en \n",
            "machine learning\n",
            " es el sobreajuste u \n",
            "overfitting\n",
            "(producir un modelo que funcione bien con los datos con los que se le\n",
            "entrena, pero que generaliza muy mal con datos nuevos). Podría implicar\n",
            "descubrir ruido en los datos. También podría suponer aprender a identificar\n",
            "determinadas entradas en lugar de cualesquiera factores que sean realmente\n",
            "predictivos para el resultado deseado.\n",
            "La otra cara de esto es el subajuste o \n",
            "underfitting\n",
            " (producir un modelo que\n",
            "no funcione bien ni siquiera con los datos de entrenamiento; aunque,\n",
            "normalmente, cuando esto ocurre, uno mismo decide que el modelo no es lo\n",
            "bastante bueno y sigue buscando uno mejor).En la figura 11.1 he ajustado tres polinomios a una muestra de datos (no\n",
            "se preocupe por cómo lo he hecho, llegaremos a ello en capítulos\n",
            "posteriores).\n",
            "La línea horizontal muestra el mejor polinomio ajustado de grado 0 (es\n",
            "decir, constante), que subajusta enormemente los datos de entrenamiento. El\n",
            "mejor polinomio ajustado de grado 9 (es decir, de parámetro 10) pasa\n",
            "exactamente por cada uno de los puntos de datos de entrenamiento, pero lo\n",
            "sobreajusta en gran medida; si tuviéramos que elegir algunos puntos de datos\n",
            "más, muy probablemente los perdería por mucho. Y la línea de grado 1\n",
            "alcanza un buen equilibrio; está bastante cerca de cada punto, y (si estos\n",
            "datos son representativos) la línea estará probablemente cerca también de\n",
            "nuevos puntos de datos.\n",
            "Está claro que los modelos que son demasiado complejos llevan al\n",
            "sobreajuste y no generalizan bien más allá de los datos con los que fueron\n",
            "entrenados. Así que ¿cómo nos aseguramos de que nuestros modelos no son\n",
            "demasiado complejos? La estrategia más básica conlleva utilizar datos\n",
            "diferentes para entrenar y probar el modelo.\n",
            "Figura 11.1. \n",
            "Sobreajuste y subajuste.La forma más sencilla de hacer esto es dividir el conjunto de datos, de\n",
            "forma que (por ejemplo) dos tercios de él se utilicen para entrenar el modelo,\n",
            "después de lo cual medimos el rendimiento del modelo en el tercio restante:\n",
            "import random\n",
            "from typing import TypeVar, List, Tuple\n",
            "X = TypeVar(‘X’)\n",
            "# tipo genérico para representar un punto de\n",
            "datos\n",
            "def split_data(data: List[X], prob: float) -> Tuple[List[X], List[X]]:\n",
            "\"\"\"Split data into fractions [prob, 1–prob]\"\"\"\n",
            "data = data[:]\n",
            "# Hace una copia rápida\n",
            "random.shuffle(data)\n",
            "# porque shuffle modifica la lista.\n",
            "cut = int(len(data) * prob)\n",
            "# Usa prob para hallar un límite\n",
            "return data[:cut],\n",
            "data[cut:]\n",
            "# y divide allí la lista mezclada.\n",
            "data = [n for n in range(1000)]\n",
            "train, test = split_data(data, 0.75)\n",
            "# Las proporciones deberían ser correctas\n",
            "assert len(train) == 750\n",
            "assert len(test) == 250\n",
            "# Y los datos originales deberían preservarse (en un cierto orden)\n",
            "assert sorted(train + test) == data\n",
            "Con frecuencia tendremos pares de variables de entrada y salida. En ese\n",
            "caso, debemos asegurarnos de poner juntos los valores correspondientes en\n",
            "los datos de entrenamiento o en los de prueba:\n",
            "Y = TypeVar(‘Y’)\n",
            "# tipo genérico para representar variables de\n",
            "salida\n",
            "def train_test_split(xs: List[X],\n",
            "ys: List[Y],\n",
            "test_pct: float) -> Tuple[List[X], List[X], List[Y],\n",
            "List[Y]]:\n",
            "# Genera los índices y los divide\n",
            "idxs = [i for i in range(len(xs))]\n",
            "train_idxs, test_idxs = split_data(idxs, 1–test_pct)\n",
            "return ([xs[i] for i in\n",
            "train_idxs],\n",
            "# x_train\n",
            "[xs[i] for i in test_idxs],\n",
            "# x_test\n",
            "[ys[i] for i in train_idxs],\n",
            "# y_train\n",
            "[ys[i] for i in test_idxs])\n",
            "# y_test\n",
            "Como siempre, queremos asegurarnos de que nuestro código funcionebien:\n",
            "xs = [x for x in range(1000)]\n",
            "# xs son 1 ... 1000\n",
            "ys = [2 * x for x in xs]\n",
            "# cada y_i es el doble de x_i\n",
            "x_train, x_test, y_train, y_test = train_test_split(xs, ys, 0.25)\n",
            "# Revisa proporciones correctas\n",
            "assert len(x_train) == len(y_train) == 750\n",
            "assert len(x_test) == len(y_test) == 250\n",
            "# Revisa puntos de datos correspondientes bien emparejados\n",
            "assert all(y == 2 * x for x, y in zip(x_train, y_train))\n",
            "assert all(y == 2 * x for x, y in zip(x_test, y_test))\n",
            "Tras de lo cual se puede hacer algo como:\n",
            "model = SomeKindOfModel()\n",
            "x_train, x_test, y_train, y_test = train_test_split(xs, ys, 0.33)\n",
            "model.train(x_train, y_train)\n",
            "performance = model.test(x_test, y_test)\n",
            "Si el modelo estuviera sobreajustado a los datos de entrenamiento,\n",
            "entonces sería de esperar que funcionara mal en los datos de prueba (que son\n",
            "completamente distintos). Dicho de otro modo, si funciona bien en los datos\n",
            "de prueba, entonces podemos estar más seguros de que está ajustado en lugar\n",
            "de sobreajustado. Sin embargo, hay varias maneras en las que esto puede salir\n",
            "mal.\n",
            "La primera es si hay patrones comunes en los datos de entrenamiento y de\n",
            "prueba que no generalizarían a un conjunto de datos más grande.\n",
            "Por ejemplo, imaginemos que el conjunto de datos que tenemos consiste\n",
            "en actividad de usuario, con una fila por usuario y semana. En tal caso, la\n",
            "mayoría de los usuarios aparecerán en los datos de entrenamiento y en los de\n",
            "prueba, y determinados modelos podrían aprender a identificar usuarios en\n",
            "lugar de descubrir relaciones que impliquen atributos. En realidad, no es una\n",
            "gran preocupación, aunque me ocurrió una vez.\n",
            "Un problema más importante es si se utiliza la separación\n",
            "prueba/entrenamiento no solo para juzgar un modelo, sino también para\n",
            "elegir entre muchos modelos. En ese caso, aunque cada modelo individual\n",
            "pueda no estar sobreajustado, “elegir un modelo que funcione mejor en el\n",
            "conjunto de prueba” es un metaentrenamiento que hace que el conjunto de\n",
            "prueba funcione como un segundo conjunto de entrenamiento (por supuesto,el modelo que funcionó mejor en el conjunto de prueba va a funcionar bien\n",
            "en el de entrenamiento).\n",
            "En una situación como esta, deberíamos dividir los datos en tres partes: un\n",
            "conjunto de entrenamiento para crear modelos, un conjunto de validación\n",
            "para elegir entre modelos entrenados y un conjunto de prueba para juzgar el\n",
            "modelo final.\n",
            "Exactitud\n",
            "Cuando no estoy haciendo ciencia de datos, hago incursiones en medicina.\n",
            "En mi tiempo libre he creado una prueba barata y no invasiva que se le puede\n",
            "dar a un recién nacido y que predice (con más de un 98 % de exactitud) si el\n",
            "recién nacido desarrollará leucemia. Mi abogado me ha convencido de que la\n",
            "prueba no se puede patentar, de modo que compartiré aquí los detalles:\n",
            "predice la leucemia si y solo si el bebé se llama Luke (que suena parecido a\n",
            "“\n",
            "leukemia\n",
            "”, como se dice leucemia en inglés).\n",
            "Como podemos comprobar, esta prueba tiene claramente más del 98 % de\n",
            "precisión. Sin embargo, es increíblemente ridícula, y es también una buena\n",
            "forma de ilustrar la razón por la cual no solemos utilizar el término\n",
            "“exactitud” para medir lo bueno que es un modelo (de clasificación binaria).\n",
            "Supongamos que creamos un modelo para emitir un juicio binario. ¿Es\n",
            "este email \n",
            "spam\n",
            "? ¿Deberíamos contratar a este candidato? ¿Es uno de los\n",
            "viajeros de este avión un terrorista en secreto?\n",
            "Dado un conjunto de datos etiquetados y un modelo predictivo como este,\n",
            "cada punto de datos está incluido en una de cuatro categorías:\n",
            "Verdadero positivo\n",
            "“Este mensaje es \n",
            "spam\n",
            ", y hemos predicho correctamente que lo es”.\n",
            "Falso positivo (error tipo 1)\n",
            "“Este mensaje no es \n",
            "spam\n",
            ", pero hemos predicho que lo es”.\n",
            "Falso negativo (error tipo 2)\n",
            "“Este mensaje es \n",
            "spam\n",
            ", pero hemos predicho que no lo es”.\n",
            "Verdadero negativo“Este mensaje no es \n",
            "spam\n",
            ", y hemos predicho correctamente que no lo es”.\n",
            "A menudo representamos estas categorías como contadores de una matriz\n",
            "de confusión:\n",
            "Es \n",
            "spam\n",
            "No es \n",
            "spam\n",
            "Predice \"es \n",
            "spam\n",
            "\"\n",
            "Verdadero positivo\n",
            "Falso positivo\n",
            "Predice \"no es \n",
            "spam\n",
            "\"\n",
            "Falso negativo\n",
            "Verdadero negativo\n",
            "Veamos cómo encaja mi prueba de la leucemia en esta estructura. En estos\n",
            "días, aproximadamente 5 bebés de cada 1.000 se llaman Luke,\n",
            "1\n",
            " y la\n",
            "prevalencia de la leucemia a lo largo de la vida es más o menos del 1,4 %, es\n",
            "decir, 14 personas de cada 1.000.\n",
            "2\n",
            "Si pensamos que estos factores son independientes y aplicamos mi prueba\n",
            "“Luke viene de leucemia” a un millón de personas, esperaríamos ver una\n",
            "matriz de confusión como esta:\n",
            "Leucemia\n",
            "No leucemia\n",
            "Total\n",
            "\"Luke\"\n",
            "70\n",
            "4.930\n",
            "5.000\n",
            "No \"Luke\"\n",
            "13.930\n",
            "981.070\n",
            "995.000\n",
            "Total\n",
            "14.000\n",
            "986.000\n",
            "1.000.000\n",
            "Podemos entonces utilizar estas matrices para calcular distintas\n",
            "estadísticas sobre el rendimiento de modelos. Por ejemplo, exactitud se\n",
            "define como la fracción de las predicciones correctas:\n",
            "def accuracy(tp: int, fp: int, fn: int, tn: int) -> float:\n",
            "correct = tp + tn\n",
            "total = tp + fp + fn + tn\n",
            "return correct / total\n",
            "assert accuracy(70, 4930, 13930, 981070) == 0.98114Parece un número que impresiona bastante. Pero sin duda no es una buena\n",
            "prueba, lo que significa que probablemente no deberíamos creer demasiado\n",
            "en la exactitud pura y dura.\n",
            "Es habitual mirar la combinación de precisión y recuerdo. La precisión\n",
            "mide lo exactas que fueron nuestras predicciones positivas:\n",
            "def precision(tp: int, fp: int, fn: int, tn: int) -> float:\n",
            "return tp / (tp + fp)\n",
            "assert precision(70, 4930, 13930, 981070) == 0.014\n",
            "Y el recuerdo mide la fracción de los positivos que identificó nuestro\n",
            "modelo:\n",
            "def recall(tp: int, fp: int, fn: int, tn: int) -> float:\n",
            "return tp / (tp + fn)\n",
            "assert recall(70, 4930, 13930, 981070) == 0.005\n",
            "Ambos son números terribles, que reflejan que es un modelo espantoso.\n",
            "En ocasiones, la precisión y el recuerdo se combinan en la puntuación F1\n",
            "(\n",
            "F1 score\n",
            "), que se define como:\n",
            "def f1_score(tp: int, fp: int, fn: int, tn: int) -> float:\n",
            "p = precision(tp, fp, fn, tn)\n",
            "r = recall(tp, fp, fn, tn)\n",
            "return 2 * p * r / (p + r)\n",
            "Esta es la media armónica\n",
            "3\n",
            " de precisión y recuerdo, y se sitúa\n",
            "forzosamente entre ellos. Normalmente, la elección de un modelo implica un\n",
            "término medio entre precisión y recuerdo. Un modelo que predice “sí” en\n",
            "cuanto tiene la más mínima confianza en este resultado tendrá probablemente\n",
            "un elevado recuerdo, pero una precisión baja; un modelo que prediga “sí”\n",
            "solo cuando tenga toda la confianza en que será así es probable que tenga un\n",
            "bajo recuerdo y una elevada precisión.\n",
            "También se puede pensar en esto como en un término medio entre falsos\n",
            "positivos y falsos negativos. Decir “sí” con demasiada frecuencia dará\n",
            "muchos falsos positivos, pero decir “no” proporcionará muchos falsos\n",
            "negativos.Supongamos que hubiera 10 factores de riesgo para la leucemia y que,\n",
            "cuántos más de ellos se tuvieran, más alta sería la probabilidad de padecer la\n",
            "enfermedad. En ese caso podemos imaginar un continuo de pruebas:\n",
            "“predecir leucemia si al menos hay un factor de riesgo”, “predecir leucemia si\n",
            "al menos hay dos factores de riesgo”, etc. A medida que aumenta el umbral,\n",
            "sube la precisión de la prueba (ya que es más probable que las personas con\n",
            "más factores de riesgo desarrollen la enfermedad), y disminuirá el recuerdo\n",
            "de la prueba (ya que cada vez menos posibles sufridores de la enfermedad\n",
            "alcanzarán el umbral). En casos así, elegir el umbral correcto es cuestión de\n",
            "encontrar el término medio adecuado.\n",
            "El término medio entre sesgo y varianza\n",
            "Otra forma de pensar con respecto al problema del sobreajuste es como en\n",
            "un término medio entre sesgo y varianza. Ambas son medidas de lo que\n",
            "ocurriría si hubiera que volver a entrenar nuestro modelo muchas veces en\n",
            "distintos conjuntos de datos de entrenamiento (a partir de la misma población\n",
            "más grande). Por ejemplo, el modelo de grado 0 de la sección anterior\n",
            "“Sobreajuste y subajuste” producirá muchos errores con prácticamente\n",
            "cualquier conjunto de entrenamiento (dibujado a partir de la misma\n",
            "población), lo que significa que tiene un alto sesgo. No obstante, cualesquiera\n",
            "dos conjuntos de entrenamiento aleatoriamente elegidos darían modelos\n",
            "bastante similares (ya que deberían tener valores promedio también bastante\n",
            "similares). De modo que decimos que tiene una varianza baja. El alto sesgo y\n",
            "la baja varianza corresponden normalmente al subajuste.\n",
            "Por otro lado, el modelo de grado 9 encaja perfectamente en el conjunto\n",
            "de entrenamiento. Tiene muy bajo sesgo, pero muy alta varianza (ya que\n",
            "cualesquiera dos conjuntos de entrenamiento darían probablemente lugar a\n",
            "modelos muy diferentes). Esto corresponde al sobreajuste.\n",
            "Pensar en problemas de modelos de este modo puede permitirnos\n",
            "averiguar qué hacer cuando el modelo no funciona tan bien.\n",
            "Si el modelo tiene un elevado sesgo (lo que significa que funciona mal\n",
            "incluso con los datos de entrenamiento), algo que se puede probar es añadirmás funciones. Pasar del modelo de grado 0 de “Sobreajuste y subajuste” al\n",
            "modelo de grado 1 supuso una gran mejora. Si nuestro modelo tiene una alta\n",
            "varianza, se pueden eliminar funciones de forma similar. Pero otra solución\n",
            "es obtener más datos (si se puede).\n",
            "En la figura 11.2, ajustamos un polinomio de grado 9 a muestras de\n",
            "distinto tamaño. El ajuste de modelo basado en 10 puntos de datos está por\n",
            "todas partes, como ya vimos antes. Pero, si entrenamos con 100 puntos de\n",
            "datos, hay mucho menos subajuste.\n",
            "Figura 11.2. \n",
            "Reducir la varianza con más datos.\n",
            "Y el modelo entrenado con 1.000 puntos de datos parece muy similar al\n",
            "modelo de grado 1. Manteniendo la complejidad del modelo constante,\n",
            "cuantos más datos tengamos, más difícil será que haya sobreajuste. Por otro\n",
            "lado, más datos no ayudarán con el sesgo. Si el modelo no utiliza suficientes\n",
            "funciones para capturar uniformidades en los datos, lanzarle más datos no\n",
            "servirá de nada.\n",
            "Extracción y selección de característicasComo ya se ha mencionado, cuando los datos no tienen suficientes\n",
            "características, es probable que el modelo subajuste; y, cuando los datos\n",
            "tienen demasiadas características, es fácil que sobreajuste. Pero ¿qué son las\n",
            "características, y de dónde proceden?\n",
            "Las características son las entradas que le proporcionamos a nuestro\n",
            "modelo.\n",
            "En el caso más sencillo, las características simplemente nos vienen dadas.\n",
            "Si queremos predecir el salario de alguien basándonos en sus años de\n",
            "experiencia, entonces los años de experiencia son la única característica que\n",
            "tenemos (aunque, como ya vimos en el apartado “Sobreajuste y subajuste”,\n",
            "también se podría considerar añadir años de experiencia al cuadrado, al cubo,\n",
            "etc., si ello nos permitiera construir un modelo mejor).\n",
            "Las cosas se ponen más interesantes a medida que los datos se van\n",
            "complicando. Supongamos que intentamos crear un filtro de \n",
            "spam\n",
            " para\n",
            "predecir si un email es basura o no. La mayoría de los modelos no sabrán qué\n",
            "hacer con un email sin depurar, que no es más que una colección de texto.\n",
            "Tendremos que extraer características. Por ejemplo:\n",
            "■\n",
            "¿Contiene el email la palabra viagra?\n",
            "■\n",
            "¿Cuántas veces aparece la letra d?\n",
            "■\n",
            "¿Cuál era el dominio del remitente?\n",
            "La respuesta a la primera pregunta es simplemente sí o no, lo que\n",
            "codificaríamos normalmente como 1 o 0. La segunda es un número. Y la\n",
            "tercera es una elección entre un reducido conjunto de opciones.\n",
            "Prácticamente siempre extraeremos características de nuestros datos que\n",
            "entran en una de estas tres categorías. Es más, los tipos de características que\n",
            "tenemos limitan los tipos de modelos que podemos utilizar.\n",
            "■\n",
            "El clasificador Naive Bayes que crearemos en el capítulo 13 es\n",
            "adecuado para características de tipo sí o no, como la primera pregunta\n",
            "de la lista anterior.\n",
            "■\n",
            "Los modelos de regresión, que estudiaremos en los capítulos 14 y 16,\n",
            "requieren características numéricas (que podrían incluir variables\n",
            "ficticias que son ceros y unos).■\n",
            "Y los árboles de decisión, que veremos en el capítulo 17, pueden\n",
            "admitir datos numéricos o categóricos.\n",
            "Aunque en el ejemplo de filtro de \n",
            "spam\n",
            " vimos formas de crear\n",
            "características, otras veces también veremos maneras de eliminarlas.\n",
            "Por ejemplo, las entradas podrían ser vectores de varios cientos de\n",
            "números. Dependiendo de la situación, podría ser apropiado reducirlos a un\n",
            "puñado de dimensiones importantes (como en la sección “Reducción de la\n",
            "dimensionalidad” del capítulo 10) y utilizar solamente ese pequeño número\n",
            "de características. O podría ser adecuado utilizar una técnica (como la\n",
            "regularización, que veremos en la sección del mismo nombre del capítulo 15)\n",
            "que penaliza los modelos cuantas más características utilizan.\n",
            "¿Cómo elegimos las características? Aquí entra en juego una combinación\n",
            "entre experiencia y conocimientos del sector. Si ha recibido muchos emails,\n",
            "entonces probablemente intuirá que la presencia de determinadas palabras\n",
            "podría ser un buen indicador de \n",
            "spam\n",
            ". Quizá también sea capaz de intuir que\n",
            "el número de letras “d” casi seguro que no es un buen indicador de \n",
            "spam\n",
            ".\n",
            "Pero, en general, siempre habrá que probar distintas cosas, lo que es parte de\n",
            "la diversión.\n",
            "Para saber más\n",
            "■\n",
            "¡Siga leyendo! Los siguientes capítulos hablan de distintas familias de\n",
            "modelos de \n",
            "machine learning\n",
            ".\n",
            "■\n",
            "El curso de \n",
            "machine learning\n",
            " de Coursera, en\n",
            "https://www.coursera.org/learn/machine-learning\n",
            ", es el MOOC\n",
            "original y un buen punto de partida para obtener una profunda\n",
            "comprensión de los fundamentos de \n",
            "machine learning\n",
            ".\n",
            "■\n",
            "The Elements of Statistical Learning\n",
            ", de Jerome H. Friedman, Robert\n",
            "Tibshirani y Trevor Hastle (Springer), es un libro de texto un poco\n",
            "canónico que se puede descargar en línea gratuitamente en\n",
            "https://hastie.su.domains/ElemStatLearn/printings/ESLII_print12.pdf\n",
            "Pero queda avisado: es muy técnico en matemáticas.1\n",
            " \n",
            "https://www.babycenter.com/baby-names-luke-2918.htm\n",
            ".\n",
            "2\n",
            " \n",
            "https://seer.cancer.gov/statfacts/html/leuks.html\n",
            ".\n",
            "3\n",
            " \n",
            "https://es.wikipedia.org/wiki/Media_arm%C3%B3nica\n",
            ".12\n",
            " k vecinos más cercanos\n",
            "Si quieres molestar a tus vecinos, di la verdad sobre ellos.\n",
            "—Pietro Aretino\n",
            "Supongamos que alguien intenta predecir cómo voy a votar en las\n",
            "próximas elecciones. Si ese alguien no sabe nada sobre mí (y dispone de los\n",
            "datos), un planteamiento razonable podría ser ver cómo están pensando votar\n",
            "mis vecinos. Viviendo en Seattle, como yo, la intención de mis vecinos sin\n",
            "duda alguna es votar al candidato demócrata, lo que sugiere que “candidato\n",
            "demócrata” es asimismo una buena suposición para mí.\n",
            "Ahora supongamos que esa persona sabe más sobre mí que solamente\n",
            "geografía; quizá conoce mi edad, mis ingresos, cuántos hijos tengo, etc. En la\n",
            "medida en que mi comportamiento se vea influido (o caracterizado) por esos\n",
            "conocimientos, parece probable que, de entre todas esas dimensiones, ver qué\n",
            "piensan los vecinos que están cerca de mí sea un indicador aún mejor que\n",
            "incluir a todos mis vecinos. Esta es la idea del método de clasificación de\n",
            "vecinos más cercanos.\n",
            "El modelo\n",
            "Vecinos más cercanos es uno de los modelos predictivos más sencillos\n",
            "que hay. No realiza suposiciones matemáticas y no exige ningún tipo de\n",
            "maquinaria pesada. Lo único que requiere es:\n",
            "■\n",
            "Una cierta noción de distancia.\n",
            "■\n",
            "La suposición de que los puntos que están cerca uno de otro son\n",
            "similares.\n",
            "La mayor parte de las técnicas que veremos en este libro tienen en cuenta\n",
            "el conjunto de datos como un todo para descubrir patrones en los datos.Vecinos más cercanos, por otra parte, descuida de forma consciente mucha\n",
            "información, ya que la predicción para cada nuevo punto depende únicamente\n",
            "del montón de puntos más cercanos a él.\n",
            "Es más, probablemente vecinos más cercanos no ayudará a comprender\n",
            "los elementos causantes del fenómeno que se esté observando. Predecir mi\n",
            "voto basándose en el de mis vecinos no dice mucho sobre las causas que me\n",
            "hacen votar como lo hago, mientras que otro modelo alternativo que prediga\n",
            "mi voto basándose en (por ejemplo) mis ingresos y mi estado civil sí podría\n",
            "ayudar a averiguarlas.\n",
            "En situaciones generales, tenemos puntos de datos y el correspondiente\n",
            "conjunto de etiquetas. Las etiquetas podrían ser \n",
            "True\n",
            " y \n",
            "False\n",
            ", indicando que\n",
            "cada entrada satisface una determinada condición, como “¿es \n",
            "spam\n",
            "?”, “¿es\n",
            "venenoso?” o “¿sería divertido de ver?”. O bien podrían ser categorías, como\n",
            "calificaciones de películas (G, PG, PG-13, R, NC-17). También podrían ser\n",
            "los nombres de los candidatos presidenciales o incluso lenguajes de\n",
            "programación favoritos.\n",
            "En nuestro caso, los puntos de datos serán vectores, lo que significa que\n",
            "podemos utilizar la función \n",
            "distance\n",
            " del capítulo 4.\n",
            "Supongamos que elegimos un número \n",
            "k\n",
            ", como 3 o 5. Entonces, cuando\n",
            "queremos clasificar un punto de datos nuevo, encontramos los \n",
            "k\n",
            " puntos más\n",
            "cercanos etiquetados y les dejamos votar en el nuevo resultado.\n",
            "Para ello, necesitaremos una función que cuente votos. Una posibilidad es:\n",
            "from typing import List\n",
            "from collections import Counter\n",
            "def raw_majority_vote(labels: List[str]) -> str:\n",
            "votes = Counter(labels)\n",
            "winner, _ = votes.most_common(1)[0]\n",
            "return winner\n",
            "assert raw_majority_vote([‘a’, ‘b’, ‘c’, ‘b’]) == ‘b’\n",
            "Pero esto no hace nada inteligente con los empates. Por ejemplo,\n",
            "imaginemos que estamos calificando películas y las cinco más cercanas están\n",
            "clasificadas como G, G, PG, PG y R. Vemos que tanto G como PG tienen dos\n",
            "votos. En ese caso, tenemos varias opciones:■\n",
            "Elegir uno de los ganadores aleatoriamente.\n",
            "■\n",
            "Ponderar los votos por distancia y elegir el ganador resultante.\n",
            "■\n",
            "Reducir\n",
            " k \n",
            "hasta encontrar un ganador único.\n",
            "Implementaremos la tercera opción:\n",
            "def majority_vote(labels: List[str]) -> str:\n",
            "\"\"\"Assumes that labels are ordered from nearest to farthest.\"\"\"\n",
            "vote_counts = Counter(labels)\n",
            "winner, winner_count = vote_counts.most_common(1)[0]\n",
            "num_winners = len([count\n",
            "for count in vote_counts.values()\n",
            "if count == winner_count])\n",
            "if num_winners == 1:\n",
            "return winner\n",
            "# ganador único, así que lo devuelve\n",
            "else:\n",
            "return\n",
            "majority_vote(labels[:-1])\n",
            "# prueba de nuevo sin el más lejano\n",
            "# Empate, así que busca los primeros 4, entonces ‘b’\n",
            "assert majority_vote([‘a’, ‘b’, ‘c’, ‘b’, ‘a’]) == ‘b’\n",
            "Este método seguro que terminará funcionando, ya que en el peor de los\n",
            "casos lo iremos reduciendo todo hasta que quede una sola etiqueta, momento\n",
            "en el cual esa es la que gana.\n",
            "Con esta función, es fácil crear un clasificador:\n",
            "from typing import NamedTuple\n",
            "from scratch.linear_algebra import Vector, distance\n",
            "class LabeledPoint(NamedTuple):\n",
            "point: Vector\n",
            "label: str\n",
            "def knn_classify(k: int,\n",
            "labeled_points: List[LabeledPoint],\n",
            "new_point: Vector) -> str:\n",
            "# Ordena los puntos etiquetados de más cercano a más lejano.\n",
            "by_distance = sorted(labeled_points,\n",
            "key=lambda lp: distance(lp.point, new_point))\n",
            "# Halla las etiquetas para los k más cercanos\n",
            "k_nearest_labels = [lp.label for lp in by_distance[:k]]\n",
            "# y les deja votar.\n",
            "return majority_vote(k_nearest_labels)Veamos cómo funciona esto.\n",
            "Ejemplo: el conjunto de datos iris\n",
            "El conjunto de datos iris es una de las bases de \n",
            "machine learning\n",
            ".\n",
            "Contiene un grupo de medidas para 150 flores que representan tres especies\n",
            "de iris. Para cada flor tenemos la longitud y la anchura del pétalo, la longitud\n",
            "del sépalo, además de su especie. Se puede descargar en la página\n",
            "https://archive.ics.uci.edu/ml/datasets/iris\n",
            ".\n",
            "import requests\n",
            "data = requests.get(\n",
            "\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
            ")\n",
            "with open(‘iris.dat’, ‘w’) as f:\n",
            "f.write(data.text)\n",
            "Los datos están separados por comas, con los campos:\n",
            "sepal_length, sepal_width, petal_length, petal_width, class\n",
            "Por ejemplo, la primera fila es algo así:\n",
            "5.1,3.5,1.4,0.2,Iris-setosa\n",
            "En esta sección trataremos de crear un modelo que pueda predecir la clase\n",
            "(es decir, la especie) a partir de las cuatro primeras medidas.\n",
            "Para empezar, carguemos y exploremos los datos. Nuestra función vecinos\n",
            "más cercanos espera un \n",
            "LabeledPoint\n",
            ", de modo que representemos nuestros\n",
            "datos de ese modo:\n",
            "from typing import Dict\n",
            "import csv\n",
            "from collections import defaultdict\n",
            "def parse_iris_row(row: List[str]) -> LabeledPoint:\n",
            "\"\"\"\n",
            "sepal_length, sepal_width, petal_length, petal_width, class\n",
            "\"\"\"\n",
            "measurements = [float(value) for value in row[:-1]]# la clase es p. ej. \"Iris-virginica\"; solo queremos \"virginica\"\n",
            "label = row[-1].split(\"-\")[-1]\n",
            "return LabeledPoint(measurements, label)\n",
            "with open(‘iris.data’) as f:\n",
            "reader = csv.reader(f)\n",
            "iris_data = [parse_iris_row(row) for row in reader]\n",
            "# Agrupamos también solo los puntos por especie/etiqueta para trazarlos\n",
            "points_by_species: Dict[str, List[Vector]] = defaultdict(list)\n",
            "for iris in iris_data:\n",
            "points_by_species[iris.label].append(iris.point)\n",
            "Nos vendría bien trazar las medidas de forma que podamos ver cómo\n",
            "varían por especie. Lamentablemente, son cuatridimensionales, lo que hace\n",
            "que resulten difíciles de representar. Una cosa que podemos hacer es recurrir\n",
            "a los gráficos de dispersión para cada uno de los seis pares de medidas (figura\n",
            "12.1). No explicaré todos los detalles, pero es una buena forma de ilustrar\n",
            "cosas más complicadas que se pueden hacer con matplotlib, por lo que vale la\n",
            "pena estudiarlo:\n",
            "from matplotlib import pyplot as plt\n",
            "metrics = [‘sepal length’, ‘sepal width’, ‘petal length’, ‘petal width’]\n",
            "pairs = [(i, j) for i in range(4) for j in range(4) if i < j]\n",
            "marks = [‘+’, ‘.’, ‘x’]\n",
            "# we have 3 classes, so 3 markers\n",
            "fig, ax = plt.subplots(2, 3)\n",
            "for row in range(2):\n",
            "for col in range(3):\n",
            "i, j = pairs[3 * row + col]\n",
            "ax[row][col].set_title(f\"{metrics[i]} vs {metrics[j]}\", fontsize=8)\n",
            "ax[row][col].set_xticks([])\n",
            "ax[row][col].set_yticks([])\n",
            "for mark, (species, points) in zip(marks, points_by_species.items()):\n",
            "xs = [point[i] for point in points]\n",
            "ys = [point[j] for point in points]\n",
            "ax[row][col].scatter(xs, ys, marker=mark, label=species)\n",
            "ax[-1][-1].legend(loc=’lower right’, prop={‘size’: 6})\n",
            "plt.show()Figura 12.1. \n",
            "Gráficos de dispersión de iris.\n",
            "Si echamos un vistazo a estos gráficos, parece que en realidad las medidas\n",
            "se agrupan por especie. Por ejemplo, mirando solamente la longitud y la\n",
            "anchura del sépalo, probablemente no se podría distinguir entre versicolor y\n",
            "virginica. Pero, en cuanto se añade a la mezcla la longitud y la anchura del\n",
            "pétalo, parece posible predecir la especie basándose en los vecinos más\n",
            "cercanos.\n",
            "Para empezar, dividamos los datos en un conjunto de prueba y otro de\n",
            "entrenamiento:\n",
            "import random\n",
            "from scratch.machine_learning import split_data\n",
            "random.seed(12)\n",
            "iris_train, iris_test = split_data(iris_data, 0.70)\n",
            "assert len(iris_train) == 0.7 * 150\n",
            "assert len(iris_test) == 0.3 * 150\n",
            "El conjunto de entrenamiento será los “vecinos” que utilizaremos para\n",
            "clasificar los puntos del conjunto de prueba. Simplemente tenemos que elegir\n",
            "un valor para \n",
            "k\n",
            ", el número de vecinos que consiguen votar. Demasiado\n",
            "pequeño (pensemos en \n",
            "k\n",
            " = 1), y dejaremos que los valores atípicos (\n",
            "outliers\n",
            ")tengan demasiada influencia; demasiado grande (digamos \n",
            "k\n",
            " = 105), y\n",
            "simplemente predeciremos la clase más común del conjunto de datos.\n",
            "En una aplicación real (y con más datos), podríamos crear un conjunto de\n",
            "validación diferente y emplearlo para elegir \n",
            "k\n",
            ". Aquí utilizaremos \n",
            "k\n",
            " = 5:\n",
            "from typing import Tuple\n",
            "# controla las veces que vemos (predicted, actual)\n",
            "confusion_matrix: Dict[Tuple[str, str], int] = defaultdict(int)\n",
            "num_correct = 0\n",
            "for iris in iris_test:\n",
            "predicted = knn_classify(5, iris_train, iris.point)\n",
            "actual = iris.label\n",
            "if predicted == actual:\n",
            "num_correct += 1\n",
            "confusion_matrix[(predicted, actual)] += 1\n",
            "pct_correct = num_correct / len(iris_test)\n",
            "print(pct_correct, confusion_matrix)\n",
            "En este sencillo conjunto de datos, el modelo predice casi perfectamente.\n",
            "Hay una única versicolor para la que predice virginica, pero por lo demás\n",
            "acierta de pleno.\n",
            "La maldición de la dimensionalidad\n",
            "El algoritmo de \n",
            "k\n",
            " vecinos más cercanos da problemas con muchas\n",
            "dimensiones gracias a la “maldición de la dimensionalidad”, que se reduce al\n",
            "hecho de que los espacios de muchas dimensiones son inmensos. Los puntos\n",
            "en los espacios con muchas dimensiones tienden a no estar en absoluto cerca\n",
            "unos de otros. Una forma de comprobar esto es generando de forma aleatoria\n",
            "pares de puntos en el “cubo unitario” \n",
            "d\n",
            "-dimensional en diversas dimensiones,\n",
            "y calculando las distancias entre ellos.\n",
            "A estas alturas, generar puntos aleatorios ya debería ser algo natural:\n",
            "def random_point(dim: int) -> Vector:\n",
            "return [random.random() for _ in range(dim)]Igual que lo es escribir una función para generar las distancias:\n",
            "def random_distances(dim: int, num_pairs: int) -> List[float]:\n",
            "return [distance(random_point(dim), random_point(dim))\n",
            "for _ in range(num_pairs)]\n",
            "Para cada dimensión de 1 a 100, calcularemos 10.000 distancias, que\n",
            "usaremos para calcular la distancia media entre puntos y la distancia mínima\n",
            "entre puntos en cada dimensión (figura 12.2):\n",
            "import tqdm\n",
            "dimensions = range(1, 101)\n",
            "avg_distances = []\n",
            "min_distances = []\n",
            "random.seed(0)\n",
            "for dim in tqdm.tqdm(dimensions, desc=\"Curse of Dimensionality\"):\n",
            "distances = random_distances(dim, 10000)\n",
            "# 10.000 pares aleatorios\n",
            "avg_distances.append(sum(distances) / 10000)\n",
            "# controla la media\n",
            "min_distances.append(min(distances))\n",
            "# controla la mínima\n",
            "Figura 12.2. \n",
            "La maldición de la dimensionalidad.\n",
            "A medida que aumenta el número de dimensiones, se incrementa también\n",
            "la distancia media entre puntos. Pero lo más problemático es la proporciónentre la distancia más cercana y la distancia media (figura 12.3):\n",
            "min_avg_ratio = [min_dist / avg_dist\n",
            "for min_dist, avg_dist in zip(min_distances, avg_distances)]\n",
            "Figura 12.3. \n",
            "Otra vez la maldición de la dimensionalidad.\n",
            "En conjuntos de datos de pocas dimensiones, los puntos más cercanos\n",
            "tienden a estar mucho más cerca que la media. Pero dos puntos están cerca\n",
            "solo si lo están en cada dimensión, y cada dimensión adicional (incluso\n",
            "aunque sea solo ruido) es otra oportunidad para que cada punto esté más lejos\n",
            "de los demás. Cuando se tienen muchas dimensiones, es probable que los\n",
            "puntos más próximos no estén mucho más cerca que la media, por tanto, que\n",
            "dos puntos estén cerca no significa mucho (a menos que haya mucha\n",
            "estructura en los datos que les haga comportarse como si fueran muy poco\n",
            "dimensionales).\n",
            "Una forma diferente de pensar acerca de este problema tiene que ver con\n",
            "la escasez de espacios de muchas dimensiones.\n",
            "Si elegimos 50 números aleatorios entre 0 y 1, probablemente\n",
            "obtendremos una muestra bastante buena del intervalo de la unidad (figura\n",
            "12.4).Si elegimos 50 puntos aleatorios dentro del cuadrado unitario, tendremos\n",
            "menos cobertura (figura 12.5).\n",
            "Figura 12.4. \n",
            "Cincuenta puntos aleatorios en una sola dimensión.\n",
            "Figura 12.5. \n",
            "Cincuenta puntos aleatorios en dos dimensiones.\n",
            "Y en tres dimensiones, todavía menos (figura 12.6).Figura 12.6. \n",
            "Cincuenta puntos aleatorios en tres dimensiones.\n",
            "matplotlib no crea bien gráficos de cuatro dimensiones, de modo que hasta\n",
            "ahí llegaremos, pero ya se puede verificar que están empezando a haber\n",
            "grandes espacios vacíos sin puntos cerca. En más dimensiones (a menos que\n",
            "obtengamos más datos exponencialmente), esos grandes espacios vacíos\n",
            "representan regiones alejadas de todos los puntos que deseamos utilizar en\n",
            "nuestras predicciones.\n",
            "Así que, si queremos utilizar vecinos más cercanos en muchas\n",
            "dimensiones, probablemente es una buena idea hacer primero algún tipo de\n",
            "reducción de dimensionalidad.\n",
            "Para saber más\n",
            "■\n",
            "scikit-learn tiene muchos modelos de vecinos más cercanos, en\n",
            "https://scikit-learn.org/stable/modules/neighbors.html\n",
            ".13\n",
            " Naive Bayes\n",
            "Está bien ser ingenuo de corazón, pero no serlo de mente.\n",
            "—Anatole France\n",
            "Una red social no es muy buena si la gente no puede conectar. Según esto,\n",
            "DataSciencester tiene una característica muy popular que permite a sus\n",
            "miembros enviar mensajes a otros miembros. Aunque la mayoría de los\n",
            "miembros son ciudadanos responsables que solo envían mensajes agradables\n",
            "del tipo “¿cómo te va?”, hay unos cuantos malandrines que envían correo\n",
            "basura de forma persistente sobre maneras de hacerse rico, productos\n",
            "farmacéuticos sin receta y programas de acreditación en ciencia de datos con\n",
            "ánimo de lucro. Los usuarios han empezado a quejarse, por lo que el\n",
            "vicepresidente de Mensajería le ha pedido que utilice la ciencia de datos para\n",
            "encontrar una manera de filtrar estos mensajes de \n",
            "spam\n",
            ".\n",
            "Un filtro de spam realmente tonto\n",
            "Supongamos un “universo” que consista en recibir un mensaje elegido\n",
            "aleatoriamente del total de posibles mensajes. Digamos que S es el evento “el\n",
            "mensaje es spam” y B el evento “el mensaje contiene la palabra bitcoin”. El\n",
            "teorema de Bayes nos dice que la probabilidad de que el mensaje sea \n",
            "spam\n",
            ",\n",
            "condicionado a que contenga la palabra “bitcoin”, es:\n",
            "P\n",
            "(\n",
            "S\n",
            "|\n",
            "B\n",
            ") = [\n",
            "P\n",
            "(\n",
            "B\n",
            "|\n",
            "S\n",
            ")\n",
            "P\n",
            "(\n",
            "S\n",
            ")]/[\n",
            "P\n",
            "(\n",
            "B\n",
            "|\n",
            "S\n",
            ")\n",
            "P\n",
            "(\n",
            "S\n",
            ") + \n",
            "P\n",
            "(\n",
            "B\n",
            "|¬\n",
            "S\n",
            ")\n",
            "P\n",
            "(¬\n",
            "S\n",
            ")]\n",
            "El numerador es la probabilidad de que un mensaje sea \n",
            "spam\n",
            " y contenga\n",
            "“bitcoin”, mientras que el denominador es solo la probabilidad de que un\n",
            "mensaje contenga “bitcoin”. Por lo tanto, se puede pensar en este cálculo\n",
            "como en la sencilla representación de la proporción de mensajes de bitcoin\n",
            "que son \n",
            "spam\n",
            ".Si tenemos una gran colección de mensajes que sabemos que son \n",
            "spam\n",
            ", y\n",
            "otra gran colección de mensajes que sabemos que no son \n",
            "spam\n",
            ", podemos\n",
            "estimar fácilmente \n",
            "P\n",
            "(\n",
            "B\n",
            "|\n",
            "S\n",
            ") y \n",
            "P\n",
            "(\n",
            "B\n",
            "|¬\n",
            "S\n",
            "). Si seguimos suponiendo que es\n",
            "igualmente probable que un determinado mensaje sea \n",
            "spam\n",
            " o no \n",
            "spam\n",
            " (de\n",
            "forma que \n",
            "P\n",
            "(\n",
            "S\n",
            ") = \n",
            "P\n",
            "(¬\n",
            "S\n",
            ") = 0,5), entonces:\n",
            "P\n",
            "(\n",
            "S\n",
            "|\n",
            "B\n",
            ") = \n",
            "P\n",
            "(\n",
            "B\n",
            "|\n",
            "S\n",
            ")/[\n",
            "P\n",
            "(\n",
            "B\n",
            "|\n",
            "S\n",
            ") + \n",
            "P\n",
            "(\n",
            "B\n",
            "|¬\n",
            "S\n",
            ")\n",
            "Por ejemplo, si el 50 % de los mensajes de \n",
            "spam\n",
            " tienen la palabra\n",
            "“bitcoin”, pero solo el 1 % de los mensajes que no son \n",
            "spam\n",
            " la tienen,\n",
            "entonces la probabilidad de que cualquier email determinado que contenga la\n",
            "palabra “bitcoin” sea \n",
            "spam\n",
            " es:\n",
            "0,5 / (0,5 + 0,01) = 98 %\n",
            "Un filtro de spam más sofisticado\n",
            "Supongamos ahora que tenemos un vocabulario formado por muchas\n",
            "palabras \n",
            "w\n",
            "1\n",
            ", ..., \n",
            "w\n",
            "n\n",
            ". Para llevar esto al reino de la teoría de la probabilidad,\n",
            "denominaremos \n",
            "X\n",
            "i\n",
            " al evento “un mensaje contiene la palabra \n",
            "w\n",
            "i\n",
            "”. Vamos a\n",
            "imaginar que (mediante algún proceso no especificado en este momento)\n",
            "hemos hallado una estimación \n",
            "P\n",
            "(\n",
            "X\n",
            "i\n",
            "|\n",
            "S\n",
            ") para la probabilidad de que un mensaje\n",
            "de \n",
            "spam\n",
            " contenga la palabra \n",
            "i\n",
            "-ésima, y una estimación \n",
            "P\n",
            "(\n",
            "X\n",
            "i\n",
            "|¬\n",
            "S\n",
            ") para la\n",
            "probabilidad de que un mensaje que no sea \n",
            "spam\n",
            " contenga la palabra \n",
            "i\n",
            "-ésima.\n",
            "La clave de Naive Bayes es hacer la (gran) suposición de que las\n",
            "presencias (o ausencias) de cada palabra son independientes una de otra,\n",
            "condicionado todo ello a que un mensaje sea \n",
            "spam\n",
            " o no lo sea.\n",
            "Intuitivamente, esta suposición significa que saber si un determinado mensaje\n",
            "de \n",
            "spam\n",
            " contiene la palabra “bitcoin” no da ninguna información sobre si el\n",
            "mismo mensaje contiene la palabra Rolex. En términos matemáticos, esto\n",
            "significa que:\n",
            "P\n",
            "(\n",
            "X\n",
            "1\n",
            " = \n",
            "x\n",
            "1\n",
            ", ..., \n",
            "X\n",
            "n\n",
            " = \n",
            "x\n",
            "n\n",
            "|\n",
            "S\n",
            ") = \n",
            "P\n",
            "(\n",
            "X\n",
            "1\n",
            " = \n",
            "x\n",
            "1\n",
            "|\n",
            "S\n",
            ") x ... x \n",
            "P\n",
            "(\n",
            "X\n",
            "n\n",
            " = \n",
            "x\n",
            "n\n",
            "|\n",
            "S\n",
            ")Esto es una suposición extrema (hay una razón por la que esta técnica\n",
            "lleva el adjetivo \n",
            "naive,\n",
            " ingenuo, en su nombre). Imaginemos que nuestro\n",
            "vocabulario solo consiste en las palabras “bitcoin” y Rolex, y que la mitad de\n",
            "los mensajes de \n",
            "spam\n",
            " son para “gana bitcoin” y la otra mitad son para\n",
            "“auténtico Rolex”. En este caso, Naive Bayes estima que un mensaje de \n",
            "spam\n",
            "que contiene tanto “bitcoin” como “Rolex” es:\n",
            "P\n",
            "(\n",
            "X\n",
            "1\n",
            " = 1, \n",
            "X\n",
            "2\n",
            " = 1|\n",
            "S\n",
            ") = \n",
            "P\n",
            "(\n",
            "X\n",
            "1\n",
            " = 1|\n",
            "S\n",
            ")\n",
            "P\n",
            "(\n",
            "X\n",
            "2\n",
            " = 1|\n",
            "S\n",
            ") = .5 x .5 = .25\n",
            "Ya que hemos asumido el saber que “bitcoin” y “Rolex” nunca ocurren\n",
            "realmente juntas. A pesar de la falta de realismo de esta suposición, este\n",
            "modelo suele funcionar bien y se ha utilizado desde siempre en filtros de\n",
            "spam\n",
            " reales.\n",
            "El mismo razonamiento del teorema de Bayes que hemos utilizado para\n",
            "nuestro filtro de \n",
            "spam\n",
            " “solo bitcoin” nos dice que podemos calcular la\n",
            "probabilidad de que un mensaje sea \n",
            "spam\n",
            " utilizando la ecuación:\n",
            "P\n",
            "(\n",
            "S\n",
            "|\n",
            "X\n",
            " = \n",
            "x\n",
            ") = \n",
            "P\n",
            "(\n",
            "X\n",
            " = \n",
            "x\n",
            "|\n",
            "S\n",
            ")/[\n",
            "P\n",
            "(\n",
            "X\n",
            " = \n",
            "x\n",
            "|\n",
            "S\n",
            ") + \n",
            "P\n",
            "(\n",
            "X\n",
            " = \n",
            "x\n",
            "|¬\n",
            "S\n",
            ")]\n",
            "La suposición de Naive Bayes nos permite calcular cada una de las\n",
            "probabilidades de la derecha simplemente multiplicando las estimaciones de\n",
            "probabilidad individuales por cada palabra del vocabulario.\n",
            "En la práctica, nos interesará evitar multiplicar muchas probabilidades\n",
            "para no tener un problema llamado \n",
            "underflow\n",
            " (o desbordamiento por\n",
            "defecto), en el que los ordenadores no saben manejar bien números de punto\n",
            "flotante que son demasiado próximos a 0. Recordando de álgebra que log\n",
            "(\n",
            "ab\n",
            ") = log \n",
            "a\n",
            " + log \n",
            "b\n",
            " y que exp ( log \n",
            "x\n",
            ") = x, normalmente calculamos \n",
            "p\n",
            "1\n",
            " * ... *\n",
            "p\n",
            "n\n",
            " como el equivalente (pero que maneja mejor el punto flotante):\n",
            "exp ( log (\n",
            "p\n",
            "1\n",
            ") + ... + log (\n",
            "p\n",
            "n\n",
            "))\n",
            "El único desafío que nos queda viene con las estimaciones para \n",
            "P\n",
            "(\n",
            "X\n",
            "i\n",
            "|\n",
            "S\n",
            ") y\n",
            "P\n",
            "(\n",
            "X\n",
            "i\n",
            "|¬\n",
            "S\n",
            "), las probabilidades de que un mensaje que es \n",
            "spam\n",
            " (o que no es\n",
            "spam\n",
            ") contenga la palabra “\n",
            "w\n",
            "i\n",
            "”. Si tenemos un buen número de mensajes de“entrenamiento” etiquetados como \n",
            "spam\n",
            " y no \n",
            "spam\n",
            ", un obvio primer intento\n",
            "es estimar \n",
            "P\n",
            "(\n",
            "X\n",
            "i\n",
            "|\n",
            "S\n",
            ") simplemente como la fracción de mensajes de \n",
            "spam\n",
            " que\n",
            "contienen la palabra “\n",
            "w\n",
            "i\n",
            "”.\n",
            "Pero esto provoca un gran problema. Supongamos que en nuestro\n",
            "conjunto de entrenamiento la palabra del vocabulario datos solo aparece en\n",
            "mensajes que no son \n",
            "spam\n",
            ". Entonces estimaríamos \n",
            "P\n",
            "(datos|\n",
            "S\n",
            ") = 0. El\n",
            "resultado es que nuestro clasificador Naive Bayes siempre asignaría\n",
            "probabilidad de \n",
            "spam\n",
            " 0 a cualquier mensaje que contuviera la palabra\n",
            "“datos”, incluso a un mensaje como “datos sobre bitcoin gratis y auténticos\n",
            "relojes Rolex”. Para evitar este problema, normalmente empleamos algún\n",
            "tipo de suavizado.\n",
            "En particular, elegiremos un pseudocontador (\n",
            "k\n",
            ") y estimaremos la\n",
            "probabilidad de ver la palabra \n",
            "i\n",
            "-ésima en un mensaje de \n",
            "spam\n",
            " como:\n",
            "P\n",
            "(\n",
            "X\n",
            "i\n",
            "|\n",
            "S\n",
            ") = (\n",
            "k\n",
            " + número de spams que contienen \n",
            "w\n",
            "i\n",
            ")/(2\n",
            "k\n",
            " + número de\n",
            "spams)\n",
            "Hacemos lo mismo para \n",
            "P\n",
            "(\n",
            "X\n",
            "i\n",
            "|¬\n",
            "S\n",
            "). Es decir, cuando calculemos las\n",
            "probabilidades de \n",
            "spam\n",
            " para la palabra \n",
            "i\n",
            "-ésima, supondremos que también\n",
            "vimos \n",
            "k\n",
            " mensajes adicionales que no son \n",
            "spam\n",
            " y que contienen la palabra y \n",
            "k\n",
            "mensajes adicionales que no son \n",
            "spam\n",
            " y que no contienen la palabra.\n",
            "Por ejemplo, si datos aparece en 0/98 mensajes de \n",
            "spam\n",
            ", y si \n",
            "k\n",
            " es 1,\n",
            "estimamos \n",
            "P\n",
            "(datos|\n",
            "S\n",
            ") como 1/100 = 0,01, lo que permite a nuestro\n",
            "clasificador seguir asignando una cierta probabilidad de \n",
            "spam\n",
            " no cero a\n",
            "mensajes que contienen la palabra “datos”.\n",
            "Implementación\n",
            "Ahora que tenemos todas las piezas, debemos montar nuestro clasificador.\n",
            "Primero, creamos una sencilla función con \n",
            "tokenize\n",
            " para separar los\n",
            "mensajes en palabras. Convertiremos antes cada mensaje a minúsculas, y\n",
            "emplearemos después \n",
            "re.findall\n",
            " para extraer “palabras” formadas porletras, números y apóstrofos. Para terminar, utilizamos \n",
            "set\n",
            " para obtener las\n",
            "palabras por separado.\n",
            "from typing import Set\n",
            "import re\n",
            "def tokenize(text: str) -> Set[str]:\n",
            "text = text.lower()\n",
            "# Convierte a minúsculas,\n",
            "all_words = re.findall(\"[a-z0-9’]+\", text)\n",
            "# extrae las palabras y\n",
            "return set(all_words)\n",
            "# elimina duplicados.\n",
            "assert tokenize(\"Data Science is science\") == {\"data\", \"science\", \"is\"}\n",
            "También definiremos un tipo para nuestros datos de entrenamiento:\n",
            "from typing import NamedTuple\n",
            "class Message(NamedTuple):\n",
            "text: str\n",
            "is_spam: bool\n",
            "Como nuestro clasificador tiene que controlar los \n",
            "tokens\n",
            ", contadores y\n",
            "etiquetas en los datos de entrenamiento, le crearemos una clase. Siguiendo el\n",
            "convenio, denominaremos emails “\n",
            "ham\n",
            "” a los mensajes que no son \n",
            "spam\n",
            ".\n",
            "El constructor tomará solo un parámetro, el pseudocontador que se utiliza\n",
            "al calcular las probabilidades. También inicializa un conjunto vacío de\n",
            "tokens\n",
            ", contadores para controlar la frecuencia con la que cada \n",
            "token\n",
            " es visto\n",
            "en mensajes de \n",
            "spam\n",
            " y \n",
            "ham\n",
            ", y contadores de la cantidad de mensajes de \n",
            "spam\n",
            "y \n",
            "ham\n",
            " en los que fue entrenado:\n",
            "from typing import List, Tuple, Dict, Iterable\n",
            "import math\n",
            "from collections import defaultdict\n",
            "class NaiveBayesClassifier:\n",
            "def __init__(self, k: float = 0.5) -> None:\n",
            "self.k = k\n",
            "# factor suavizante\n",
            "self.tokens: Set[str] = set()\n",
            "self.token_spam_counts: Dict[str, int] = defaultdict(int)\n",
            "self.token_ham_counts: Dict[str, int] = defaultdict(int)\n",
            "self.spam_messages = self.ham_messages = 0\n",
            "A continuación, le daremos un método para entrenarlo con un montón demensajes. Primero, aumentamos los contadores de \n",
            "spam_messages\n",
            " y\n",
            "ham_messages\n",
            ". Después, dividimos cada mensaje de texto con \n",
            "tokenize\n",
            " y\n",
            "por cada \n",
            "token\n",
            " incrementamos los \n",
            "token_spam_counts\n",
            " o \n",
            "token_ham_counts\n",
            "según el tipo de mensaje:\n",
            "def train(self, messages: Iterable[Message]) -> None:\n",
            "for message in messages:\n",
            "# Incrementa contadores de mensajes\n",
            "if message.is_spam:\n",
            "self.spam_messages += 1\n",
            "else:\n",
            "self.ham_messages += 1\n",
            "# Incrementa contadores de palabras\n",
            "for token in tokenize(message.text):\n",
            "self.tokens.add(token)\n",
            "if message.is_spam:\n",
            "self.token_spam_counts[token] += 1\n",
            "else:\n",
            "self.token_ham_counts[token] += 1\n",
            "Lo que queremos en última instancia es predecir \n",
            "P\n",
            "(spam | token). Como\n",
            "ya hemos visto antes, para aplicar el teorema de Bayes tenemos que conocer\n",
            "P\n",
            "(token | spam) y \n",
            "P\n",
            "(token | ham) para cada \n",
            "token\n",
            " del vocabulario. De modo\n",
            "que crearemos una función auxiliar “privada” para calcularlos:\n",
            "def _probabilities(self, token: str) -> Tuple[float, float]:\n",
            "\"\"\"returns P(token | spam) and P(token | ham)\"\"\"\n",
            "spam = self.token_spam_counts[token]\n",
            "ham = self.token_ham_counts[token]\n",
            "p_token_spam = (spam + self.k) / (self.spam_messages + 2 * self.k)\n",
            "p_token_ham = (ham + self.k) / (self.ham_messages + 2 * self.k)\n",
            "return p_token_spam, p_token_ham\n",
            "Finalmente, estamos listos para escribir nuestro modelo \n",
            "predict\n",
            ". Como\n",
            "dijimos antes, en lugar de multiplicar muchas probabilidades pequeñas,\n",
            "sumaremos las probabilidades logarítmicas:\n",
            "def predict(self, text: str) -> float:\n",
            "text_tokens = tokenize(text)\n",
            "log_prob_if_spam = log_prob_if_ham = 0.0# Itera por cada palabra de nuestro vocabulario\n",
            "for token in self.tokens:\n",
            "prob_if_spam, prob_if_ham = self._probabilities(token)\n",
            "# Si aparece *token* en el mensaje,\n",
            "# añade la probabilidad logarítmica de verlo\n",
            "if token in text_tokens:\n",
            "log_prob_if_spam += math.log(prob_if_spam)\n",
            "log_prob_if_ham += math.log(prob_if_ham)\n",
            "# En otro caso añade la probabilidad logarítmica de _no_ verlo,\n",
            "# que es log(1 – probabilidad de verlo)\n",
            "else:\n",
            "log_prob_if_spam += math.log(1.0–prob_if_spam)\n",
            "log_prob_if_ham += math.log(1.0–prob_if_ham)\n",
            "prob_if_spam = math.exp(log_prob_if_spam)\n",
            "prob_if_ham = math.exp(log_prob_if_ham)\n",
            "return prob_if_spam / (prob_if_spam + prob_if_ham)\n",
            "Y ya tenemos un clasificador.\n",
            "A probar nuestro modelo\n",
            "Asegurémonos de que nuestro modelo funciona escribiendo para él unas\n",
            "unidades de prueba.\n",
            "messages = [Message(\"spam rules\", is_spam=True),\n",
            "Message(\"ham rules\", is_spam=False),\n",
            "Message(\"hello ham\", is_spam=False)]\n",
            "model = NaiveBayesClassifier(k=0.5)\n",
            "model.train(messages)\n",
            "Primero, veamos si obtuvo correctamente los contadores:\n",
            "assert model.tokens == {\"spam\", \"ham\", \"rules\", \"hello\"}\n",
            "assert model.spam_messages == 1\n",
            "assert model.ham_messages == 2\n",
            "assert model.token_spam_counts == {\"spam\": 1, \"rules\": 1}\n",
            "assert model.token_ham_counts == {\"ham\": 2, \"rules\": 1, \"hello\": 1}\n",
            "Ahora hagamos una predicción. También revisaremos (laboriosamente) a\n",
            "mano nuestra lógica Naive Bayes, y nos aseguraremos de que obtenemos el\n",
            "mismo resultado:text = \"hello spam\"\n",
            "probs_if_spam = [\n",
            "(1 + 0.5) / (1 + 2 * 0.5), # \"spam\" (presente)\n",
            "1–(0 + 0.5) / (1 + 2 * 0.5), # \"ham\" (no presente)\n",
            "1–(1 + 0.5) / (1 + 2 * 0.5), # \"rules\" (no presente)\n",
            "(0 + 0.5) / (1 + 2 * 0.5) # \"hello\" (presente)\n",
            "]\n",
            "probs_if_ham = [\n",
            "(0 + 0.5) / (2 + 2 * 0.5), # \"spam\" (presente)\n",
            "1–(2 + 0.5) / (2 + 2 * 0.5), # \"ham\" (no presente)\n",
            "1–(1 + 0.5) / (2 + 2 * 0.5), # \"rules\" (no presente)\n",
            "(1 + 0.5) / (2 + 2 * 0.5), # \"hello\" (presente)\n",
            "]\n",
            "p_if_spam = math.exp(sum(math.log(p) for p in probs_if_spam))\n",
            "p_if_ham = math.exp(sum(math.log(p) for p in probs_if_ham))\n",
            "# Debería ser como 0,83\n",
            "assert model.predict(text) == p_if_spam / (p_if_spam + p_if_ham)\n",
            "Esta prueba funciona, de modo que parece que nuestro modelo está\n",
            "haciendo lo que pensamos que debe hacer. Si miramos las probabilidades\n",
            "reales, los dos grandes conductores son que nuestro mensaje contiene \n",
            "spam\n",
            "(cosa que hacía nuestro único mensaje \n",
            "spam\n",
            " de entrenamiento) y que no\n",
            "contiene \n",
            "ham\n",
            " (cosa que hacían nuestros dos mensajes \n",
            "ham\n",
            " de entrenamiento).\n",
            "A continuación, probemos con datos de verdad.\n",
            "Utilizar nuestro modelo\n",
            "Un conjunto de datos conocido (aunque algo antiguo) es el recopilatorio\n",
            "público SpamAssassin.\n",
            "1\n",
            " Vamos a consultar los archivos con el prefijo\n",
            "20021010.\n",
            "Este es un fragmento de código que los descargará y descomprimirá en el\n",
            "directorio que elijamos (o bien puede hacerse manualmente):\n",
            "from io import BytesIO\n",
            "# Así podemos tratar bytes como archivo.\n",
            "import requests\n",
            "# Descargar los archivos, que\n",
            "import tarfile\n",
            "# están en formato .tar.bz.\n",
            "BASE_URL = \"https://spamassassin.apache.org/old/publiccorpus\"\n",
            "FILES = [\"20021010_easy_ham.tar.bz2\",\n",
            "\"20021010_hard_ham.tar.bz2\",\"20021010_spam.tar.bz2\"]\n",
            "# Aquí terminarán los datos,\n",
            "# en los subdirectorios /spam, /easy_ham y /hard_ham.\n",
            "# Cambie esto a donde quiera los datos.\n",
            "OUTPUT_DIR = ‘spam_data’\n",
            "for filename in FILES:\n",
            "# Usa requests para obtener el contenido del archivo en cada URL.\n",
            "content = requests.get(f\"{BASE_URL}/{filename}\").content\n",
            "# Envuelve los bytes en memoria para poder usarlos como \"archivo\".\n",
            "fin = BytesIO(content)\n",
            "# Y extrae todos los archivos al dir de salida especificado.\n",
            "with tarfile.open(fileobj=fin, mode=’r:bz2’) as tf:\n",
            "tf.extractall(OUTPUT_DIR)\n",
            "Es posible que la ubicación de los archivos cambie (lo que ocurrió entre la\n",
            "primera y segunda edición de este libro), en cuyo caso ajuste el código\n",
            "adecuadamente.\n",
            "Tras descargar los datos, debería tener tres carpetas: \n",
            "spam\n",
            ", \n",
            "easy_ham\n",
            " y\n",
            "hard_ham\n",
            ". Cada carpeta contiene muchos emails, cada uno de ellos contenido\n",
            "en un solo archivo. Para simplificar de verdad las cosas, solo veremos las\n",
            "líneas del asunto de cada email.\n",
            "¿Cómo identificamos la línea del asunto? Cuando revisamos los archivos,\n",
            "todos parecen empezar por “Subject:” (asunto en inglés). Así que buscaremos\n",
            "eso:\n",
            "import glob, re\n",
            "# modifique la ruta a donde tenga los archivos\n",
            "path = ‘spam_data/*/*’\n",
            "data: List[Message] = []\n",
            "# glob.glob devuelve nombres de archivo que coinciden con la ruta comodín\n",
            "for filename in glob.glob(path):\n",
            "is_spam = \"ham\" not in filename\n",
            "# Hay caracteres sobrantes en los emails; el errors=’ignore’\n",
            "# los salta en lugar de mostrar una excepción.\n",
            "with open(filename, errors=’ignore’) as email_file:\n",
            "for line in email_file:\n",
            "if line.startswith(\"Subject:\"):\n",
            "subject = line.lstrip(\"Subject: \")\n",
            "data.append(Message(subject, is_spam))\n",
            "break\n",
            "# done with this fileAhora podemos dividir los datos en datos de entrenamiento y datos de\n",
            "prueba, así estamos listos para crear un clasificador:\n",
            "import random\n",
            "from scratch.machine_learning import split_data\n",
            "random.seed(0)\n",
            "# justo así obtiene las mismas respuestas que yo\n",
            "train_messages, test_messages = split_data(data, 0.75)\n",
            "model = NaiveBayesClassifier()\n",
            "model.train(train_messages)\n",
            "Generemos algunas predicciones y veamos si funciona nuestro modelo:\n",
            "from collections import Counter\n",
            "predictions = [(message, model.predict(message.text))\n",
            "for message in test_messages]\n",
            "# Supone que spam_probability > 0.5 corresponde a predicción de spam\n",
            "# y cuenta las combinaciones de (actual is_spam, predicted is_spam)\n",
            "confusion_matrix = Counter((message.is_spam, spam_probability > 0.5)\n",
            "for message, spam_probability in predictions)\n",
            "print(confusion_matrix)\n",
            "Esto proporciona 84 verdaderos positivos (\n",
            "spam\n",
            " clasificado como\n",
            "“\n",
            "spam\n",
            "”), 25 falsos positivos (han clasificado como “\n",
            "spam\n",
            "”), 703 verdaderos\n",
            "negativos (\n",
            "ham\n",
            " clasificado como “\n",
            "ham\n",
            "”) y 44 falsos negativos (\n",
            "spam\n",
            "clasificado como “\n",
            "ham\n",
            "”), lo que significa que nuestra precisión es de 84 / (84\n",
            "+ 25) = 77 % y nuestro recuerdo de 84 / (84 + 44) = 65 %, que no son\n",
            "números malos para un modelo tan sencillo (supuestamente saldría mejor si\n",
            "tuviéramos en cuenta algo más que las líneas del asunto).\n",
            "También podemos inspeccionar las entrañas del modelo para ver qué\n",
            "palabras son menos y más indicadoras de \n",
            "spam\n",
            ":\n",
            "def p_spam_given_token(token: str, model: NaiveBayesClassifier) -> float:\n",
            "# Probablemente no habría que usar métodos privados, pero es por una buena\n",
            "causa.\n",
            "prob_if_spam, prob_if_ham = model._probabilities(token)\n",
            "return prob_if_spam / (prob_if_spam + prob_if_ham)\n",
            "words = sorted(model.tokens, key=lambda t: p_spam_given_token(t, model))\n",
            "print(\"spammiest_words\", words[-10:])\n",
            "print(\"hammiest_words\", words[:10])Entre las palabras más indicadoras de \n",
            "spam\n",
            " se encuentran \n",
            "sale\n",
            " (venta),\n",
            "mortgage\n",
            " (hipoteca), \n",
            "money\n",
            " (dinero) y \n",
            "rates\n",
            " (cuotas), mientras que algunas\n",
            "de las palabras más indicadoras de \n",
            "ham\n",
            " son \n",
            "spambayes\n",
            ", \n",
            "users\n",
            " (usuarios), \n",
            "apt\n",
            "y \n",
            "perl\n",
            ". Por lo tanto, esto nos da cierta confianza intuitiva en que nuestro\n",
            "modelo está haciendo básicamente lo que debe hacer.\n",
            "¿Cómo podemos obtener un mejor rendimiento? Una forma obvia podría\n",
            "ser consiguiendo más datos para entrenar el modelo. También hay otras\n",
            "maneras diferentes de mejorar el modelo; estas son algunas posibilidades:\n",
            "■\n",
            "Mirar el contenido del mensaje, no solo el asunto. Hay que tener\n",
            "cuidado con el manejo de los encabezados de los mensajes.\n",
            "■\n",
            "Nuestro clasificador tiene en cuenta cada palabra que aparece en el\n",
            "conjunto de entrenamiento, incluso palabras que solo aparecen una vez.\n",
            "Se puede modificar para que acepte un umbral óptimo \n",
            "min_count\n",
            " e\n",
            "ignore \n",
            "tokens\n",
            " que no aparecen al menos esa cantidad de veces.\n",
            "■\n",
            "El \n",
            "tokenizer\n",
            " no tiene la noción de palabras similares (por ejemplo,\n",
            "cheap\n",
            " y \n",
            "cheapest\n",
            "). Entonces se puede cambiar el clasificador para que\n",
            "admita una función opcional \n",
            "stemmer\n",
            ", que convierte palabras en clases\n",
            "de equivalencia de palabras. Por ejemplo, una función stemmer muy\n",
            "sencilla podría ser:\n",
            "def drop_final_s(word):\n",
            "return re.sub(\"s$\", \"\", word)\n",
            "Crear una buena función stemmer es difícil. La gente suele utilizar el\n",
            "stemmer Porter.\n",
            "2\n",
            "■\n",
            "Aunque nuestras funciones tengan la forma “el mensaje contiene la\n",
            "palabra \n",
            "w\n",
            "i\n",
            "”, no hay razón por la que este tenga que ser el caso. En\n",
            "nuestra implementación, podríamos añadir funciones adicionales como\n",
            "“el mensaje contiene un número” creando \n",
            "tokens\n",
            " falsos como\n",
            "contains:number\n",
            " y modificando el \n",
            "tokenizer\n",
            " para emitirlos cuando\n",
            "corresponda.Para saber más\n",
            "■\n",
            "Los artículos de Paul Graham, “A Plan for Spam” en\n",
            "http://www.paulgraham.com/spam.html\n",
            " y “Better Bayesian\n",
            "Filtering” en (\n",
            "http://www.paulgraham.com/better.html\n",
            ", son\n",
            "interesantes y dan más información sobre las ideas que subyacen tras la\n",
            "creación de filtros de \n",
            "spam\n",
            ".\n",
            "■\n",
            "scikit-learn, en \n",
            "https://scikit-\n",
            "learn.org/stable/modules/naive_bayes.html\n",
            ", contiene un modelo\n",
            "BernoulliNB\n",
            " que implementa el mismo algoritmo Naive Bayes que\n",
            "hemos implementado aquí, además de otras variaciones del modelo.\n",
            "1\n",
            " \n",
            "https://spamassassin.apache.org/old/publiccorpus/\n",
            ".\n",
            "2\n",
            " \n",
            "http://tartarus.org/martin/PorterStemmer/\n",
            ".14\n",
            " Regresión lineal simple\n",
            "El arte, como la moral, consiste en trazar la línea en algún lugar.\n",
            "—G. K. Chesterton\n",
            "En el capítulo 5 utilizamos la función \n",
            "correlation\n",
            " para medir la fuerza\n",
            "de la relación lineal entre dos variables. En la mayoría de las aplicaciones, no\n",
            "basta con saber que existe una relación lineal como esta; queremos\n",
            "comprender la naturaleza de la relación. Aquí es donde empleamos la\n",
            "regresión lineal simple.\n",
            "El modelo\n",
            "Recordemos que estábamos investigando la relación entre el número de\n",
            "amigos de un usuario de DataSciencester y la cantidad de tiempo que el\n",
            "usuario se pasa en el sitio cada día. Supongamos que usted se ha convencido\n",
            "a sí mismo de que tener más amigos hace que la gente se pase más tiempo en\n",
            "el sitio, en lugar de una de las explicaciones alternativas que ya hemos\n",
            "tratado.\n",
            "El vicepresidente de Compromiso le pide que cree un modelo que describa\n",
            "esta relación. Como ha descubierto ya una relación lineal bastante intensa, lo\n",
            "más natural es empezar por un modelo lineal.\n",
            "En particular, podríamos proponer que haya dos constantes \n",
            "α\n",
            " (alfa) y \n",
            "β\n",
            "(beta) como por ejemplo:\n",
            "y\n",
            "i\n",
            " = \n",
            "β\n",
            "x\n",
            "i\n",
            " + \n",
            "α\n",
            " + \n",
            "ε\n",
            "i\n",
            "Donde \n",
            "yi\n",
            " es el número de minutos que el usuario \n",
            "i\n",
            " se pasa en el sitio\n",
            "diariamente, \n",
            "xi\n",
            " es el número de amigos que tiene el usuario \n",
            "i\n",
            ", y \n",
            "ε\n",
            " es un\n",
            "término de error (con suerte, pequeño) que representa el hecho de que hayotros factores no tenidos en cuenta en este sencillo modelo.\n",
            "Suponiendo que hemos determinado tales \n",
            "alpha\n",
            " y \n",
            "beta\n",
            ", hacemos\n",
            "predicciones fácilmente con:\n",
            "def predict(alpha: float, beta: float, x_i: float) -> float:\n",
            "return beta * x_i + alpha\n",
            "¿Cómo elegimos \n",
            "alpha\n",
            " y \n",
            "beta\n",
            "? Pues sea cual sea los que elijamos, nos\n",
            "dan un resultado previsto para cada entrada \n",
            "x_i\n",
            ". Como ya conocemos el\n",
            "resultado real \n",
            "y_i\n",
            ", podemos calcular el error para cada par:\n",
            "def error(alpha: float, beta: float, x_i: float, y_i: float) -> float:\n",
            "\"\"\"\n",
            "The error from predicting beta * x_i + alpha\n",
            "when the actual value is y_i\n",
            "\"\"\"\n",
            "return predict(alpha, beta, x_i)–y_i\n",
            "Lo que realmente nos gustaría saber es el error total sobre el conjunto de\n",
            "datos completo. Pero no queremos solamente sumar los errores (si la\n",
            "predicción para \n",
            "x_1\n",
            " es demasiado alta y para \n",
            "x_2\n",
            " es demasiado baja, los\n",
            "errores podrían anularse mutuamente).\n",
            "Así que, en lugar de ello, sumamos los errores al cuadrado:\n",
            "from scratch.linear_algebra import Vector\n",
            "def sum_of_sqerrors(alpha: float, beta: float, x: Vector, y: Vector) -> float:\n",
            "return sum(error(alpha, beta, x_i, y_i) ** 2\n",
            "for x_i, y_i in zip(x, y))\n",
            "La solución de mínimos cuadrados es elegir los \n",
            "alpha\n",
            " y \n",
            "beta\n",
            " que hagan\n",
            "que \n",
            "sum_of_sqerrors\n",
            " sea lo más pequeña posible.\n",
            "Utilizando el cálculo (o la aburrida álgebra), los \n",
            "alpha\n",
            " y \n",
            "beta\n",
            "minimizadores de errores vienen dados por:\n",
            "from typing import Tuple\n",
            "from scratch.linear_algebra import Vector\n",
            "from scratch.statistics import correlation, standard_deviation, meandef least_squares_fit(x: Vector, y: Vector) -> Tuple[float, float]:\n",
            "\"\"\"\n",
            "Given two vectors x and y,\n",
            "find the least-squares values of alpha and beta\n",
            "\"\"\"\n",
            "beta = correlation(x, y) * standard_deviation(y) / standard_deviation(x)\n",
            "alpha = mean(y)–beta * mean(x)\n",
            "return alpha, beta\n",
            "Sin revisar a fondo las matemáticas exactas, pensemos en la razón por la\n",
            "que esta podría ser una solución razonable. La elección de \n",
            "alpha\n",
            " dice\n",
            "simplemente que, cuando vemos el valor medio de la variable independiente\n",
            "x\n",
            ", predecimos el valor medio de la variable dependiente \n",
            "y\n",
            ".\n",
            "La elección de \n",
            "beta\n",
            " significa que, cuando el valor de entrada aumenta en\n",
            "standard_deviation(x)\n",
            ", la predicción se incrementa entonces en\n",
            "correlation\n",
            " \n",
            "(x,\n",
            " \n",
            "y)\n",
            " \n",
            "*\n",
            " \n",
            "standard_deviation(y)\n",
            ". En el caso en que \n",
            "x\n",
            " e \n",
            "y\n",
            " estén\n",
            "perfectamente correlacionadas, un incremento de una sola desviación\n",
            "estándar en \n",
            "x\n",
            " da como resultado un aumento de una sola desviación estándar\n",
            "de \n",
            "y\n",
            " en la predicción. Cuando están perfectamente anticorrelacionadas, el\n",
            "aumento en \n",
            "x\n",
            " da como resultado una disminución en la predicción. Y, cuando\n",
            "la correlación es 0, \n",
            "beta\n",
            " es 0, lo que significa que los cambios en \n",
            "x\n",
            " no\n",
            "afectan en absoluto a la predicción.\n",
            "Como es habitual, escribimos una rápida prueba para esto:\n",
            "x = [i for i in range(-100, 110, 10)]\n",
            "y = [3 * i–5 for i in x]\n",
            "# Debería hallar que y = 3x–5\n",
            "assert least_squares_fit(x, y) == (-5, 3)\n",
            "Ahora es fácil aplicar esto a los datos sin \n",
            "outliers\n",
            " del capítulo 5:\n",
            "from scratch.statistics import num_friends_good, daily_minutes_good\n",
            "alpha, beta = least_squares_fit(num_friends_good, daily_minutes_good)\n",
            "assert 22.9 < alpha < 23.0\n",
            "assert 0.9 < beta < 0.905\n",
            "Lo que nos da valores de \n",
            "alpha\n",
            " = 22,95 y \n",
            "beta\n",
            " = 0,903. Por tanto, nuestromodelo dice que esperamos que un usuario con \n",
            "n\n",
            " amigos pase 22,95 + \n",
            "n\n",
            " *\n",
            "0,903 minutos en el sitio cada día. Es decir, predecimos que un usuario sin\n",
            "amigos en DataSciencester aún se pasaría unos 23 minutos al día en el sitio.\n",
            "Por cada amigo adicional, esperamos que un usuario se pase casi un minuto\n",
            "más en el sitio cada día.\n",
            "En la figura 14.1 trazamos la línea de predicción para hacernos una idea\n",
            "de lo bien que encaja el modelo en los datos observados.\n",
            "Por supuesto, necesitamos una manera mejor de averiguar lo bien que\n",
            "hemos ajustado los datos que simplemente mirando el gráfico. Un método\n",
            "habitual es el coeficiente de determinación (o R\n",
            "2\n",
            ", pronunciado R cuadrado),\n",
            "que mide la fracción de la variación total en la variable dependiente que es\n",
            "capturada por el modelo:\n",
            "from scratch.statistics import de_mean\n",
            "def total_sum_of_squares(y: Vector) -> float:\n",
            "\"\"\"the total squared variation of y_i’s from their mean\"\"\"\n",
            "return sum(v ** 2 for v in de_mean(y))\n",
            "def r_squared(alpha: float, beta: float, x: Vector, y: Vector) -> float:\n",
            "\"\"\"\n",
            "the fraction of variation in y captured by the model, which equals\n",
            "1–the fraction of variation in y not captured by the model\n",
            "\"\"\"\n",
            "return 1.0–(sum_of_sqerrors(alpha, beta, x, y) /\n",
            "total_sum_of_squares(y))\n",
            "rsq = r_squared(alpha, beta, num_friends_good, daily_minutes_good)\n",
            "assert 0.328 < rsq < 0.330Figura 14.1. \n",
            "Nuestro sencillo modelo lineal.\n",
            "Recordemos que elegimos los \n",
            "alpha\n",
            " y \n",
            "beta\n",
            " que minizaban la suma de los\n",
            "errores de predicción al cuadrado. Un modelo lineal que pudimos haber\n",
            "elegido es “predecir siempre \n",
            "mean(y)\n",
            "” (correspondiendo a \n",
            "alpha\n",
            " = \n",
            "mean(y)\n",
            "y \n",
            "beta\n",
            " = 0), cuya suma de errores al cuadrado es exactamente igual a su suma\n",
            "total de cuadrados. Esto significa un R cuadrado de 0, que indica un modelo\n",
            "que (obviamente, en este caso) no funciona mejor que solamente predecir la\n",
            "media.\n",
            "Sin duda, el modelo de mínimos cuadrados debe ser al menos tan bueno\n",
            "como este, lo que significa que la suma de los errores al cuadrado es como\n",
            "mucho la suma total de cuadrados, es decir, que el R cuadrado debe ser al\n",
            "menos 0. Y la suma de errores al cuadrado debe ser al menos 0, lo que\n",
            "significa que el R cuadrado puede ser como mucho 1.\n",
            "Cuánto más alto sea el número, mejor ajustará nuestro modelo los datos.\n",
            "Aquí calculamos un R cuadrado de 0,329, lo que nos dice que nuestro modelo\n",
            "solo se ajusta más o menos bien a los datos, y que sin duda hay otros factores\n",
            "en juego.Utilizar descenso de gradiente\n",
            "Si escribimos \n",
            "theta\n",
            " \n",
            "=\n",
            " \n",
            "[alpha,\n",
            " \n",
            "beta]\n",
            ", podemos también resolver esto\n",
            "utilizando descenso de gradiente:\n",
            "import random\n",
            "import tqdm\n",
            "from scratch.gradient_descent import gradient_step\n",
            "num_epochs = 10000\n",
            "random.seed(0)\n",
            "guess = [random.random(),\n",
            "random.random()]\n",
            "# selecciona valor aleatorio para\n",
            "empezar\n",
            "learning_rate = 0.00001\n",
            "with tqdm.trange(num_epochs) as t:\n",
            "for _ in t:\n",
            "alpha, beta = guess\n",
            "# Derivada parcial de pérdida con respecto a alpha\n",
            "grad_a = sum(2 * error(alpha, beta, x_i, y_i)\n",
            "for x_i, y_i in zip(num_friends_good,\n",
            "daily_minutes_good))\n",
            "# Derivada parcial de pérdida con respecto a beta\n",
            "grad_b = sum(2 * error(alpha, beta, x_i, y_i) * x_i\n",
            "for x_i, y_i in zip(num_friends_good,\n",
            "daily_minutes_good))\n",
            "# Calcula pérdida para mantener la descripción tqdm\n",
            "loss = sum_of_sqerrors(alpha, beta,\n",
            "num_friends_good, daily_minutes_good)\n",
            "t.set_description(f\"loss: {loss:.3f}\")\n",
            "# Por último, actualiza la conjetura\n",
            "guess = gradient_step(guess, [grad_a, grad_b], -learning_rate)\n",
            "# Deberíamos obtener resultados similares:\n",
            "alpha, beta = guess\n",
            "assert 22.9 < alpha < 23.0\n",
            "assert 0.9 < beta < 0.905\n",
            "Si ejecutamos esto obtendremos los mismos valores para \n",
            "alpha\n",
            " y \n",
            "beta\n",
            "que obtuvimos utilizando la fórmula exacta.\n",
            "Estimación por máxima verosimilitud¿Por qué elegir mínimos cuadrados? Una justificación tiene que ver con la\n",
            "estimación por máxima verosimilitud. Supongamos que tenemos una muestra\n",
            "de datos \n",
            "v\n",
            "1, ..., \n",
            "vn\n",
            " procedente de una distribución que depende de un cierto\n",
            "parámetro desconocido \n",
            "θ\n",
            " (theta):\n",
            "p\n",
            "(\n",
            "v\n",
            "1\n",
            ", ..., \n",
            "v\n",
            "n\n",
            " | \n",
            "θ\n",
            ")\n",
            "Si no conocemos \n",
            "θ\n",
            ", podríamos sentarnos a pensar en esta cantidad como\n",
            "en la verosimilitud de \n",
            "θ\n",
            " dada la muestra:\n",
            "L\n",
            "(\n",
            "θ\n",
            " | \n",
            "v\n",
            "1\n",
            ", ..., \n",
            "v\n",
            "n\n",
            ")\n",
            "Según este enfoque, el parámetro \n",
            "θ\n",
            " más admisible es el valor que\n",
            "maximiza esta función de verosimilitud (es decir, el valor que hace que el\n",
            "dato observado sea el más probable). En el caso de una distribución continua,\n",
            "en la que tenemos una función de distribución de probabilidad en lugar de\n",
            "una función de masa de probabilidad, podemos hacer lo mismo.\n",
            "Volvamos a la regresión. Una suposición que se hace a menudo sobre el\n",
            "modelo de regresión simple es que los errores de regresión se distribuyen\n",
            "normalmente con media 0 y una cierta desviación estándar (conocida) \n",
            "σ\n",
            ". Si es\n",
            "este el caso, entonces la verosimilitud basada en ver un par (\n",
            "x_i\n",
            ", \n",
            "y_i\n",
            ") es:\n",
            "La verosimilitud basada en el conjunto de datos completo es el producto\n",
            "de las verosimilitudes individuales, que es mayor precisamente cuando \n",
            "alpha\n",
            "y \n",
            "beta\n",
            " se eligen para minimizar la suma de errores al cuadrado. Es decir, en\n",
            "este caso (con estas suposiciones), minimizar la suma de errores al cuadrado\n",
            "es equivalente a maximizar la verosimilitud de los datos observados.\n",
            "Para saber más\n",
            "Siga leyendo sobre la regresión múltiple en el capítulo 15.15\n",
            " Regresión múltiple\n",
            "Yo no miro un problema y pongo en él variables que no le afectan.\n",
            "—Bill Parcells\n",
            "Aunque la vicepresidenta está bastante impresionada con su modelo\n",
            "predictivo, ella cree que puede hacerlo mejor. Con ese objetivo, se ha\n",
            "dedicado a recoger datos adicionales: sabe cuántas horas trabaja cada día\n",
            "cada uno de sus usuarios y si tienen un doctorado; naturalmente, quiere\n",
            "utilizar estos datos para mejorar su modelo.\n",
            "Por consiguiente, se le ocurre proponer un modelo lineal con más\n",
            "variables independientes:\n",
            "minutos = \n",
            "α\n",
            " + \n",
            "β\n",
            "1\n",
            "amigos + \n",
            "β\n",
            "2\n",
            "horas de trabajo + \n",
            "β\n",
            "3\n",
            "doctorado + \n",
            "ε\n",
            "Obviamente, el hecho de que un usuario tenga un doctorado no es un\n",
            "número, pero, como ya vimos en el capítulo 11, podemos introducir una\n",
            "variable ficticia que es igual a 1 para usuarios con doctorado y a 0 para los\n",
            "que no lo tienen, y así es igual de numérica que las demás variables.\n",
            "El modelo\n",
            "Recordemos que en el capítulo 14 ajustamos un modelo con esta forma:\n",
            "y\n",
            "i\n",
            " \n",
            "α\n",
            "+\n",
            "β\n",
            "x\n",
            "i\n",
            " \n",
            "ε\n",
            "i\n",
            "Ahora supongamos que cada entrada \n",
            "x\n",
            "i\n",
            " no es solamente un número, sino\n",
            "más bien un vector de \n",
            "k\n",
            " números \n",
            "x\n",
            "i1\n",
            ", ..., \n",
            "x\n",
            "ik\n",
            ". El modelo de regresión múltiple\n",
            "supone que:\n",
            "y\n",
            "i\n",
            "=\n",
            "α β\n",
            "1\n",
            "xi\n",
            "1\n",
            " \n",
            "β\n",
            "k\n",
            "x\n",
            "ik\n",
            " \n",
            "ε\n",
            "iEn la regresión múltiple el vector de parámetros se suele denominar \n",
            "β\n",
            ".\n",
            "Queremos que incluya también el término constante, cosa que podemos\n",
            "conseguir añadiendo una columna de unos a nuestros datos:\n",
            "beta = [alpha, beta_1, ..., beta_k]\n",
            "Y:\n",
            "x_i = [1, x_i1, ..., x_ik]\n",
            "Entonces nuestro modelo queda así:\n",
            "from scratch.linear_algebra import dot, Vector\n",
            "def predict(x: Vector, beta: Vector) -> float:\n",
            "\"\"\"assumes that the first element of x is 1\"\"\"\n",
            "return dot(x, beta)\n",
            "En este caso en particular, nuestra variable independiente \n",
            "x\n",
            " será una lista\n",
            "de vectores, cada uno de los cuales tiene este aspecto:\n",
            "[1,\n",
            "# término constante\n",
            "49,\n",
            "# número de amigos\n",
            "4,\n",
            "# horas de trabajo al día\n",
            "0]\n",
            "# no tiene doctorado\n",
            "Otros supuestos del modelo de mínimos\n",
            "cuadrados\n",
            "Hay un par de supuestos adicionales necesarios para que este modelo (y\n",
            "nuestra solución) tenga sentido.\n",
            "El primero es que las columnas de \n",
            "x\n",
            " son linealmente independientes (es\n",
            "decir, que no hay forma de escribir cualquiera de ellas como una suma\n",
            "ponderada de algunas de las otras). Si este supuesto falla, es imposible\n",
            "estimar \n",
            "beta\n",
            ". Para ver esto en una situación extrema, imaginemos que\n",
            "tuviéramos en nuestros datos un campo adicional \n",
            "num_acquaintances\n",
            " que,\n",
            "para cada usuario, fuera exactamente igual a \n",
            "num_friends\n",
            ".\n",
            "Después, empezando con cualquier \n",
            "beta\n",
            ", si sumamos cualquier número alcoeficiente \n",
            "num_friends\n",
            " y restamos ese mismo número al coeficiente\n",
            "num_acquaintances\n",
            ", las predicciones del modelo no cambiarán, lo que\n",
            "significa que no hay forma de encontrar el coeficiente para \n",
            "num_friends\n",
            "(normalmente, los incumplimientos de este supuesto no serán tan obvios).\n",
            "El segundo supuesto importante es que las columnas de \n",
            "x\n",
            " no están todas\n",
            "correlacionadas con los errores ε. Si este no es el caso, nuestras estimaciones\n",
            "de \n",
            "beta\n",
            " serán sistemáticamente erróneas. Por ejemplo, en el capítulo 14\n",
            "creamos un modelo que predecía que cada amigo adicional estaba asociado a\n",
            "0,90 minutos diarios extra en el sitio. Supongamos que es también el caso\n",
            "que:\n",
            "■\n",
            "La gente que trabaja más horas se pasa menos tiempo en el sitio.\n",
            "■\n",
            "La gente con más amigos tiende a trabajar más horas.\n",
            "Es decir, imaginemos que el modelo “real” es:\n",
            "minutos =\n",
            "α\n",
            " + \n",
            "β\n",
            "1\n",
            "amigos + \n",
            "β\n",
            "2\n",
            "horas de trabajo + \n",
            "ε\n",
            "Donde \n",
            "β\n",
            "2\n",
            " es negativo, y que las horas de trabajo y los amigos están\n",
            "positivamente correlacionados. En ese caso, cuando minimicemos los errores\n",
            "del modelo de única variable:\n",
            "minutos = \n",
            "α\n",
            " + \n",
            "β\n",
            "1\n",
            "amigos + \n",
            "ε\n",
            "Subestimaremos \n",
            "β\n",
            "1\n",
            ".\n",
            "Pensemos en lo que ocurriría si hiciéramos predicciones utilizando el\n",
            "modelo de única variable con el valor “real” de \n",
            "β\n",
            "1 (es decir, el valor que se\n",
            "obtiene de minimizar los errores de lo que llamamos el modelo “real”). Las\n",
            "predicciones tenderían a ser excesivamente grandes para usuarios que\n",
            "trabajan muchas horas y un poco demasiado grandes para los que trabajan\n",
            "pocas horas, porque \n",
            "β\n",
            "2 < 0 y “olvidamos” incluirlo. El hecho de que las horas\n",
            "de trabajo estén positivamente correlacionadas con el número de amigos\n",
            "significa que las predicciones tienden a ser excesivamente grandes para los\n",
            "usuarios con muchos amigos, y solo ligeramente demasiado grandes parausuarios con pocos amigos.\n",
            "El resultado es que podemos reducir los errores (en el modelo de única\n",
            "variable) disminuyendo nuestra estimación de \n",
            "β\n",
            "1\n",
            ", lo que significa que la \n",
            "β\n",
            "1\n",
            "minimizadora de errores es más pequeña que el valor “real”. Es decir, en este\n",
            "caso la solución de mínimos cuadrados de única variable tiende a subestimar\n",
            "β\n",
            "1\n",
            ". Además, en general, siempre que las variables independientes estén\n",
            "correlacionadas con errores como este, nuestra solución de mínimos\n",
            "cuadrados nos dará una estimación sesgada de \n",
            "β\n",
            "1\n",
            ".\n",
            "Ajustar el modelo\n",
            "Como hicimos en el modelo lineal simple, elegiremos \n",
            "beta\n",
            " para\n",
            "minimizar la suma de errores cuadrados. Hallar una solución exacta\n",
            "manualmente no es sencillo, lo que significa que tendremos que utilizar\n",
            "descenso de gradiente. De nuevo, nos interesará minimizar la suma de los\n",
            "errores cuadrados. La función de error es casi idéntica a la que empleamos en\n",
            "el capítulo 14, salvo porque, en lugar de esperar parámetros \n",
            "[alpha,\n",
            " \n",
            "beta]\n",
            ",\n",
            "requerirá un vector de longitud arbitraria:\n",
            "from typing import List\n",
            "def error(x: Vector, y: float, beta: Vector) -> float:\n",
            "return predict(x, beta)–y\n",
            "def squared_error(x: Vector, y: float, beta: Vector) -> float:\n",
            "return error(x, y, beta) ** 2\n",
            "x = [1, 2, 3]\n",
            "y = 30\n",
            "beta = [4, 4, 4]\n",
            "# así la predicción = 4 + 8 + 12 = 24\n",
            "assert error(x, y, beta) == -6\n",
            "assert squared_error(x, y, beta) == 36\n",
            "Sabiendo cálculo, es fácil calcular el gradiente:\n",
            "def sqerror_gradient(x: Vector, y: float, beta: Vector) -> Vector:\n",
            "err = error(x, y, beta)\n",
            "return [2 * err * x_i for x_i in x]\n",
            "assert sqerror_gradient(x, y, beta) == [-12, -24, -36]Si no, habrá que aceptar mi palabra.\n",
            "En este momento, estamos preparados para encontrar la \n",
            "beta\n",
            " óptima\n",
            "utilizando descenso de gradiente. Escribamos primero una función\n",
            "least_squares_fit\n",
            " que pueda funcionar con cualquier conjunto de datos:\n",
            "import random\n",
            "import tqdm\n",
            "from scratch.linear_algebra import vector_mean\n",
            "from scratch.gradient_descent import gradient_step\n",
            "def least_squares_fit(xs: List[Vector],\n",
            "ys: List[float],\n",
            "learning_rate: float = 0.001,\n",
            "num_steps: int = 1000,\n",
            "batch_size: int = 1) -> Vector:\n",
            "\"\"\"\n",
            "Find the beta that minimizes the sum of squared errors\n",
            "assuming the model y = dot(x, beta).\n",
            "\"\"\"\n",
            "# Empieza con una conjetura aleatoria\n",
            "guess = [random.random() for _ in xs[0]]\n",
            "for _ in tqdm.trange(num_steps, desc=\"least squares fit\"):\n",
            "for start in range(0, len(xs), batch_size):\n",
            "batch_xs = xs[start:start+batch_size]\n",
            "batch_ys = ys[start:start+batch_size]\n",
            "gradient = vector_mean([sqerror_gradient(x, y, guess)\n",
            "for x, y in zip(batch_xs, batch_ys)])\n",
            "guess = gradient_step(guess, gradient, -learning_rate)\n",
            "return guess\n",
            "Entonces podemos aplicarla a nuestros datos:\n",
            "from scratch.statistics import daily_minutes_good\n",
            "from scratch.gradient_descent import gradient_step\n",
            "random.seed(0)\n",
            "# Usé prueba y error para elegir num_iters y step_size.\n",
            "# Esto funcionará un rato.\n",
            "learning_rate = 0.001\n",
            "beta = least_squares_fit(inputs, daily_minutes_good, learning_rate, 5000, 25)\n",
            "assert 30.50 < beta[0] < 30.70\n",
            "# constante\n",
            "assert 0.96 < beta[1] < 1.00\n",
            "# núm amigos\n",
            "assert -1.89 < beta[2] < -1.85\n",
            "# horas trabajo al día\n",
            "assert 0.91 < beta[3] < 0.94\n",
            "# doctoradoEn la práctica, no estimaríamos una regresión lineal utilizando descenso\n",
            "de gradiente; se obtendrían los coeficientes exactos empleando técnicas de\n",
            "álgebra lineal que están más allá del alcance de este libro. Si lo hiciéramos,\n",
            "daríamos con la ecuación:\n",
            "minutos = 30 , 58 + 0 , 972 amigos – 1 , 87 horas de trabajo + 0 , 923\n",
            "doctorados\n",
            "Que se acerca bastante a lo que hemos descubierto.\n",
            "Interpretar el modelo\n",
            "Hay que pensar que los coeficientes del modelo representan estimaciones\n",
            "del tipo “siendo todo lo demás igual” de los impactos que tiene cada factor.\n",
            "Siendo todo lo demás igual, cada amigo adicional corresponde con un minuto\n",
            "extra pasado cada día en el sitio. Siendo todo lo demás igual, cada hora\n",
            "adicional del día de trabajo de un usuario corresponde con unos dos minutos\n",
            "menos pasados cada día en el sitio. Siendo todo lo demás igual, tener un\n",
            "doctorado se asocia a pasar un minuto más cada día en el sitio.\n",
            "Lo que no nos dice (directamente) es nada sobre las interacciones entre las\n",
            "variables. Es posible que el efecto de las horas de trabajo sea diferente en\n",
            "gente con muchos amigos que en gente con pocos. Este modelo no captura\n",
            "eso. Una forma de manejar esta situación es introducir una nueva variable: el\n",
            "producto de “amigos” y “horas de trabajo”. Esto permite sin duda al\n",
            "coeficiente de “horas de trabajo” aumentar (o disminuir) a medida que el\n",
            "número de amigos se incrementa.\n",
            "También es posible que cuantos más amigos se tengan, más tiempo se\n",
            "pase en el sitio hasta un cierto punto, tras el cual aún más amigos hace que se\n",
            "pase menos tiempo en el sitio (¿quizá con demasiados amigos la experiencia\n",
            "es demasiado abrumadora?). Podríamos intentar capturar esto en nuestro\n",
            "modelo añadiendo otra variable que es el cuadrado del número de amigos.\n",
            "En cuanto empezamos a añadir variables, tenemos que preocuparnos de si\n",
            "sus coeficientes “importan”. No hay límites en las cantidades de productos,logaritmos, cuadrados y potencias que podemos añadir.\n",
            "Bondad de ajuste\n",
            "De nuevo podemos echar un vistazo al R cuadrado:\n",
            "from scratch.simple_linear_regression import total_sum_of_squares\n",
            "def multiple_r_squared(xs: List[Vector], ys: Vector, beta: Vector) -> float:\n",
            "sum_of_squared_errors = sum(error(x, y, beta) ** 2\n",
            "for x, y in zip(xs, ys))\n",
            "return 1.0–sum_of_squared_errors / total_sum_of_squares(ys)\n",
            "Que ha aumentado ahora a 0,68:\n",
            "assert 0.67 < multiple_r_squared(inputs, daily_minutes_good, beta) < 0.68\n",
            "Debemos recordar, sin embargo, que añadir nuevas variables a una\n",
            "regresión aumentará necesariamente el R cuadrado. Después de todo, el\n",
            "modelo de regresión simple no es más que el caso especial del modelo de\n",
            "regresión múltiple, en el que los coeficientes de “horas de trabajo” y\n",
            "“doctorado” son ambos iguales a 0. El modelo de regresión múltiple óptimo\n",
            "tendrá obligadamente un error al menos tan pequeño como ese.\n",
            "Debido a esto, en una regresión múltiple también tenemos que mirar los\n",
            "errores estándares de los coeficientes, que miden lo seguros que estamos de\n",
            "nuestras estimaciones de cada \n",
            "β\n",
            "1\n",
            ". La regresión, como un todo, puede ajustar\n",
            "muy bien nuestros datos, pero, si algunas de las variables independientes\n",
            "están correlacionadas (o son irrelevantes), sus coeficientes podrían no\n",
            "significar mucho.\n",
            "El enfoque habitual para medir estos errores empieza con otro supuesto:\n",
            "que los errores ε\n",
            "i\n",
            " son variables aleatorias normales e independientes con\n",
            "media 0 y una cierta desviación estándar (desconocida) \n",
            "σ\n",
            ". En ese caso,\n",
            "nosotros (o, lo más probable, nuestro software estadístico) podemos utilizar\n",
            "álgebra lineal para encontrar el error estándar de cada coeficiente. Cuanto\n",
            "más grande sea, menos seguro está nuestro modelo de ese coeficiente.\n",
            "Lamentablemente, no estamos preparados para este tipo de álgebra linealdesde cero.\n",
            "Digresión: el bootstrap\n",
            "Supongamos que tenemos una muestra de \n",
            "n\n",
            " puntos de datos, generados\n",
            "por una cierta distribución (desconocida para nosotros):\n",
            "data = get_sample(num_points=n)\n",
            "En el capítulo 5, escribimos una función que podía calcular la \n",
            "median\n",
            " de\n",
            "la muestra, que podemos utilizar como estimación de la mediana de la propia\n",
            "distribución.\n",
            "Pero ¿hasta qué punto podemos estar seguros de nuestra estimación? Si\n",
            "todos los puntos de datos de la muestra están muy cerca de 100, entonces\n",
            "parece probable que la mediana real esté cerca de 100. Si aproximadamente\n",
            "la mitad de los puntos de datos de la muestra está cerca de 0 y la otra mitad\n",
            "está cerca de 200, entonces no podemos estar tan seguros de la mediana.\n",
            "Si pudiéramos obtener repetidamente nuevas muestras, podríamos calcular\n",
            "las medianas de todas esas muestras y mirar su distribución. Pero con\n",
            "frecuencia no es posible. En ese caso, sí se puede aplicar \n",
            "bootstrap\n",
            " a nuevos\n",
            "conjuntos de datos seleccionando \n",
            "n\n",
            " puntos de datos con reemplazo de\n",
            "nuestros datos. Después, podemos calcular las medianas de esos conjuntos de\n",
            "datos sintéticos:\n",
            "from typing import TypeVar, Callable\n",
            "X = TypeVar(‘X’)\n",
            "# Tipo genérico para datos\n",
            "Stat = TypeVar(‘Stat’)\n",
            "# Tipo genérico para \"estadística\"\n",
            "def bootstrap_sample(data: List[X]) -> List[X]:\n",
            "\"\"\"randomly samples len(data) elements with replacement\"\"\"\n",
            "return [random.choice(data) for _ in data]\n",
            "def bootstrap_statistic(data: List[X],\n",
            "stats_fn: Callable[[List[X]], Stat],\n",
            "num_samples: int) -> List[Stat]:\n",
            "\"\"\"evaluates stats_fn on num_samples bootstrap samples from data\"\"\"\n",
            "return [stats_fn(bootstrap_sample(data)) for _ in range(num_samples)]\n",
            "Por ejemplo, consideremos los dos conjuntos de datos siguientes:# 101 puntos todos muy cerca de 100\n",
            "close_to_100 = [99.5 + random.random() for _ in range(101)]\n",
            "# 101 puntos, 50 de ellos cerca de 0, 50 de ellos cerca de 200\n",
            "far_from_100 = ([99.5 + random.random()] +\n",
            "[random.random() for _ in range(50)] +\n",
            "[200 + random.random() for _ in range(50)])\n",
            "Si calculamos las \n",
            "median\n",
            " de los dos conjuntos de datos, ambas estarán\n",
            "muy cerca de 100. Sin embargo, si miramos:\n",
            "from scratch.statistics import median, standard_deviation\n",
            "medians_close = bootstrap_statistic(close_to_100, median, 100)\n",
            "Veremos en su mayoría números realmente cercanos a 100. Pero si lo que\n",
            "miramos es:\n",
            "medians_far = bootstrap_statistic(far_from_100, median, 100)\n",
            "Veremos muchos números cercanos a 0 y otros muchos cercanos a 200.\n",
            "La \n",
            "standard_deviation\n",
            " del primer conjunto de medianas está cerca de 0,\n",
            "mientras que la del segundo conjunto de medianas está cerca de 100:\n",
            "assert standard_deviation(medians_close) < 1\n",
            "assert standard_deviation(medians_far) > 90\n",
            "(Este caso extremo sería bastante fácil de averiguar manualmente\n",
            "inspeccionando los datos, pero en general eso no suele ocurrir).\n",
            "Errores estándares de coeficientes de regresión\n",
            "Podemos seguir el mismo sistema para estimar los errores estándares de\n",
            "nuestros coeficientes de regresión. Tomamos repetidamente una\n",
            "bootstrap_sample\n",
            " de nuestros datos y estimamos la \n",
            "beta\n",
            " basándonos en esa\n",
            "muestra. Si el coeficiente correspondiente a una de las variables\n",
            "independientes (digamos, \n",
            "num_friends\n",
            ") no varía mucho a lo largo de las\n",
            "muestras, entonces podemos estar seguros de que nuestra estimación esrelativamente ajustada. Si el coeficiente varía mucho a lo largo de las\n",
            "muestras, no podemos estar tan seguros entonces de nuestra estimación.\n",
            "La única sutileza es que, antes de tomar las muestras, tendremos que\n",
            "empaquetar con \n",
            "zip\n",
            " nuestros datos \n",
            "x\n",
            " e \n",
            "y\n",
            " para asegurarnos de que los valores\n",
            "correspondientes de las variables independientes y dependientes estén juntos\n",
            "en la muestra. Esto significa que \n",
            "bootstrap_sample\n",
            " devolverá una lista de\n",
            "pares (\n",
            "x_i\n",
            ", \n",
            "y_i\n",
            "), que tendremos que volver a reformular como \n",
            "x_sample\n",
            " e\n",
            "y_sample\n",
            ":\n",
            "from typing import Tuple\n",
            "import datetime\n",
            "def estimate_sample_beta(pairs: List[Tuple[Vector, float]]):\n",
            "x_sample = [x for x, _ in pairs]\n",
            "y_sample = [y for _, y in pairs]\n",
            "beta = least_squares_fit(x_sample, y_sample, learning_rate, 5000, 25)\n",
            "print(\"bootstrap sample\", beta)\n",
            "return beta\n",
            "random.seed(0)\n",
            "# así obtiene los mismos datos que yo\n",
            "# ¡Esto tardará un par de minutos!\n",
            "bootstrap_betas = bootstrap_statistic(list(zip(inputs, daily_minutes_good)),\n",
            "estimate_sample_beta,\n",
            "100)\n",
            "Después, podemos estimar la desviación estándar de cada coeficiente:\n",
            "bootstrap_standard_errors = [\n",
            "standard_deviation([beta[i] for beta in bootstrap_betas])\n",
            "for i in range(4)]\n",
            "print(bootstrap_standard_errors)\n",
            "# [1.272,\n",
            "# término constante,\n",
            "error real = 1.19\n",
            "# 0.103,\n",
            "# num_friends,\n",
            "error real = 0.080\n",
            "# 0.155,\n",
            "# work_hours,\n",
            "error real = 0.127\n",
            "# 1.249]\n",
            "# doctorado,\n",
            "error real = 0.998\n",
            "(Obtendríamos mejores estimaciones si recogiéramos más de 100\n",
            "muestras y utilizáramos más de 5.000 iteraciones para estimar cada \n",
            "beta\n",
            ",\n",
            "pero no tenemos todo el día).\n",
            "Podemos utilizar estas estimaciones para probar hipótesis como “¿es \n",
            "β\n",
            "i\n",
            "igual a 0?”. Bajo la hipótesis nula \n",
            "β\n",
            "i\n",
            " = 0 (y con nuestros otros supuestossobre la distribución de \n",
            "ε\n",
            "i\n",
            "), la estadística:\n",
            "Que es nuestra estimación de \n",
            "β\n",
            "j\n",
            " dividida por nuestra estimación de su\n",
            "error estándar, sigue a una distribución \n",
            "t\n",
            " de Student con “\n",
            "n\n",
            " – \n",
            "k\n",
            " grados de\n",
            "libertad”.\n",
            "Si tuviéramos una función \n",
            "students_t_cdf\n",
            ", podríamos calcular valores \n",
            "p\n",
            "para cada coeficiente de mínimos cuadrados, que indicara la probabilidad de\n",
            "que observáramos un valor así si el coeficiente real fuera 0.\n",
            "Lamentablemente, no tenemos una función como esta (aunque si la\n",
            "tuviéramos no estaríamos trabajando desde cero).\n",
            "No obstante, a medida que los grados de libertad son mayores, la\n",
            "distribución \n",
            "t\n",
            " se acerca cada vez más a una normal estándar. En una situación\n",
            "como esta, donde \n",
            "n\n",
            " es mucho más grande que \n",
            "k\n",
            ", podemos utilizar\n",
            "normal_cdf\n",
            " y seguir sintiéndonos bien con nosotros mismos:\n",
            "from scratch.probability import normal_cdf\n",
            "def p_value(beta_hat_j: float, sigma_hat_j: float) -> float:\n",
            "if beta_hat_j > 0:\n",
            "# si el coeficiente es positivo, tenemos que calcular el doble\n",
            "# de la probabilidad de ver un valor aún *mayor*\n",
            "return 2 * (1–normal_cdf(beta_hat_j / sigma_hat_j))\n",
            "else:\n",
            "# si no el doble de la probabilidad de ver un valor *menor*\n",
            "return 2 * normal_cdf(beta_hat_j / sigma_hat_j)\n",
            "assert p_value(30.58, 1.27) < 0.001\n",
            "# término constante\n",
            "assert p_value(0.972, 0.103) < 0.001\n",
            "# num_friends\n",
            "assert p_value(-1.865, 0.155) < 0.001\n",
            "# work_hours\n",
            "assert p_value(0.923, 1.249) > 0.4\n",
            "# doctorado\n",
            "En una situación diferente a esta, probablemente utilizaríamos software\n",
            "estadístico, que sabe cómo calcular la distribución \n",
            "t\n",
            ", además de cómo calcular\n",
            "los errores estándares exactos.\n",
            "Aunque la mayoría de los coeficientes tienen valores \n",
            "p\n",
            " muy pequeños (lo\n",
            "que sugiere que de hecho no son cero), el coeficiente de “doctorado” no es\n",
            "“apreciablemente” distinto de 0, lo que hace probable que el coeficiente de“doctorado” sea aleatorio en lugar de significativo.\n",
            "En situaciones de regresión más complicadas, se suele querer probar\n",
            "hipótesis más complejas sobre los datos, como “al menos una de las \n",
            "β\n",
            "j\n",
            " no es\n",
            "cero” o “\n",
            "β\n",
            "1\n",
            " es igual a \n",
            "β\n",
            "2\n",
            " y \n",
            "β\n",
            "3\n",
            " es igual a \n",
            "β\n",
            "4\n",
            "”. Esto puede hacerse con una\n",
            "prueba F, pero, por desgracia, eso queda fuera del alcance de este libro.\n",
            "Regularización\n",
            "En la práctica, a menudo se suele aplicar regresión lineal a conjuntos de\n",
            "datos con grandes cantidades de variables. Pero esto crea otro par de\n",
            "problemas. Primero, cuantas más variables se empleen, más probable es que\n",
            "se sobreajuste el modelo al conjunto de entrenamiento. Y segundo, cuantos\n",
            "más coeficientes no cero se tengan, más difícil es darles sentido. Si el\n",
            "objetivo es explicar algún fenómeno, un modelo disperso con tres factores\n",
            "podría ser más útil que un modelo ligeramente mejor con cientos.\n",
            "La regularización es un método en el que añadimos al término de error\n",
            "una penalización, que es mayor a medida que \n",
            "beta\n",
            " aumenta. Entonces\n",
            "minimizamos el error y la penalización combinados. Cuanta más importancia\n",
            "le demos al término de penalización, más desalentaremos a los coeficientes\n",
            "grandes.\n",
            "Por ejemplo, en la regresión \n",
            "ridge\n",
            ", añadimos una penalización\n",
            "proporcional a la suma de cuadrados de la \n",
            "beta_i\n",
            " (excepto que normalmente\n",
            "no penalizamos \n",
            "beta_0\n",
            ", el término constante):\n",
            "# alpha es un *hiperparámetro* que controla lo dura que es la penalización.\n",
            "# A veces se le llama \"lambda\" pero eso ya significa algo en Python.\n",
            "def ridge_penalty(beta: Vector, alpha: float) -> float:\n",
            "return alpha * dot(beta[1:], beta[1:])\n",
            "def squared_error_ridge(x: Vector,\n",
            "y: float,\n",
            "beta: Vector,\n",
            "alpha: float) -> float:\n",
            "\"\"\"estimate error plus ridge penalty on beta\"\"\"\n",
            "return error(x, y, beta) ** 2 + ridge_penalty(beta, alpha)Podemos después conectar esto con el descenso de gradiente de la manera\n",
            "habitual:\n",
            "from scratch.linear_algebra import add\n",
            "def ridge_penalty_gradient(beta: Vector, alpha: float) -> Vector:\n",
            "\"\"\"gradient of just the ridge penalty\"\"\"\n",
            "return [0.] + [2 * alpha * beta_j for beta_j in beta[1:]]\n",
            "def sqerror_ridge_gradient(x: Vector,\n",
            "y: float,\n",
            "beta: Vector,\n",
            "alpha: float) -> Vector:\n",
            "\"\"\"\n",
            "the gradient corresponding to the ith squared error term\n",
            "including the ridge penalty\n",
            "\"\"\"\n",
            "return add(sqerror_gradient(x, y, beta),\n",
            "ridge_penalty_gradient(beta, alpha))\n",
            "Y después tendremos que modificar la función \n",
            "least_squares_fit\n",
            " para\n",
            "usar \n",
            "sqerror_ridge_gradient\n",
            " en lugar de \n",
            "sqerror_gradient\n",
            " (no voy a\n",
            "repetir aquí el código).\n",
            "Con \n",
            "alpha\n",
            " establecido en 0, no hay penalización ninguna y obtenemos los\n",
            "mismos resultados que antes:\n",
            "random.seed(0)\n",
            "beta_0 = least_squares_fit_ridge(inputs,\n",
            "daily_minutes_good, 0.0,\n",
            "# alpha\n",
            "learning_rate, 5000, 25)\n",
            "# [30.51, 0.97, -1.85, 0.91]\n",
            "assert 5 < dot(beta_0[1:], beta_0[1:]) < 6\n",
            "assert 0.67 < multiple_r_squared(inputs, daily_minutes_good, beta_0) < 0.69\n",
            "A medida que aumentamos \n",
            "alpha\n",
            ", la bondad de ajuste empeora, pero el\n",
            "tamaño de \n",
            "beta\n",
            " se reduce:\n",
            "beta_0_1 = least_squares_fit_ridge(inputs,\n",
            "daily_minutes_good, 0.1,\n",
            "# alpha\n",
            "learning_rate, 5000, 25)\n",
            "# [30.8, 0.95, -1.83, 0.54]\n",
            "assert 4 < dot(beta_0_1[1:], beta_0_1[1:]) < 5\n",
            "assert 0.67 < multiple_r_squared(inputs, daily_minutes_good, beta_0_1) < 0.69beta_1 = least_squares_fit_ridge(inputs,\n",
            "daily_minutes_good, 1,\n",
            "# alpha\n",
            "learning_rate, 5000, 25)\n",
            "# [30.6, 0.90, -1.68, 0.10]\n",
            "assert 3 < dot(beta_1[1:], beta_1[1:]) < 4\n",
            "assert 0.67 < multiple_r_squared(inputs, daily_minutes_good, beta_1) < 0.69\n",
            "beta_10 = least_squares_fit_ridge(inputs,\n",
            "daily_minutes_good,10,\n",
            "# alpha\n",
            "learning_rate, 5000, 25)\n",
            "# [28.3, 0.67, -0.90, -0.01]\n",
            "assert 1 < dot(beta_10[1:], beta_10[1:]) < 2\n",
            "assert 0.5 < multiple_r_squared(inputs, daily_minutes_good, beta_10) < 0.6\n",
            "En particular, el coeficiente de “doctorado” desaparece a medida que\n",
            "aumentamos la penalización, lo que está de acuerdo con nuestro anterior\n",
            "resultado, que no era apreciablemente distinto de 0.\n",
            "Nota:\n",
            " Normalmente conviene redimensionar los datos con \n",
            "rescale\n",
            " antes de\n",
            "utilizar este método. Después de todo, si cambiáramos años de experiencia por\n",
            "siglos de experiencia, su coeficiente de mínimos cuadrados aumentaría en un\n",
            "factor de 100 y, de repente, resultaría mucho más penalizado, incluso aunque\n",
            "fuera el mismo modelo.\n",
            "Otro método es la regresión \n",
            "lasso\n",
            ", que utiliza la penalización:\n",
            "def lasso_penalty(beta, alpha):\n",
            "return alpha * sum(abs(beta_i) for beta_i in beta[1:])\n",
            "Mientras que la penalización \n",
            "ridge\n",
            " encogía en general los coeficientes, la\n",
            "penalización \n",
            "lasso\n",
            " tiende a obligar a los coeficientes a ser 0, por lo que nos\n",
            "sirve para aprender modelos dispersos. Lamentablemente, no admite el\n",
            "descenso de gradiente, con lo cual no podremos resolverlo desde cero.\n",
            "Para saber más\n",
            "■\n",
            "La regresión tiene una teoría abundante y extensa, por lo que es otro\n",
            "tema sobre el que podría considerar leer un libro de texto, o al menos\n",
            "unos cuantos artículos de la Wikipedia.■\n",
            "scikit-learn tiene un módulo \n",
            "linear_model\n",
            ", en \n",
            "https://scikit-\n",
            "learn.org/stable/modules/linear_model.html\n",
            ", que ofrece un\n",
            "modelo \n",
            "LinearRegression\n",
            " similar al nuestro, además de regresión\n",
            "ridge\n",
            ", \n",
            "lasso\n",
            " y otros tipos de regularización.\n",
            "■\n",
            "StatsModels, en \n",
            "https://statsmodels.org\n",
            ", es otro módulo de Python\n",
            "que contiene (entre otras cosas) modelos de regresión lineal.16\n",
            " Regresión logística\n",
            "Mucha gente dice que hay una línea muy fina entre el genio y la locura. No creo que\n",
            "haya una línea fina, lo que realmente creo que hay es un abismo.\n",
            "—Bill Bailey\n",
            "En el capítulo 1 hemos visto brevemente el problema de tratar de predecir\n",
            "qué usuarios de DataSciencester pagaron por cuentas \n",
            "premium\n",
            ". En este\n",
            "capítulo le echaremos otro vistazo a este problema.\n",
            "El problema\n",
            "Tenemos un conjunto de datos anónimo de unos 200 usuarios, que\n",
            "contiene el salario de cada usuario, sus años de experiencia como científico\n",
            "de datos y si pagó por una cuenta \n",
            "premium\n",
            " (figura 16.1). Como es habitual\n",
            "con las variables categóricas, representamos la variable dependiente como 0\n",
            "(sin cuenta \n",
            "premium\n",
            ") o 1 (con cuenta \n",
            "premium\n",
            ").\n",
            "Como siempre, nuestros datos son una lista de filas \n",
            "[experience,\n",
            "salary,\n",
            " \n",
            "paid_account]\n",
            ". Convirtámosla al formato que necesitamos:\n",
            "xs = [[1.0] + row[:2] for row in data]\n",
            "# [1, experience, salary]\n",
            "ys = [row[2] for row in data]\n",
            "# paid_account\n",
            "Un primer intento obvio es utilizar regresión lineal y hallar el mejor\n",
            "modelo:\n",
            "cuenta de pago = \n",
            "β\n",
            "0\n",
            " + \n",
            "β\n",
            "1\n",
            "experiencia + \n",
            "β\n",
            "2\n",
            "salario + \n",
            "εFigura 16.1. \n",
            "Usuarios de pago y no de pago.\n",
            "Sin duda, no hay nada que nos impida crear así un modelo similar del\n",
            "problema. Los resultados se muestran en la figura 16.2:\n",
            "Figura 16.2. \n",
            "Utilizar la regresión lineal para predecir las cuentas de pago.from matplotlib import pyplot as plt\n",
            "from scratch.working_with_data import rescale\n",
            "from scratch.multiple_regression import least_squares_fit, predict\n",
            "from scratch.gradient_descent import gradient_step\n",
            "learning_rate = 0.001\n",
            "rescaled_xs = rescale(xs)\n",
            "beta = least_squares_fit(rescaled_xs, ys, learning_rate, 1000, 1)\n",
            "# [0.26, 0.43, -0.43]\n",
            "predictions = [predict(x_i, beta) for x_i in rescaled_xs]\n",
            "plt.scatter(predictions, ys)\n",
            "plt.xlabel(\"predicted\")\n",
            "plt.ylabel(\"actual\")\n",
            "plt.show()\n",
            "Pero este enfoque nos conduce a un par de problemas inmediatos:\n",
            "■\n",
            "Nos gustaría que nuestras salidas previstas fueran 0 o 1, para indicar la\n",
            "membresía de clase. Está bien si están entre 0 y 1, ya que podemos\n",
            "interpretarlas como probabilidades (un resultado de 0,25 podría\n",
            "significar un 25 % de posibilidades de ser un miembro de pago). Pero\n",
            "los resultados del modelo lineal pueden ser grandes números positivos\n",
            "o incluso negativos, cuya interpretación no queda clara. De hecho, aquí\n",
            "muchas de nuestras predicciones fueron negativas.\n",
            "■\n",
            "El modelo de regresión lineal asumía que los errores no estaban\n",
            "correlacionados con las columnas de \n",
            "x\n",
            ". Pero, en este caso, el\n",
            "coeficiente de regresión para \n",
            "experience\n",
            " es 0,43, indicando que más\n",
            "experiencia da lugar a una mayor probabilidad de una cuenta de pago.\n",
            "Esto significa que nuestro modelo da como resultado valores muy\n",
            "grandes para gente con mucha experiencia. Pero sabemos que los\n",
            "valores reales deben ser como máximo 1, lo que significa que\n",
            "resultados necesariamente muy grandes (y por lo tanto valores muy\n",
            "altos de \n",
            "experience\n",
            ") corresponden a valores negativos muy altos del\n",
            "término de error. Como es este el caso, nuestra estimación de \n",
            "beta\n",
            " está\n",
            "sesgada.\n",
            "Lo que realmente nos gustaría es que valores grandes positivos de\n",
            "dot(x_i,\n",
            " \n",
            "beta)\n",
            " correspondieran a probabilidades cercanas a 1, y que valores\n",
            "grandes negativos correspondieran a probabilidades cercanas a 0. Podemosconseguir esto aplicando otra función al resultado.\n",
            "La función logística\n",
            "En el caso de la regresión logística, utilizamos la función del mismo\n",
            "nombre, representada en la figura 16.3:\n",
            "def logistic(x: float) -> float:\n",
            "return 1.0 / (1 + math.exp(-x))\n",
            "Figura 16.3. \n",
            "La función logística.\n",
            "A medida que su entrada se hace más grande y positiva, se acerca cada\n",
            "vez más a 1; a medida que se hace más grande y negativa, se va acercando\n",
            "más a 0. Además, tiene la oportuna propiedad de que su derivada viene dada\n",
            "por:\n",
            "def logistic_prime(x: float) -> float:\n",
            "y = logistic(x)\n",
            "return y * (1 — y)Que utilizaremos en un momento, para ajustar un modelo:\n",
            "y\n",
            "i\n",
            " = \n",
            "ƒ\n",
            "(\n",
            "xi\n",
            "β\n",
            ") + \n",
            "ε\n",
            "i\n",
            "Donde \n",
            "ƒ\n",
            " es la función \n",
            "logistic\n",
            ".\n",
            "Recordemos que para la regresión lineal ajustábamos el modelo\n",
            "minimizando la suma de errores cuadrados, lo que terminaba eligiendo la \n",
            "β\n",
            "que maximizaba la verosimilitud de los datos.\n",
            "Aquí los dos no son equivalentes, de modo que utilizaremos descenso de\n",
            "gradiente para maximizar la verosimilitud directamente; esto significa que\n",
            "necesitamos calcular la función de verosimilitud y su gradiente.\n",
            "Dada una cierta \n",
            "β\n",
            ", nuestro modelo dice que cada \n",
            "yi\n",
            " debería ser igual a 1\n",
            "con probabilidad \n",
            "ƒ\n",
            "(\n",
            "x\n",
            "i\n",
            "β\n",
            ") y a 0 con probabilidad 1 - \n",
            "ƒ\n",
            "(\n",
            "x\n",
            "i\n",
            "β\n",
            ").\n",
            "En particular, la función PDF (de densidad de probabilidad) para \n",
            "yi\n",
            " se\n",
            "puede escribir como:\n",
            "Ya que, si \n",
            "y\n",
            "i\n",
            " es 0, es igual a:\n",
            "1 - \n",
            "ƒ\n",
            "(\n",
            "1\n",
            ")\n",
            "Y, si \n",
            "y\n",
            "i\n",
            " es 1, es igual a:\n",
            "ƒ\n",
            "(\n",
            "x\n",
            "i\n",
            "β\n",
            ")\n",
            "Resulta que es realmente más sencillo maximizar la log-verosimilitud:\n",
            "log \n",
            "L\n",
            "(\n",
            "β\n",
            " | \n",
            "x\n",
            "i\n",
            ", \n",
            "y\n",
            "i\n",
            ") = \n",
            "y\n",
            "i\n",
            " log \n",
            "ƒ\n",
            "(\n",
            "x\n",
            "i\n",
            "β\n",
            ") + (1 - \n",
            "yi\n",
            ") log (1 - \n",
            "ƒ\n",
            "(\n",
            "x\n",
            "i\n",
            "β\n",
            "))\n",
            "Como el logaritmo es una función estrictamente incremental, cualquier\n",
            "beta\n",
            " que maximice la log-verosimilitud también hace lo mismo con la\n",
            "verosimilitud, y viceversa. Como el descenso de gradiente minimiza las\n",
            "cosas, realmente trabajaremos con la log-verosimilitud negativa, ya quemaximizar la verosimilitud es lo mismo que minimizar su negativa:\n",
            "import math\n",
            "from scratch.linear_algebra import Vector, dot\n",
            "def _negative_log_likelihood(x: Vector, y: float, beta: Vector) -> float:\n",
            "\"\"\"The negative log likelihood for one data point\"\"\"\n",
            "if y == 1:\n",
            "return -math.log(logistic(dot(x, beta)))\n",
            "else:\n",
            "return -math.log(1–logistic(dot(x, beta)))\n",
            "Si suponemos que los distintos puntos de datos son independientes uno de\n",
            "otro, la verosimilitud total no es más que el producto de las verosimilitudes\n",
            "individuales; lo que significa que la log-verosimilitud total es la suma de las\n",
            "log-verosimilitudes individuales:\n",
            "from typing import List\n",
            "def negative_log_likelihood(xs: List[Vector],\n",
            "ys: List[float],\n",
            "beta: Vector) -> float:\n",
            "return sum(_negative_log_likelihood(x, y, beta)\n",
            "for x, y in zip(xs, ys))\n",
            "Un poco de cálculo nos da el gradiente:\n",
            "from scratch.linear_algebra import vector_sum\n",
            "def _negative_log_partial_j(x: Vector, y: float, beta: Vector, j: int) ->\n",
            "float:\n",
            "\"\"\"\n",
            "The jth partial derivative for one data point.\n",
            "Here i is the index of the data point.\n",
            "\"\"\"\n",
            "return -(y–logistic(dot(x, beta))) * x[j]\n",
            "def _negative_log_gradient(x: Vector, y: float, beta: Vector) -> Vector:\n",
            "\"\"\"\n",
            "The gradient for one data point.\"\"\"\n",
            "return [_negative_log_partial_j(x, y, beta, j)\n",
            "for j in range(len(beta))]\n",
            "def negative_log_gradient(xs: List[Vector],\n",
            "ys: List[float],\n",
            "beta: Vector) -> Vector:\n",
            "return vector_sum([_negative_log_gradient(x, y, beta)\n",
            "for x, y in zip(xs, ys)])\n",
            "Momento en el cual tenemos todas las piezas que necesitamos.\n",
            "Aplicar el modelo\n",
            "Nos interesará dividir nuestros datos en un conjunto de entrenamiento y\n",
            "uno de prueba:\n",
            "from scratch.machine_learning import train_test_split\n",
            "import random\n",
            "import tqdm\n",
            "random.seed(0)\n",
            "x_train, x_test, y_train, y_test = train_test_split(rescaled_xs, ys, 0.33)\n",
            "learning_rate = 0.01\n",
            "# elige un punto de partida aleatorio\n",
            "beta = [random.random() for _ in range(3)]\n",
            "with tqdm.trange(5000) as t:\n",
            "for epoch in t:\n",
            "gradient = negative_log_gradient(x_train, y_train, beta)\n",
            "beta = gradient_step(beta, gradient, -learning_rate)\n",
            "loss = negative_log_likelihood(x_train, y_train, beta)\n",
            "t.set_description(f\"loss: {loss:.3f} beta: {beta}\")\n",
            "Y después descubrimos que \n",
            "beta\n",
            " es aproximadamente:\n",
            "[-2.0, 4.7, -4.5]\n",
            "Estos son coeficientes para los datos redimensionados con \n",
            "rescale\n",
            ", pero\n",
            "también podemos transformarlos de nuevo en los datos originales:\n",
            "from scratch.working_with_data import scale\n",
            "means, stdevs = scale(xs)beta_unscaled = [(beta[0]\n",
            "–beta[1] * means[1] / stdevs[1]\n",
            "–beta[2] * means[2] / stdevs[2]),\n",
            "beta[1] / stdevs[1],\n",
            "beta[2] / stdevs[2]]\n",
            "# [8.9, 1.6, -0.000288]\n",
            "Lamentablemente, estos no son tan fáciles de interpretar como los\n",
            "coeficientes de regresión lineal. Siendo todo lo demás igual, un año de\n",
            "experiencia adicional suma 1,6 a la entrada de \n",
            "logistic\n",
            ". Siendo todo lo\n",
            "demás igual, 10.000 dólares extra de salario restan 2,88 a la entrada de\n",
            "logistic\n",
            ".\n",
            "Pero el impacto del resultado depende también de las otras entradas. Si\n",
            "dot(beta,\n",
            " \n",
            "x_i)\n",
            " ya es grande (correspondiendo a una probabilidad cercana a\n",
            "1), aumentarlo aun en una elevada cantidad no puede afectar mucho a la\n",
            "probabilidad. Si está cerca de 0, incrementarlo solo un poquito podría\n",
            "aumentar bastante la probabilidad.\n",
            "Lo que podemos decir es que (siendo todo lo demás igual) es más\n",
            "probable que la gente con más experiencia pague por las cuentas. Y que\n",
            "(siendo todo lo demás igual) es menos probable que la gente con salarios más\n",
            "altos pague por las cuentas (esto también se hizo evidente al trazar los datos).\n",
            "Bondad de ajuste\n",
            "No hemos utilizado aún los datos de prueba que nos quedaban. Veamos lo\n",
            "que ocurre si predecimos cuenta de pago siempre que la probabilidad supere\n",
            "0,5:\n",
            "true_positives = false_positives = true_negatives = false_negatives = 0\n",
            "for x_i, y_i in zip(x_test, y_test):\n",
            "prediction = logistic(dot(beta, x_i))\n",
            "if y_i == 1 and prediction >=\n",
            "0.5:\n",
            "# TP: de pago y predecimos de pago\n",
            "true_positives += 1\n",
            "elif y_i == 1:\n",
            "# FN: de pago y predecimos no de pago\n",
            "false_negatives += 1\n",
            "elif prediction >= 0.5:\n",
            "# FP: no de pago y predecimos de pagofalse_positives += 1\n",
            "else:\n",
            "# TN: no de pago y predecimos no de\n",
            "pago\n",
            "true_negatives += 1\n",
            "precision = true_positives / (true_positives + false_positives)\n",
            "recall = true_positives / (true_positives + false_negatives)\n",
            "Esto ofrece una precisión del 75 % (“cuando predecimos cuenta de pago\n",
            "acertamos el 75 % de las veces”) y un recuerdo del 80 % (“cuando un usuario\n",
            "tiene una cuenta de pago predecimos cuenta de pago el 80 % de las veces”),\n",
            "lo que no está nada mal, teniendo en cuenta los pocos datos de que\n",
            "disponemos.\n",
            "También podemos representar las predicciones frente a los datos reales\n",
            "(figura 16.4), lo que también demuestra que el modelo funciona bien:\n",
            "predictions = [logistic(dot(beta, x_i)) for x_i in x_test]\n",
            "plt.scatter(predictions, y_test, marker=’+’)\n",
            "plt.xlabel(\"predicted probability\")\n",
            "plt.ylabel(\"actual outcome\")\n",
            "plt.title(\"Logistic Regression Predicted vs. Actual\")\n",
            "plt.show()\n",
            "Figura 16.4.\n",
            " Regresión logística predicha frente a real.Máquinas de vectores de soporte\n",
            "El conjunto de puntos donde \n",
            "dot(beta,\n",
            " \n",
            "x_i)\n",
            " es igual a 0 es la frontera\n",
            "entre nuestras clases. Podemos representar esto para ver exactamente lo que\n",
            "está haciendo nuestro modelo (figura 16.5).\n",
            "Figura 16.5.\n",
            " Usuarios con cuentas de pago y no de pago con frontera de decisión.\n",
            "Esta frontera es un hiperplano, que divide el espacio de parámetros en dos\n",
            "mitades correspondientes a predice de pago y predice no de pago. Lo\n",
            "descubrimos como un efecto colateral de hallar el modelo logístico más\n",
            "probable.\n",
            "Un método alternativo a la clasificación es simplemente buscar el\n",
            "hiperplano que “mejor” separe las clases en los datos de entrenamiento. Esta\n",
            "es la idea de la máquina de vectores de soporte, que localiza el hiperplano\n",
            "que maximiza la distancia al punto más cercano en cada clase (figura 16.6).Figura 16.6.\n",
            " Un hiperplano de separación.\n",
            "Encontrar un hiperplano como este es un problema de optimización que\n",
            "implica técnicas demasiado avanzadas para nosotros. Un problema distinto es\n",
            "que un hiperplano de separación podría no existir. En nuestro conjunto de\n",
            "datos “¿quién paga?”, simplemente es que no hay línea que separe\n",
            "perfectamente los usuarios que pagan de los que no pagan.\n",
            "En ocasiones, podemos sortear esto transformando los datos en un espacio\n",
            "de muchas dimensiones. Por ejemplo, veamos el sencillo conjunto de datos\n",
            "unidimensional mostrado en la figura 16.7.\n",
            "Sin duda, no hay hiperplano que separe los ejemplos positivos de los\n",
            "negativos. Sin embargo, veamos lo que ocurre cuando mapeamos este\n",
            "conjunto de datos en dos dimensiones enviando el punto \n",
            "x\n",
            " a \n",
            "(x,\n",
            " \n",
            "x**2)\n",
            ". De\n",
            "repente es posible encontrar un hiperplano que divida los datos (figura 16.8).Figura 16.7.\n",
            " Un conjunto de datos unidimensional no separable.\n",
            "Figura 16.8.\n",
            " El conjunto de datos se vuelve separable con muchas dimensiones.\n",
            "Esto se denomina el truco del \n",
            "kernel\n",
            ", porque, en lugar de mapear\n",
            "realmente los puntos en el espacio de muchas dimensiones (lo que podría\n",
            "resultar caro si hay muchos puntos y el mapeado es complicado), podemos\n",
            "utilizar una función “\n",
            "kernel\n",
            "” para calcular productos de punto en el espaciode muchas dimensiones y utilizarlos para encontrar un hiperplano.\n",
            "Es difícil (y probablemente en absoluto una buena idea) utilizar máquinas\n",
            "de vectores de soporte sin confiar en software de optimización especializado\n",
            "escrito por gente con la experiencia adecuada, de modo que tendremos que\n",
            "dejar aquí nuestro planteamiento.\n",
            "Para saber más\n",
            "■\n",
            "scikit-learn tiene módulos de regresión logística, en \n",
            "https://scikit-\n",
            "learn.org/stable/modules/linear_model.html#logistic-\n",
            "regression\n",
            ", y de máquinas de vectores de soporte, en\n",
            "https://scikit-learn.org/stable/modules/svm.html\n",
            ".\n",
            "■\n",
            "LIBSVM, en \n",
            "https://www.csie.ntu.edu.tw/~cjlin/libsvm/\n",
            ", es la\n",
            "implementación de máquina de soporte vectorial que realmente utiliza\n",
            "scikit-learn. Su sitio web tiene mucha documentación variada sobre\n",
            "este algoritmo.17\n",
            " Árboles de decisión\n",
            "Un árbol es un misterio incomprensible.\n",
            "—Jim Woodring\n",
            "El vicepresidente de Talento de DataSciencester ha entrevistado a varios\n",
            "candidatos del sitio para un puesto de trabajo, con diversos grados de éxito.\n",
            "Ha recogido un conjunto de datos, que consiste en varios atributos\n",
            "(cualitativos) de cada candidato, además de si la entrevista con cada uno fue\n",
            "bien o mal. Así que plantea la siguiente pregunta: ¿se podrían utilizar estos\n",
            "datos para crear un modelo que identifique los candidatos que harán una\n",
            "buena entrevista, de forma que no tenga que perder el tiempo en esta tarea?\n",
            "Parece que en esto encaja bien un árbol de decisión, otra herramienta de\n",
            "creación de modelos predictivos que forma parte del equipo del científico de\n",
            "datos.\n",
            "¿Qué es un árbol de decisión?\n",
            "Un árbol de decisión emplea una estructura en árbol para representar una\n",
            "serie de posibles rutas de ramificación y un resultado para cada ruta.\n",
            "Si alguna vez ha jugado al juego de las 20 preguntas,\n",
            "1\n",
            " estará familiarizado\n",
            "con los árboles de decisión. Por ejemplo:\n",
            "■\n",
            "“Estoy pensando en un animal”.\n",
            "■\n",
            "“¿Tiene más de cinco patas?”.\n",
            "■\n",
            "“No”.\n",
            "■\n",
            "“¿Es delicioso?”.\n",
            "■\n",
            "“No”.\n",
            "■\n",
            "“¿Aparece en el reverso de la moneda de cinco centavos australiana?”.\n",
            "■\n",
            "“Sí”.■\n",
            "“¿Es un equidna?”.\n",
            "■\n",
            "“¡Sí, correcto!”.\n",
            "Esta batería de preguntas corresponde a la siguiente ruta, que sería la de\n",
            "un árbol de decisión “adivine el animal” bastante singular (y no muy amplio)\n",
            "(figura 17.1):\n",
            "“No más de 5 patas” → “No delicioso” → “En la moneda de 5 centavos” →\n",
            "“¡Equidna!”\n",
            "Figura 17.1. \n",
            "Un árbol de decisión “adivine el animal”.\n",
            "Los árboles de decisión son recomendables por varias razones. Son muy\n",
            "fáciles de entender e interpretar, y el proceso mediante el cual alcanzan una\n",
            "predicción es totalmente transparente. A diferencia de los otros modelos que\n",
            "hemos visto hasta ahora, los árboles de decisión pueden gestionar sin\n",
            "problemas una mezcla de atributos numéricos (por ejemplo, número de patas)\n",
            "y categóricos (por ejemplo, delicioso/no delicioso) y pueden inclusoclasificar datos para los que falten atributos.\n",
            "Al mismo tiempo, encontrar un árbol de decisión “óptimo” para un\n",
            "conjunto de datos de entrenamiento es un problema muy complicado desde el\n",
            "punto de vista computacional (solucionaremos esto tratando de crear un árbol\n",
            "bastante bueno en lugar de óptimo, aunque para conjuntos de datos grandes\n",
            "puede suponer mucho trabajo). Aún más importante es el hecho de que es\n",
            "muy fácil (y muy malo) crear árboles de decisión que estén sobreajustados a\n",
            "los datos de entrenamiento y que no generalicen bien con datos no visibles.\n",
            "Veremos formas de resolver esto.\n",
            "La mayoría de la gente divide los árboles de decisión en árboles de\n",
            "clasificación (que producen resultados categóricos) y árboles de regresión\n",
            "(que producen resultados numéricos). En este capítulo, nos centraremos en\n",
            "los árboles de clasificación y estudiaremos el algoritmo ID3 para lograr un\n",
            "árbol de decisión a partir de un conjunto de datos etiquetados, lo que debería\n",
            "permitirnos entender cómo funcionan realmente estos algoritmos. Para\n",
            "simplificar las cosas, nos limitamos a problemas con resultados binarios\n",
            "como “¿debería contratar a este candidato?”, “¿debería mostrar al visitante de\n",
            "este sitio web el anuncio A o el anuncio B?” o “¿me enfermaré si me como\n",
            "esta comida que encontré en la nevera de la oficina?”.\n",
            "Entropía\n",
            "Para crear un árbol de decisión, necesitaremos decidir qué preguntas\n",
            "formular y en qué orden. En cada etapa del árbol hay algunas posibilidades\n",
            "que hemos eliminado y otras que no. Tras descubrir que un animal no tiene\n",
            "más de cinco patas, hemos eliminado la posibilidad de que sea un\n",
            "saltamontes. No hemos eliminado la posibilidad de que sea un pato. Cada\n",
            "posible pregunta divide las posibilidades restantes según su respuesta.\n",
            "Lo ideal sería elegir preguntas cuyas respuestas dieran mucha información\n",
            "sobre lo que debería predecir nuestro árbol. Si hay una sola pregunta sí/no\n",
            "para la que las respuestas “sí” siempre corresponden a resultados \n",
            "True\n",
            " y las\n",
            "respuestas “no” a resultados \n",
            "False\n",
            " (o viceversa), sería la pregunta perfecta.Pero, sin embargo, probablemente no sería una buena opción una pregunta\n",
            "sí/no para la que ninguna respuesta dé mucha información nueva sobre cómo\n",
            "debería ser la predicción.\n",
            "Esta noción de “cantidad de información” se captura con la entropía. Es\n",
            "probable que haya oído ya antes este término con el significado de desorden.\n",
            "Aquí lo utilizamos para representar la incertidumbre asociada a los datos.\n",
            "Supongamos que tenemos un conjunto \n",
            "S\n",
            " de datos, cada miembro del cual\n",
            "está etiquetado como perteneciente a una de un número finito de clases \n",
            "C\n",
            "1\n",
            ",\n",
            "..., \n",
            "C\n",
            "n\n",
            ". Si todos los puntos de datos pertenecen a una sola clase, entonces no\n",
            "hay incertidumbre, con lo cual idealmente la entropía sería baja. Si los puntos\n",
            "de datos están distribuidos por igual a lo largo de las clases, sí habría mucha\n",
            "incertidumbre y la entropía sería alta.\n",
            "En términos matemáticos, si \n",
            "p\n",
            "i\n",
            " es la proporción de datos etiquetados como\n",
            "clase \n",
            "c\n",
            "i\n",
            ", definimos la entropía como:\n",
            "H\n",
            "(\n",
            "S\n",
            ") = ‒ \n",
            "p\n",
            "1\n",
            " log\n",
            "2\n",
            " \n",
            "p\n",
            "1\n",
            " ‒ ... ‒ \n",
            "p\n",
            "n\n",
            " log\n",
            "2\n",
            " \n",
            "p\n",
            "n\n",
            "Con el convenio (estándar) de que 0 log 0 = 0.\n",
            "Sin preocuparnos demasiado por los detalles, cada término ‒ \n",
            "p\n",
            "i\n",
            " log\n",
            "2\n",
            " \n",
            "p\n",
            "i\n",
            " es\n",
            "no negativo y está cerca de 0 precisamente cuando \n",
            "p\n",
            "i\n",
            " está o bien cerca de 0 o\n",
            "cerca de 1 (figura 17.2).Figura 17.2. \n",
            "Una representación de ‒ \n",
            "p\n",
            " log \n",
            "p\n",
            ".\n",
            "Esto significa que la entropía será pequeña cuando cada \n",
            "p\n",
            "i\n",
            " esté cerca de 0\n",
            "o 1 (es decir, cuando la mayoría de los datos están en una sola clase), y será\n",
            "más grande cuando muchos de los \n",
            "p\n",
            "i\n",
            " no estén cerca de 0 (es decir, cuando los\n",
            "datos estén repartidos a lo largo de varias clases). Este es exactamente el\n",
            "comportamiento que deseamos.\n",
            "Es bastante sencillo desarrollar todo esto en una función:\n",
            "from typing import List\n",
            "import math\n",
            "def entropy(class_probabilities: List[float]) -> float:\n",
            "\"\"\"Given a list of class probabilities, compute the entropy\"\"\"\n",
            "return sum(-p * math.log(p, 2)\n",
            "for p in class_probabilities\n",
            "if p > 0)\n",
            "# ignora probabilidades cero\n",
            "assert entropy([1.0]) == 0\n",
            "assert entropy([0.5, 0.5]) == 1\n",
            "assert 0.81 < entropy([0.25, 0.75]) < 0.82\n",
            "Nuestros datos consistirán en pares \n",
            "(input,\n",
            " \n",
            "label)\n",
            ", lo que significa quetendremos que calcular nosotros mismos las probabilidades de clase. Hay que\n",
            "tener en cuenta que no nos preocupa realmente qué etiqueta está asociada a\n",
            "qué probabilidad, únicamente cuáles son las probabilidades:\n",
            "from typing import Any\n",
            "from collections import Counter\n",
            "def class_probabilities(labels: List[Any]) -> List[float]:\n",
            "total_count = len(labels)\n",
            "return [count / total_count\n",
            "for count in Counter(labels).values()]\n",
            "def data_entropy(labels: List[Any]) -> float:\n",
            "return entropy(class_probabilities(labels))\n",
            "assert data_entropy([‘a’]) == 0\n",
            "assert data_entropy([True, False]) == 1\n",
            "assert data_entropy([3, 4, 4, 4]) == entropy([0.25, 0.75])\n",
            "La entropía de una partición\n",
            "Lo que hemos hecho hasta ahora es calcular la entropía (o sea,\n",
            "“incertidumbre”) de un conjunto único de datos etiquetados. Pero cada etapa\n",
            "de un árbol de decisión implica formular una pregunta cuya respuesta reparte\n",
            "los datos en uno o (supuestamente) varios subconjuntos. Por ejemplo, nuestra\n",
            "pregunta “¿tiene más de cinco patas?” divide los animales en los que tienen\n",
            "más de cinco patas (por ejemplo, las arañas) y los que no (por ejemplo, los\n",
            "equidnas).\n",
            "En consecuencia, queremos tener una cierta noción de la entropía\n",
            "resultante de la partición de un conjunto de datos de una determinada forma.\n",
            "Queremos que una partición tenga entropía baja si reparte los datos en\n",
            "subconjuntos que tienen también entropía baja (es decir, son muy seguros), y\n",
            "entropía alta si contiene subconjuntos que (son grandes y) tienen asimismo\n",
            "entropía alta (es decir, son muy inciertos).\n",
            "Por ejemplo, la pregunta de la “moneda de cinco céntimos australiana” era\n",
            "bastante tonta (¡aunque también bastante afortunada!), ya que dividió los\n",
            "animales que quedaban en ese punto en \n",
            "S\n",
            "1\n",
            " = {equidna} y \n",
            "S\n",
            "2\n",
            " = {los demás},\n",
            "donde \n",
            "S\n",
            "2\n",
            " es grande y además tiene alta entropía (\n",
            "S\n",
            "1\n",
            " no tiene entropía, perorepresenta una pequeña fracción de las “clases” restantes).\n",
            "Matemáticamente, si dividimos nuestros datos \n",
            "S\n",
            " en subconjuntos \n",
            "S\n",
            "1\n",
            ", ...,\n",
            "S\n",
            "m\n",
            " conteniendo proporciones \n",
            "q\n",
            "1\n",
            ", ..., \n",
            "q\n",
            "m\n",
            " de los datos, calculamos entonces la\n",
            "entropía de la partición como una suma ponderada:\n",
            "H\n",
            " = \n",
            "q\n",
            "1\n",
            "H\n",
            "(\n",
            "S\n",
            "1\n",
            ") + ... + \n",
            "q\n",
            "m\n",
            "H\n",
            "(\n",
            "S\n",
            "m\n",
            ")\n",
            "Que podemos implementar como:\n",
            "def partition_entropy(subsets: List[List[Any]]) -> float:\n",
            "\"\"\"Returns the entropy from this partition of data into subsets\"\"\"\n",
            "total_count = sum(len(subset) for subset in subsets)\n",
            "return sum(data_entropy(subset) * len(subset) / total_count\n",
            "for subset in subsets)\n",
            "Nota:\n",
            " Un problema con este planteamiento es que repartir según un atributo\n",
            "con muchos valores distintos dará como resultado una entropía muy baja\n",
            "debido al sobreajuste. Por ejemplo, imaginemos que trabajamos en un banco y\n",
            "estamos tratando de crear un árbol de decisión para predecir cuál de sus\n",
            "clientes es probable que no pague la hipoteca, utilizando algunos datos\n",
            "históricos, como el conjunto de entrenamiento de que disponemos. Vayamos\n",
            "aún más allá y supongamos que el conjunto de datos contiene el número de la\n",
            "Seguridad Social de cada cliente. Dividir según el NSS producirá subconjuntos\n",
            "de una sola persona, cada uno de los cuales tiene necesariamente cero\n",
            "entropía. Pero podemos tener la certeza de que un modelo que se base en el\n",
            "NSS no generaliza más allá del conjunto de entrenamiento. Por esta razón, al\n",
            "crear árboles de decisión deberíamos probablemente tratar de evitar (o poner\n",
            "en \n",
            "buckets\n",
            ", si corresponde) atributos con grandes cantidades de valores\n",
            "posibles.\n",
            "Crear un árbol de decisión\n",
            "El vicepresidente le ofrece los datos del entrevistado, que consisten en\n",
            "(según su especificación) un módulo \n",
            "NamedTuple\n",
            " de los atributos más\n",
            "importantes de cada candidato: su nivel (\n",
            "level\n",
            "), su lenguaje predilecto (\n",
            "lang\n",
            "),\n",
            "si es activo o no en Twitter (\n",
            "tweets\n",
            "), si tiene doctorado (\n",
            "phd\n",
            ") y si la entrevista\n",
            "fue positiva (\n",
            "did_well\n",
            "):from typing import NamedTuple, Optional\n",
            "class Candidate(NamedTuple):\n",
            "level: str\n",
            "lang: str\n",
            "tweets: bool\n",
            "phd: bool\n",
            "did_well: Optional[bool] = None\n",
            "# permite datos sin etiquetar\n",
            "# level lang tweets phd did_well\n",
            "inputs = [Candidate(‘Senior’, ‘Java’, False, False, False),\n",
            "Candidate(‘Senior’, ‘Java’, False, True, False),\n",
            "Candidate(‘Mid’, ‘Python’, False, False, True),\n",
            "Candidate(‘Junior’, ‘Python’, False, False, True),\n",
            "Candidate(‘Junior’, ‘R’, True, False, True),\n",
            "Candidate(‘Junior’, ‘R’, True, True, False),\n",
            "Candidate(‘Mid’, ‘R’, True, True, True),\n",
            "Candidate(‘Senior’, ‘Python’, False, False, False),\n",
            "Candidate(‘Senior’, ‘R’, True, False, True),\n",
            "Candidate(‘Junior’, ‘Python’, True, False, True),\n",
            "Candidate(‘Senior’, ‘Python’, True, True, True),\n",
            "Candidate(‘Mid’, ‘Python’, False, True, True),\n",
            "Candidate(‘Mid’, ‘Java’, True, False, True),\n",
            "Candidate(‘Junior’, ‘Python’, False, True, False)\n",
            "]\n",
            "Nuestro árbol consiste en nodos de decisión (que formulan una pregunta y\n",
            "nos dirigen de forma diferente dependiendo de la respuesta) y nodos de hoja\n",
            "(que nos dan una predicción). Lo crearemos utilizando el algoritmo ID3,\n",
            "relativamente sencillo, que funciona del siguiente modo. Digamos que nos\n",
            "han dado datos etiquetados y una lista de atributos para considerar las\n",
            "ramificaciones:\n",
            "■\n",
            "Si los datos tienen todos la misma etiqueta, crea un nodo de hoja que\n",
            "predice la etiqueta y después se detiene.\n",
            "■\n",
            "Si la lista de atributos está vacía (es decir, no hay más preguntas\n",
            "posibles que formular), crea un nodo de hoja que predice la etiqueta\n",
            "más habitual y después se detiene.\n",
            "■\n",
            "Si no, intenta dividir los datos por cada uno de los atributos.\n",
            "■\n",
            "Elige la bifurcación con la entropía más baja posible.\n",
            "■\n",
            "Añade un nodo de decisión basándose en el atributo elegido.\n",
            "■\n",
            "Vuelve a repetirlo en cada subconjunto dividido utilizando los\n",
            "atributos restantes.Esto es lo que se conoce como algoritmo “voraz” porque, en cada paso,\n",
            "elige la mejor opción inmediata. Dado un conjunto de datos, puede haber un\n",
            "árbol mejor con un primer movimiento de peor aspecto. Si es así, este\n",
            "algoritmo no lo encontrará. No obstante, es relativamente fácil de comprender\n",
            "e implementar, por lo que nos ofrece un buen punto de partida para empezar a\n",
            "explorar los árboles de decisión.\n",
            "Vayamos manualmente por cada uno de estos pasos en el conjunto de\n",
            "datos del entrevistado. El conjunto tiene ambas etiquetas \n",
            "True\n",
            " y \n",
            "False\n",
            ", y\n",
            "tenemos cuatro atributos según los cuales podemos repartir. Así que nuestro\n",
            "primer paso será hallar la división con la menor entropía. Empezaremos\n",
            "escribiendo una función que se encarga del proceso de partición:\n",
            "from typing import Dict, TypeVar\n",
            "from collections import defaultdict\n",
            "T = TypeVar(‘T’)\n",
            "# tipo genérico para entradas\n",
            "def partition_by(inputs: List[T], attribute: str) -> Dict[Any, List[T]]:\n",
            "\"\"\"Partition the inputs into lists based on the specified attribute.\"\"\"\n",
            "partitions: Dict[Any, List[T]] = defaultdict(list)\n",
            "for input in inputs:\n",
            "key = getattr(input,\n",
            "attribute)\n",
            "# valor del atributo especificado\n",
            "partitions[key].append(input)\n",
            "# añade entrada a la partición\n",
            "correcta\n",
            "return partitions\n",
            "Y otra que la utilice para calcular la entropía:\n",
            "def partition_entropy_by(inputs: List[Any],\n",
            "attribute: str,\n",
            "label_attribute: str) -> float:\n",
            "\"\"\"Compute the entropy corresponding to the given partition\"\"\"\n",
            "# partitions consiste en nuestras entradas\n",
            "partitions = partition_by(inputs, attribute)\n",
            "# pero partition_entropy solo necesita las etiquetas de clase\n",
            "labels = [[getattr(input, label_attribute) for input in partition]\n",
            "for partition in partitions.values()]\n",
            "return partition_entropy(labels)\n",
            "Ahora solo necesitamos la partición de mínima entropía para el conjuntode datos entero:\n",
            "for key in [‘level’,’lang’,’tweets’,’phd’]:\n",
            "print(key, partition_entropy_by(inputs, key, ‘did_well’))\n",
            "assert 0.69 < partition_entropy_by(inputs, ‘level’, ‘did_well’) < 0.70\n",
            "assert 0.86 < partition_entropy_by(inputs, ‘lang’, ‘did_well’) < 0.87\n",
            "assert 0.78 < partition_entropy_by(inputs, ‘tweets’, ‘did_well’) < 0.79\n",
            "assert 0.89 < partition_entropy_by(inputs, ‘phd’, ‘did_well’) < 0.90\n",
            "La entropía más baja viene de dividir según \n",
            "level\n",
            ", de modo que nos hará\n",
            "falta hacer un subárbol para cada posible valor de \n",
            "level\n",
            ". Cada candidato \n",
            "Mid\n",
            "se etiqueta \n",
            "True\n",
            ", lo que significa que el subárbol \n",
            "Mid\n",
            " es simplemente un nodo\n",
            "de hoja que predice \n",
            "True\n",
            ". Para candidatos \n",
            "Senior\n",
            ", tenemos una mezcla de\n",
            "valores \n",
            "True\n",
            " y \n",
            "False\n",
            ", de modo que tenemos que dividir de nuevo:\n",
            "senior_inputs = [input for input in inputs if input.level == ‘Senior’]\n",
            "assert 0.4 == partition_entropy_by(senior_inputs, ‘lang’, ‘did_well’)\n",
            "assert 0.0 == partition_entropy_by(senior_inputs, ‘tweets’, ‘did_well’)\n",
            "assert 0.95 < partition_entropy_by(senior_inputs, ‘phd’, ‘did_well’) < 0.96\n",
            "Esto nos demuestra que nuestra siguiente división debería realizarse según\n",
            "tweets\n",
            ", lo que da como resultado una partición con entropía cero. Para esos\n",
            "candidatos de nivel \n",
            "Senior\n",
            ", un “sí” en el atributo de los tuits siempre da\n",
            "como resultado \n",
            "True\n",
            ", mientras que un “no” siempre da como resultado\n",
            "False\n",
            ".\n",
            "Por último, si hacemos lo mismo para los candidatos \n",
            "Junior\n",
            ", terminamos\n",
            "repartiendo según \n",
            "phd\n",
            ", tras de lo cual descubrimos que no tener doctorado\n",
            "siempre da como resultado \n",
            "True\n",
            " y tener doctorado siempre da \n",
            "False\n",
            ".\n",
            "La figura 17.3 muestra el árbol de decisión completo.Figura 17.3. \n",
            "El árbol de decisión para contrataciones.\n",
            "Ahora, a combinarlo todo\n",
            "Ahora que ya hemos visto cómo funciona el algoritmo, nos gustaría\n",
            "implementarlo más en general, lo que significa que tenemos que decidir\n",
            "cómo queremos representar los árboles. Utilizaremos la representación más\n",
            "liviana posible. Definimos un árbol de dos maneras:\n",
            "■\n",
            "Un \n",
            "Leaf\n",
            " (que predice un solo valor).\n",
            "■\n",
            "Un \n",
            "Split\n",
            " (que contiene un atributo según el que dividir, subárboles\n",
            "para valores determinados de ese atributo y posiblemente un valor\n",
            "predeterminado que utilizar si encontramos un valor desconocido).\n",
            "from typing import NamedTuple, Union, Any\n",
            "class Leaf(NamedTuple):\n",
            "value: Any\n",
            "class Split(NamedTuple):\n",
            "attribute: str\n",
            "subtrees: dictdefault_value: Any = None\n",
            "DecisionTree = Union[Leaf, Split]\n",
            "Con esta representación, nuestro árbol de contrataciones tendría este\n",
            "aspecto:\n",
            "hiring_tree = Split(‘level’, {\n",
            "# primero, considera \"level\"\n",
            "‘Junior’: Split(‘phd’, {\n",
            "# si el nivel es \"Junior\", mira \"phd\"\n",
            "False: Leaf(True),\n",
            "# si \"phd\" es False, predice True\n",
            "True: Leaf(False)\n",
            "# si \"phd\" es True, predice False\n",
            "}),\n",
            "‘Mid’: Leaf(True),\n",
            "# si el nivel es \"Mid\", predice True\n",
            "‘Senior’: Split(‘tweets’, {\n",
            "# si el nivel es \"Senior\", mira \"tweets\"\n",
            "False: Leaf(False),\n",
            "# si \"tweets\" es False, predice False\n",
            "True: Leaf(True)\n",
            "# si \"tweets\" es True, predice True\n",
            "})\n",
            "})\n",
            "Queda pendiente la cuestión de qué hacer si encontramos un valor de\n",
            "atributo inesperado (o faltante). ¿Qué debe hacer nuestro árbol de\n",
            "contrataciones si encuentra un candidato cuyo \n",
            "level\n",
            " es \n",
            "Intern\n",
            "?\n",
            "Gestionaremos este caso asignando al atributo \n",
            "default_value\n",
            " la etiqueta más\n",
            "común.\n",
            "Dada una representación como esta, podemos clasificar una entrada con:\n",
            "def classify(tree: DecisionTree, input: Any) -> Any:\n",
            "\"\"\"classify the input using the given decision tree\"\"\"\n",
            "# Si es un nodo de hoja, devuelve su valor\n",
            "if isinstance(tree, Leaf):\n",
            "return tree.value\n",
            "# Si no este árbol consiste en un atributo según el que dividir\n",
            "# y un diccionario cuyas claves son valores de ese atributo\n",
            "# y cuyos valores son subárboles que considerar después\n",
            "subtree_key = getattr(input, tree.attribute)\n",
            "if subtree_key not in\n",
            "tree.subtrees:\n",
            "# Si no hay subárbol para clave,\n",
            "return tree.default_value\n",
            "# devuelve el valor predeterminado.\n",
            "subtree =\n",
            "tree.subtrees[subtree_key]\n",
            "# Elige el subárbol adecuado\n",
            "return classify(subtree, input)\n",
            "# y lo usa para clasificar la\n",
            "entrada.Todo lo que queda por hacer es crear la representación del árbol a partir de\n",
            "nuestros datos de entrenamiento:\n",
            "def build_tree_id3(inputs: List[Any],\n",
            "split_attributes: List[str],\n",
            "target_attribute: str) -> DecisionTree:\n",
            "# Cuenta etiquetas destino\n",
            "label_counts = Counter(getattr(input, target_attribute)\n",
            "for input in inputs)\n",
            "most_common_label = label_counts.most_common(1)[0][0]\n",
            "# Si hay una etiqueta única, la predice\n",
            "if len(label_counts) == 1:\n",
            "return Leaf(most_common_label)\n",
            "# Si no quedan atributos de división, devuelve la etiqueta mayoritaria\n",
            "if not split_attributes:\n",
            "return Leaf(most_common_label)\n",
            "# Si no divide por el mejor atributo\n",
            "def split_entropy(attribute: str) -> float:\n",
            "\"\"\"Helper function for finding the best attribute\"\"\"\n",
            "return partition_entropy_by(inputs, attribute, target_attribute)\n",
            "best_attribute = min(split_attributes, key=split_entropy)\n",
            "partitions = partition_by(inputs, best_attribute)\n",
            "new_attributes = [a for a in split_attributes if a != best_attribute]\n",
            "# Crea recursivamente los subárboles\n",
            "subtrees = {attribute_value : build_tree_id3(subset,\n",
            "new_attributes,\n",
            "target_attribute)\n",
            "for attribute_value, subset in partitions.items()}\n",
            "return Split(best_attribute, subtrees, default_value=most_common_label)\n",
            "En el árbol que creamos, cada hoja estaba enteramente formada por\n",
            "entradas \n",
            "True\n",
            " o por entradas \n",
            "False\n",
            ". Esto significa que el árbol predice\n",
            "perfectamente según el conjunto de datos de entrenamiento. Pero también\n",
            "podemos aplicarlo a nuevos datos que no estuvieran en el conjunto de\n",
            "entrenamiento:\n",
            "tree = build_tree_id3(inputs,\n",
            "[‘level’, ‘lang’, ‘tweets’, ‘phd’],\n",
            "‘did_well’)\n",
            "# Debe predecir True\n",
            "assert classify(tree, Candidate(\"Junior\", \"Java\", True, False))\n",
            "# Debe predecir Falseassert not classify(tree, Candidate(\"Junior\", \"Java\", True, True))\n",
            "Y también a datos con valores inesperados:\n",
            "# Debe predecir True\n",
            "assert classify(tree, Candidate(\"Intern\", \"Java\", True, True))\n",
            "Nota: \n",
            "Como nuestro objetivo era principalmente mostrar cómo crear un árbol,\n",
            "lo construimos utilizando el conjunto de datos entero. Como siempre, si\n",
            "estuviéramos tratando realmente de crear un buen modelo para algo,\n",
            "habríamos recogido más datos y los habríamos dividido en subconjuntos de\n",
            "entrenamiento/validación/prueba.\n",
            "Bosques aleatorios\n",
            "Teniendo en cuenta lo mucho que pueden los árboles de decisión ajustarse\n",
            "a sus datos de entrenamiento, no resulta sorprendente que tengan tendencia a\n",
            "sobreajustar. Una forma de evitar esto es una técnica llamada bosques\n",
            "aleatorios, en la que creamos varios árboles de decisión y combinamos sus\n",
            "resultados. Si son árboles de clasificación, podríamos dejarlos votar; si son de\n",
            "regresión, podríamos promediar sus predicciones.\n",
            "Nuestro proceso de creación de árboles era determinista, de modo que\n",
            "¿cómo obtenemos árboles aleatorios?\n",
            "Una parte del proceso implica aplicar \n",
            "bootstrap\n",
            " a los datos (recordemos la\n",
            "sección sobre \n",
            "bootstrap\n",
            " en el capítulo 15). En lugar de entrenar cada árbol en\n",
            "todas las entradas del conjunto de entrenamiento, lo entrenamos en el\n",
            "resultado de \n",
            "bootstrap_sample\n",
            " \n",
            "(inputs)\n",
            ". Como cada árbol se ha creado\n",
            "usando distintos datos, cada uno será diferente de los demás (un beneficio\n",
            "secundario es que es totalmente justo utilizar los datos no muestreados para\n",
            "probar cada árbol, lo que significa que uno se puede salir con la suya\n",
            "utilizando todos los datos como conjunto de entrenamiento si se es lo\n",
            "bastante listo midiendo el rendimiento). Esta técnica se conoce como\n",
            "agregación o empaquetado de \n",
            "bootstrap\n",
            ".\n",
            "Una segunda fuente de aleatoriedad implica cambiar la forma que tenemosde elegir el \n",
            "best_attribute\n",
            " según el cual dividir. En lugar de mirar todos los\n",
            "atributos restantes, primero elegimos un subconjunto aleatorio de ellos y\n",
            "después repartimos según el de ellos que sea mejor:\n",
            "# si ya hay suficientes candidatos divididos, los mira todos\n",
            "if len(split_candidates) <= self.num_split_candidates:\n",
            "sampled_split_candidates = split_candidates\n",
            "# si no elige una muestra aleatoria\n",
            "else:\n",
            "sampled_split_candidates = random.sample(split_candidates,\n",
            "self.num_split_candidates)\n",
            "# ahora elige el mejor atributo solo de esos candidatos\n",
            "best_attribute = min(sampled_split_candidates, key=split_entropy)\n",
            "partitions = partition_by(inputs, best_attribute)\n",
            "Este es un ejemplo de una técnica más amplia llamada aprendizaje\n",
            "combinado o \n",
            "ensemble\n",
            ", en la que combinamos varios estudiantes débiles\n",
            "(normalmente modelos de alto sesgo y baja varianza) para producir un\n",
            "modelo global fuerte.\n",
            "Para saber más\n",
            "■\n",
            "scikit-learn tiene muchos modelos de árbol de decisión, en\n",
            "https://scikit-learn.org/stable/modules/tree.html\n",
            ". También\n",
            "tiene un módulo \n",
            "ensemble\n",
            " en \n",
            "https://scikit-\n",
            "learn.org/stable/modules/classes.html#module-\n",
            "sklearn.ensemble\n",
            ", que incluye un \n",
            "RandomForestClassifier\n",
            ", además\n",
            "de otros métodos de aprendizaje combinado.\n",
            "■\n",
            "XGBoost, en \n",
            "https://xgboost.ai/\n",
            ", es una librería para entrenar\n",
            "árboles de decisión con potenciación del gradiente que tiende a ganar\n",
            "muchas competiciones de \n",
            "machine learning\n",
            " de estilo Kaggle.\n",
            "■\n",
            "Apenas hemos arañado la superficie de los árboles de decisión y sus\n",
            "algoritmos. La Wikipedia, en\n",
            "https://es.wikipedia.org/wiki/Aprendizaje_basado_en_%C3%A1rboles_de_decisi%C3%B3n\n",
            "es un buen punto de partida para un estudio más detallado.1\n",
            " \n",
            "https://en.wikipedia.org/wiki/Twenty_questions\n",
            ".18\n",
            " Redes neuronales\n",
            "Me gusta el sinsentido; despierta las células del cerebro.\n",
            "—Dr. Seuss\n",
            "Una red neuronal artificial (o red neuronal sin más) es un modelo\n",
            "predictivo motivado por el modo en que funciona el cerebro. Piense en el\n",
            "cerebro como en una colección de neuronas conectadas entre ellas. Cada\n",
            "neurona mira las salidas de las otras neuronas que la alimentan, hace un\n",
            "cálculo y después se activa (si el cálculo excede un cierto umbral) o no (si no\n",
            "lo excede).\n",
            "Según esta explicación, las redes neuronales artificiales están formadas\n",
            "por neuronas artificiales, que realizan cálculos similares sobre sus entradas.\n",
            "Las redes neuronales pueden resolver distintos problemas, como\n",
            "reconocimiento de escritura y detección de caras, y se utilizan mucho en el\n",
            "deep learning\n",
            ", uno de los subcampos más recientes de la ciencia de datos. Sin\n",
            "embargo, la mayoría de las redes neuronales son “cajas negras” (es decir,\n",
            "inspeccionar sus detalles no permite entender mucho mejor cómo resuelven\n",
            "un problema). Además, pueden ser difíciles de entrenar. Para resolver la\n",
            "mayor parte de los problemas que uno se suele encontrar como científico de\n",
            "datos en ciernes, probablemente no son la mejor opción. Pero, si algún día el\n",
            "objetivo es construir una inteligencia artificial para crear la singularidad,\n",
            "entonces sí podrían ser de utilidad.\n",
            "Perceptrones\n",
            "La red neuronal más sencilla de todas es el perceptrón, que se aproxima a\n",
            "una sola neurona con \n",
            "n\n",
            " entradas binarias. Calcula una suma ponderada de sus\n",
            "entradas y se “activa” si esa suma es 0 o mayor que 0:\n",
            "from scratch.linear_algebra import Vector, dotdef step_function(x: float) -> float:\n",
            "return 1.0 if x >= 0 else 0.0\n",
            "def perceptron_output(weights: Vector, bias: float, x: Vector) -> float:\n",
            "\"\"\"Returns 1 if the perceptron ‘fires’, 0 if not\"\"\"\n",
            "calculation = dot(weights, x) + bias\n",
            "return step_function(calculation)\n",
            "El perceptrón simplemente distingue entre los semiespacios separados por\n",
            "el hiperplano de puntos \n",
            "x\n",
            ", para los cuales:\n",
            "dot(weights, x) + bias == 0\n",
            "Con pesos adecuadamente elegidos, los perceptrones pueden resolver unos\n",
            "cuantos problemas sencillos (véase la figura 18.1). Por ejemplo, podemos\n",
            "crear una puerta AND, que devuelve 1 si sus dos entradas son 1 y 0 si una de\n",
            "sus entradas es 0, utilizando:\n",
            "Figura 18.1. \n",
            "Espacio de decisión para un perceptrón de dos entradas.\n",
            "and_weights = [2., 2]\n",
            "and_bias = -3.\n",
            "assert perceptron_output(and_weights, and_bias, [1, 1]) == 1\n",
            "assert perceptron_output(and_weights, and_bias, [0, 1]) == 0assert perceptron_output(and_weights, and_bias, [1, 0]) == 0\n",
            "assert perceptron_output(and_weights, and_bias, [0, 0]) == 0\n",
            "Si ambas entradas son 1, \n",
            "calculation\n",
            " es igual a 2 + 2 - 3 = 1, y el\n",
            "resultado es 1. Si solo una de las entradas es 1, \n",
            "calculation\n",
            " es igual a 2 + 0 -\n",
            "3 = -1, y el resultado es 0. Pero, si ambas entradas son 0, \n",
            "calculation\n",
            " es\n",
            "igual a -3 y el resultado es 0.\n",
            "Utilizando un razonamiento parecido, podríamos crear una puerta OR con\n",
            "este código:\n",
            "or_weights = [2., 2]\n",
            "or_bias = -1.\n",
            "assert perceptron_output(or_weights, or_bias, [1, 1]) == 1\n",
            "assert perceptron_output(or_weights, or_bias, [0, 1]) == 1\n",
            "assert perceptron_output(or_weights, or_bias, [1, 0]) == 1\n",
            "assert perceptron_output(or_weights, or_bias, [0, 0]) == 0\n",
            "También podríamos crear una puerta NOT (que tiene una sola entrada y\n",
            "convierte 1 en 0 y 0 en 1) con:\n",
            "not_weights = [-2.]\n",
            "not_bias = 1.\n",
            "assert perceptron_output(not_weights, not_bias, [0]) == 1\n",
            "assert perceptron_output(not_weights, not_bias, [1]) == 0\n",
            "Sin embargo, hay algunos problemas que simplemente no se pueden\n",
            "resolver con un solo perceptrón. Por ejemplo, por mucho que se intente, no se\n",
            "puede usar un perceptrón para crear una puerta XOR que dé como resultado 1\n",
            "si exactamente una de sus entradas es 1 y 0 si no lo es. Aquí es donde\n",
            "empezamos a necesitar redes neuronales más complicadas.\n",
            "Por supuesto, no hace falta aproximarse a una neurona para poder crear\n",
            "una puerta lógica:\n",
            "and_gate = min\n",
            "or_gate = max\n",
            "xor_gate = lambda x, y: 0 if x == y else 1\n",
            "Como ocurre con las neuronas de verdad, las artificiales empiezan a\n",
            "resultar más interesantes cuando se las empieza a conectar unas con otras.Redes neuronales prealimentadas\n",
            "La topología del cerebro es enormemente complicada, de ahí que sea\n",
            "habitual aproximarse a ella con una red neuronal prealimentada teórica,\n",
            "formada por capas discretas de neuronas, cada una de ellas conectada con la\n",
            "siguiente. Normalmente esto conlleva una capa de entrada (que recibe\n",
            "entradas y las transmite sin cambios), una o varias “capas ocultas” (cada una\n",
            "de las cuales consiste en neuronas que toman las salidas de la capa anterior,\n",
            "realizan algún tipo de cálculo y pasan el resultado a la siguiente capa) y una\n",
            "capa de salida (que produce los resultados finales).\n",
            "Exactamente igual que en el perceptrón, cada neurona (no de entrada)\n",
            "tiene un peso correspondiente a cada una de sus entradas y un sesgo. Para que\n",
            "nuestra representación sea más sencilla, añadiremos el sesgo al final de\n",
            "nuestro vector de pesos y daremos a cada neurona una entrada de sesgo que\n",
            "siempre es igual a 1.\n",
            "Igual que con el perceptrón, para cada neurona sumaremos los productos\n",
            "de sus entradas y sus pesos. Pero aquí, en lugar de dar como resultado\n",
            "step_function\n",
            " aplicado a dicho producto, obtendremos una aproximación\n",
            "suave de él. Lo que emplearemos es la función \n",
            "sigmoid\n",
            " (figura 18.2):\n",
            "import math\n",
            "def sigmoid(t: float) -> float:\n",
            "return 1 / (1 + math.exp(-t))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chunks"
      ],
      "metadata": {
        "id": "hlwS-1ZBfvFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)"
      ],
      "metadata": {
        "id": "gUg2qcINEAA6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grafo"
      ],
      "metadata": {
        "id": "LXS7gUvCg9OC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El siguiente código se crea un flujo de indexación de los chunks que se transforman en embeddings para su posterior recuperacion y finalmente se estructura la ejecución en un grafo de estado."
      ],
      "metadata": {
        "id": "ramghfMifz0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Indexar fragmentos (chunks)\n",
        "docs_chunks = text_splitter.split_documents([Document(page_content=text)])\n",
        "\n",
        "# Agregar los fragmentos de documentos al almacén vectorial\n",
        "vector_store.add_documents(docs_chunks)\n",
        "# Define prompt for question-answering\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "\n",
        "# Definir el estado para la aplicación\n",
        "class State(TypedDict):\n",
        "    question: str\n",
        "    context: List[Document]\n",
        "    answer: str\n",
        "\n",
        "\n",
        "def retrieve(state: State):\n",
        "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
        "    # Asegurar que todos los documentos sean del tipo Document\n",
        "    retrieved_docs = [\n",
        "        Document(page_content=doc) if isinstance(doc, str) else doc\n",
        "        for doc in retrieved_docs #Busca los documentos de smilitud, si el documento es de estado str lo transforma a doc, pero si es doc lo deja como esta\n",
        "    ]\n",
        "    return {\"context\": retrieved_docs}\n",
        "\n",
        "\n",
        "def generate(state: State):\n",
        "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
        "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
        "    response = llm.invoke(messages)\n",
        "    return {\"answer\": response.content}\n",
        "\n",
        "\n",
        "\n",
        "# Compilar la aplicación y probar\n",
        "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
        "graph_builder.add_edge(START, \"retrieve\") #Establece el punto de inicio del flujo de trabajo\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "zOCo4A14jLjb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d0060dd-f868-4e4c-ab36-715ac350ded0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preguntas al LLM"
      ],
      "metadata": {
        "id": "hs6g_HqLhcrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = graph.invoke({\"question\": \"Cuales son los modelos de Machine Learning que se describen en el documento?\"})\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09kt9RXXEL4Q",
        "outputId": "4013d41a-9a99-4f06-be2c-7b83f3bd6468"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los modelos de Machine Learning descritos en el documento son: regresión múltiple, regresión logística, máquinas de vectores de soporte, árboles de decisión, bosques aleatorios, redes neuronales, y aprendizaje profundo (deep learning).\n"
          ]
        }
      ]
    }
  ]
}